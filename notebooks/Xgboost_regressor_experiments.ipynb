{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81d39100",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/echerif/miniconda3/envs/ironhack/lib/python3.14/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "\n",
    "import kagglehub\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e625e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "random_state = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6771454",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Visualization settings ##\n",
    "\n",
    "##### Matplotlib ##\n",
    "# Matplotlib inline to visualize Matplotlib graphs\n",
    "%matplotlib inline\n",
    "\n",
    "# Configuration to set so that all the Seaborn figures come out with this size\n",
    "%config Inlinebackend.figure_format= 'retina'\n",
    "\n",
    "\n",
    "#### Pandas ###\n",
    "#### show the max of columns in a pandas object\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "############ Seaborn ##\n",
    "# Set the Seaborn context to \"poster\" for larger text and figures\n",
    "sns.set_context(\"poster\")\n",
    "\n",
    "# Set the default figure size for Seaborn plots\n",
    "sns.set(rc={\"figure.figsize\": (12., 6.)})\n",
    "\n",
    "# Set the Seaborn style to \"whitegrid\" for a white background with gridlines\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8fbfb922",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Function for Regression evaluation\n",
    "def Reg_eval(X_train, y_train, MEDV_linReg):\n",
    "    from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "    \n",
    "    ### Make predictions\n",
    "    y_pred_train = MEDV_linReg.predict(X_train)\n",
    "\n",
    "    r2_score = float(round(r2_score(y_train, y_pred_train),3))\n",
    "    RMSE = float(round(np.sqrt(mean_squared_error(y_pred_train, y_train)),3))\n",
    "    MAE = float(round(mean_absolute_error(y_pred_train, y_train),3))\n",
    "\n",
    "    reg_scores = pd.DataFrame([r2_score, RMSE, MAE], index=['r2_score', 'RMSE', 'MAE'])\n",
    "    return reg_scores.T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66bb55a7",
   "metadata": {},
   "source": [
    "# 1. Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1533f48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_path = \"data/df_fe.csv\"\n",
    "king_hs = pd.read_csv(full_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "debd250d",
   "metadata": {},
   "source": [
    "- This version of the cleaned dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e535b98a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 21606 entries, 0 to 21605\n",
      "Data columns (total 31 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   id                      21606 non-null  int64  \n",
      " 1   date                    21606 non-null  object \n",
      " 2   price                   21606 non-null  float64\n",
      " 3   bedrooms                21606 non-null  int64  \n",
      " 4   bathrooms               21606 non-null  float64\n",
      " 5   sqft_living             21606 non-null  float64\n",
      " 6   sqft_lot                21606 non-null  float64\n",
      " 7   floors                  21606 non-null  float64\n",
      " 8   waterfront              21606 non-null  int64  \n",
      " 9   view                    21606 non-null  int64  \n",
      " 10  condition               21606 non-null  int64  \n",
      " 11  grade                   21606 non-null  int64  \n",
      " 12  sqft_above              21606 non-null  int64  \n",
      " 13  sqft_basement           21606 non-null  int64  \n",
      " 14  yr_built                21606 non-null  int64  \n",
      " 15  yr_renovated            21606 non-null  int64  \n",
      " 16  zipcode                 21606 non-null  int64  \n",
      " 17  lat                     21606 non-null  float64\n",
      " 18  long                    21606 non-null  float64\n",
      " 19  sqft_living15           21606 non-null  float64\n",
      " 20  sqft_lot15              21606 non-null  float64\n",
      " 21  log_price               21606 non-null  float64\n",
      " 22  year_sold               21606 non-null  int64  \n",
      " 23  month_sold              21606 non-null  int64  \n",
      " 24  house_age               21606 non-null  int64  \n",
      " 25  renovated               21606 non-null  int64  \n",
      " 26  years_since_renovation  21606 non-null  int64  \n",
      " 27  sqft_per_bedroom        21600 non-null  float64\n",
      " 28  sold_occ                21606 non-null  int64  \n",
      " 29  loc_clusters            21606 non-null  int64  \n",
      " 30  grade_clean             21606 non-null  float64\n",
      "dtypes: float64(12), int64(18), object(1)\n",
      "memory usage: 5.1+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(king_hs.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df60e0f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id: 21429\n",
      "date: 372\n",
      "price: 3889\n",
      "bedrooms: 13\n",
      "bathrooms: 30\n",
      "sqft_living: 887\n",
      "sqft_lot: 9615\n",
      "floors: 6\n",
      "waterfront: 2\n",
      "view: 5\n",
      "condition: 5\n",
      "grade: 11\n",
      "sqft_above: 943\n",
      "sqft_basement: 306\n",
      "yr_built: 116\n",
      "yr_renovated: 70\n",
      "zipcode: 70\n",
      "lat: 5033\n",
      "long: 752\n",
      "sqft_living15: 684\n",
      "sqft_lot15: 8544\n",
      "log_price: 4025\n",
      "year_sold: 2\n",
      "month_sold: 12\n",
      "house_age: 117\n",
      "renovated: 2\n",
      "years_since_renovation: 71\n",
      "sqft_per_bedroom: 1551\n",
      "sold_occ: 3\n",
      "loc_clusters: 4\n",
      "grade_clean: 7\n"
     ]
    }
   ],
   "source": [
    "for i in king_hs.columns:\n",
    "    print(f'{i}: {king_hs[i].nunique()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "66551442",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix the 33-bedroom outlier (likely a typo for 3)\n",
    "king_hs.loc[king_hs['bedrooms'] == 33, 'bedrooms'] = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb5ff0d",
   "metadata": {},
   "source": [
    "# 2. Split the dataset into features (X) and target (y)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "21c105c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "king_hs_X = king_hs.drop(['price','log_price'], axis=1)\n",
    "king_hs_y = king_hs[['price']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "85181468",
   "metadata": {},
   "outputs": [],
   "source": [
    "king_hs_X_clean = king_hs_X.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "15bb67f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'date', 'bedrooms', 'bathrooms', 'sqft_living', 'sqft_lot',\n",
       "       'floors', 'waterfront', 'view', 'condition', 'grade', 'sqft_above',\n",
       "       'sqft_basement', 'yr_built', 'yr_renovated', 'zipcode', 'lat', 'long',\n",
       "       'sqft_living15', 'sqft_lot15', 'year_sold', 'month_sold', 'house_age',\n",
       "       'renovated', 'years_since_renovation', 'sqft_per_bedroom', 'sold_occ',\n",
       "       'loc_clusters', 'grade_clean'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "king_hs_X.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa4d759b",
   "metadata": {},
   "source": [
    "# 3. Train baseline models: Linear Regression and Evaluate the models using metrics like RÂ², RMSE and MAE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9676d480",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Baseline after cleaning the data: Outliers and removed erroneous rows\n",
    "# - Improve the baseline:\n",
    "#     - check the data with 0 bedrooms and 0 bathrooms\n",
    "#     - OUTLIERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f39feaca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_train(king_hs_X_clean, king_hs_y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(king_hs_X_clean, king_hs_y, random_state=random_state, test_size=0.2)\n",
    "\n",
    "    ### Prepare the baseline \n",
    "    lin_baseline = LinearRegression()\n",
    "    lin_baseline.fit(X_train, y_train)\n",
    "\n",
    "    eval_tr = Reg_eval(X_train, y_train, lin_baseline)\n",
    "    eval_ts = Reg_eval(X_test, y_test, lin_baseline)\n",
    "\n",
    "    eval = pd.concat([eval_tr,eval_ts])\n",
    "    eval.index=['train', 'test']\n",
    "    return eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "769ad95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_cv(king_hs_X_clean, king_hs_y):\n",
    "    from sklearn.model_selection import cross_validate\n",
    "\n",
    "    ### Prepare the baseline \n",
    "    lin_baseline = LinearRegression()\n",
    "\n",
    "    cv_results = cross_validate(lin_baseline, king_hs_X_clean, king_hs_y, cv=3, scoring=('r2', 'neg_mean_squared_error',  'neg_mean_absolute_error'))\n",
    "\n",
    "    return cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "93b62da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_columns = ['id', 'bedrooms', 'bathrooms', 'sqft_living', 'sqft_lot',\n",
    "       'floors', 'waterfront', 'view',\n",
    "        'condition', 'grade', 'sqft_above',\n",
    "       'sqft_basement', 'yr_built', 'yr_renovated', 'zipcode', 'lat', 'long',\n",
    "       'sqft_living15', 'sqft_lot15', 'year_sold', 'month_sold']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bcfe7bef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>r2_score</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td>0.738</td>\n",
       "      <td>162453.101</td>\n",
       "      <td>113154.318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>0.743</td>\n",
       "      <td>161368.913</td>\n",
       "      <td>112806.907</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       r2_score        RMSE         MAE\n",
       "train     0.738  162453.101  113154.318\n",
       "test      0.743  161368.913  112806.907"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_train(king_hs_X_clean[baseline_columns], king_hs_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cdc8405e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.01870942, 0.01617455, 0.01645255]),\n",
       " 'score_time': array([0.00595498, 0.00569367, 0.00599194]),\n",
       " 'test_r2': array([0.74266012, 0.73274476, 0.72659796]),\n",
       " 'test_neg_mean_squared_error': array([-2.95489167e+10, -2.76876102e+10, -2.30126442e+10]),\n",
       " 'test_neg_mean_absolute_error': array([-117950.95060602, -114960.21778687, -108821.45408904])}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_cv(king_hs_X_clean[baseline_columns], king_hs_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc8b82e",
   "metadata": {},
   "source": [
    "# 4. Improve the baseline:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df7a76b",
   "metadata": {},
   "source": [
    "## Data side"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7eef02c",
   "metadata": {},
   "source": [
    "- Test feature engineering on the baseline:\n",
    "    - change yr_renovated (binary)\n",
    "    - yr_built >> convert to age based on reference year (e.g. 1900)\n",
    "    - replace long, lat and zipcode >> with k-means clusters\n",
    "    - transform the grade to a better grade system (12 grades here)\n",
    "    - replace the year with a flag column >> sold_occ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b70785bc",
   "metadata": {},
   "source": [
    "### sqft_above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "29d0eb6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "king_hs_X_clean_im = king_hs_X_clean.copy()\n",
    "\n",
    "king_hs_X_clean_im.drop(['sqft_above'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "24bd0cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_columns = [\n",
    "  'id',\n",
    " 'bedrooms',\n",
    " 'bathrooms',\n",
    " 'sqft_living',\n",
    " 'sqft_lot',\n",
    " 'floors',\n",
    " 'waterfront',\n",
    " 'view',\n",
    " 'condition',\n",
    " 'grade',\n",
    "#  'sqft_above',\n",
    " 'sqft_basement',\n",
    " 'yr_built',\n",
    " 'yr_renovated',\n",
    " 'zipcode',\n",
    " 'lat',\n",
    " 'long',\n",
    " 'sqft_living15',\n",
    " 'sqft_lot15',\n",
    " 'year_sold',\n",
    " 'month_sold']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1d778687",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>r2_score</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td>0.737</td>\n",
       "      <td>162962.310</td>\n",
       "      <td>113722.988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>0.740</td>\n",
       "      <td>162482.062</td>\n",
       "      <td>113730.605</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       r2_score        RMSE         MAE\n",
       "train     0.737  162962.310  113722.988\n",
       "test      0.740  162482.062  113730.605"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_train(king_hs_X_clean_im[baseline_columns], king_hs_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9aad3d19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.01563287, 0.01713514, 0.01573849]),\n",
       " 'score_time': array([0.00661683, 0.00591707, 0.00598288]),\n",
       " 'test_r2': array([0.74056663, 0.73055855, 0.72582083]),\n",
       " 'test_neg_mean_squared_error': array([-2.97893006e+10, -2.79141014e+10, -2.30780564e+10]),\n",
       " 'test_neg_mean_absolute_error': array([-118664.94207482, -115586.26383876, -109510.54560565])}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_cv(king_hs_X_clean[baseline_columns], king_hs_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5196a8fb",
   "metadata": {},
   "source": [
    "- sqft_above: slight drop in the perfomance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d511d0",
   "metadata": {},
   "source": [
    "### zipcode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "30b7c95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "king_hs_X_clean_im = king_hs_X_clean.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b27ee3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_columns = [\n",
    "  'id',\n",
    " 'bedrooms',\n",
    " 'bathrooms',\n",
    " 'sqft_living',\n",
    " 'sqft_lot',\n",
    " 'floors',\n",
    " 'waterfront',\n",
    " 'view',\n",
    " 'condition',\n",
    " 'grade',\n",
    " 'sqft_above',\n",
    " 'sqft_basement',\n",
    " 'yr_built',\n",
    " 'yr_renovated',\n",
    " 'lat',\n",
    " 'long',\n",
    " 'sqft_living15',\n",
    " 'sqft_lot15',\n",
    " 'year_sold',\n",
    " 'month_sold',\n",
    " \n",
    " 'loc_clusters',\n",
    " #  'zipcode'\n",
    " ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "933137fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>r2_score</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td>0.748</td>\n",
       "      <td>159323.483</td>\n",
       "      <td>108877.036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>0.754</td>\n",
       "      <td>158047.484</td>\n",
       "      <td>108494.530</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       r2_score        RMSE         MAE\n",
       "train     0.748  159323.483  108877.036\n",
       "test      0.754  158047.484  108494.530"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_train(king_hs_X_clean_im[baseline_columns], king_hs_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "71a5987a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.01797152, 0.0193584 , 0.02040863]),\n",
       " 'score_time': array([0.00771999, 0.00763822, 0.00792766]),\n",
       " 'test_r2': array([0.75174143, 0.74310856, 0.74011913]),\n",
       " 'test_neg_mean_squared_error': array([-2.85061604e+10, -2.66139214e+10, -2.18745481e+10]),\n",
       " 'test_neg_mean_absolute_error': array([-113466.04456542, -110459.07065686, -104219.13138181])}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_cv(king_hs_X_clean[baseline_columns], king_hs_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fca4a88",
   "metadata": {},
   "source": [
    "- sqft_above: slight drop in the perfomance\n",
    "- zipcode: Jump **Imporoved  the perfomance** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc3269ba",
   "metadata": {},
   "source": [
    "### grade_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "745d233b",
   "metadata": {},
   "outputs": [],
   "source": [
    "king_hs_X_clean_im = king_hs_X_clean.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "64e48f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_columns = [\n",
    "  'id',\n",
    " 'bedrooms',\n",
    " 'bathrooms',\n",
    " 'sqft_living',\n",
    " 'sqft_lot',\n",
    " 'floors',\n",
    " 'waterfront',\n",
    " 'view',\n",
    " 'condition',\n",
    "#  'grade',\n",
    " 'grade_clean',\n",
    " 'sqft_above',\n",
    " 'sqft_basement',\n",
    " 'yr_built',\n",
    " 'yr_renovated',\n",
    " 'lat',\n",
    " 'long',\n",
    " 'sqft_living15',\n",
    " 'sqft_lot15',\n",
    " 'year_sold',\n",
    " 'month_sold',\n",
    " 'zipcode',\n",
    "#  'loc_clusters'\n",
    " ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "af319a8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>r2_score</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td>0.740</td>\n",
       "      <td>161940.787</td>\n",
       "      <td>113606.018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>0.742</td>\n",
       "      <td>161789.679</td>\n",
       "      <td>113543.527</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       r2_score        RMSE         MAE\n",
       "train     0.740  161940.787  113606.018\n",
       "test      0.742  161789.679  113543.527"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_train(king_hs_X_clean_im[baseline_columns], king_hs_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "205bb426",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.01994157, 0.01771641, 0.0192008 ]),\n",
       " 'score_time': array([0.00917864, 0.00852656, 0.00635052]),\n",
       " 'test_r2': array([0.74455956, 0.73440014, 0.72639769]),\n",
       " 'test_neg_mean_squared_error': array([-2.93308148e+10, -2.75161130e+10, -2.30295007e+10]),\n",
       " 'test_neg_mean_absolute_error': array([-118179.91685821, -115611.34302529, -109365.08140745])}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_cv(king_hs_X_clean[baseline_columns], king_hs_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6465d90d",
   "metadata": {},
   "source": [
    "- sqft_above: slight drop in the perfomance\n",
    "- zipcode: Jump **Imporoved  the perfomance** \n",
    "- grade_clean: Slight drop\n",
    "- grade_clean:**Slight improvement**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c71b5d",
   "metadata": {},
   "source": [
    "###  sold_occ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6e6d7464",
   "metadata": {},
   "outputs": [],
   "source": [
    "king_hs_X_clean_im = king_hs_X_clean.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e3e46127",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_columns = [\n",
    "  # 'id',\n",
    "'sold_occ',\n",
    "\n",
    " 'bedrooms',\n",
    " 'bathrooms',\n",
    " 'sqft_living',\n",
    " 'sqft_lot',\n",
    " 'floors',\n",
    " 'waterfront',\n",
    " 'view',\n",
    " 'condition',\n",
    " 'grade',\n",
    " 'sqft_above',\n",
    " 'sqft_basement',\n",
    " 'yr_built',\n",
    " 'yr_renovated',\n",
    " 'lat',\n",
    " 'long',\n",
    " 'sqft_living15',\n",
    " 'sqft_lot15',\n",
    " 'year_sold',\n",
    " 'month_sold',\n",
    " \n",
    " 'zipcode',\n",
    "#  'loc_clusters'\n",
    " ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "14e8e88b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>r2_score</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td>0.738</td>\n",
       "      <td>162469.163</td>\n",
       "      <td>113093.665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>0.744</td>\n",
       "      <td>161233.529</td>\n",
       "      <td>112727.323</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       r2_score        RMSE         MAE\n",
       "train     0.738  162469.163  113093.665\n",
       "test      0.744  161233.529  112727.323"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_train(king_hs_X_clean_im[baseline_columns], king_hs_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cf1ea5b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.0180192 , 0.01712537, 0.01746368]),\n",
       " 'score_time': array([0.00725985, 0.00725102, 0.00714588]),\n",
       " 'test_r2': array([0.74187811, 0.73310377, 0.72668657]),\n",
       " 'test_neg_mean_squared_error': array([-2.96387108e+10, -2.76504165e+10, -2.30051859e+10]),\n",
       " 'test_neg_mean_absolute_error': array([-117858.66761534, -114823.71457101, -109025.82897439])}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_cv(king_hs_X_clean[baseline_columns], king_hs_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a96a117",
   "metadata": {},
   "source": [
    "- sqft_above: slight drop in the perfomance\n",
    "- zipcode: Jump **Imporoved  the perfomance** \n",
    "- grade_clean: Slight drop\n",
    "- grade_clean:**Slight improvement**\n",
    "- sold_occ **Slight improvement**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1480ce37",
   "metadata": {},
   "source": [
    "### age drop yr_renovated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "58402c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "king_hs_X_clean_im = king_hs_X_clean.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8ae8fb6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_columns = [\n",
    "  'id',\n",
    "# 'sold_occ',\n",
    "\n",
    " 'bedrooms',\n",
    " 'bathrooms',\n",
    " 'sqft_living',\n",
    " 'sqft_lot',\n",
    " 'floors',\n",
    " 'waterfront',\n",
    " 'view',\n",
    " 'condition',\n",
    " 'grade_clean',\n",
    " 'sqft_above',\n",
    " 'sqft_basement',\n",
    "\n",
    " 'yr_built',\n",
    " 'yr_renovated',\n",
    "#  'house_age',\n",
    "\n",
    " 'sqft_living15',\n",
    " 'sqft_lot15',\n",
    " 'year_sold',\n",
    " 'month_sold',\n",
    "\n",
    " 'lat',\n",
    " 'long',\n",
    " 'zipcode',\n",
    "#  'loc_clusters'\n",
    " ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9190f4ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>r2_score</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td>0.740</td>\n",
       "      <td>161940.787</td>\n",
       "      <td>113606.018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>0.742</td>\n",
       "      <td>161789.679</td>\n",
       "      <td>113543.527</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       r2_score        RMSE         MAE\n",
       "train     0.740  161940.787  113606.018\n",
       "test      0.742  161789.679  113543.527"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_train(king_hs_X_clean_im[baseline_columns], king_hs_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1f416623",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.01784086, 0.01805997, 0.01730537]),\n",
       " 'score_time': array([0.00702119, 0.00594497, 0.0058949 ]),\n",
       " 'test_r2': array([0.74455956, 0.73440014, 0.72639769]),\n",
       " 'test_neg_mean_squared_error': array([-2.93308148e+10, -2.75161130e+10, -2.30295007e+10]),\n",
       " 'test_neg_mean_absolute_error': array([-118179.91685822, -115611.34302529, -109365.08140746])}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_cv(king_hs_X_clean[baseline_columns], king_hs_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "668d81d8",
   "metadata": {},
   "source": [
    "- sqft_above: slight drop in the perfomance\n",
    "- zipcode: Jump **Imporoved  the perfomance** \n",
    "- grade_clean: Slight drop\n",
    "- grade_clean:**Slight improvement**\n",
    "- sold_occ **Slight improvement**\n",
    "- Age: Drop in the perfoemance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d55fd24",
   "metadata": {},
   "source": [
    "### drop month_sold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fd7f0710",
   "metadata": {},
   "outputs": [],
   "source": [
    "king_hs_X_clean_im = king_hs_X_clean.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c4fb8495",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_columns = [\n",
    "  'id',\n",
    "# 'sold_occ',\n",
    "\n",
    " 'bedrooms',\n",
    " 'bathrooms',\n",
    " 'sqft_living',\n",
    " 'sqft_lot',\n",
    " 'floors',\n",
    " 'waterfront',\n",
    " 'view',\n",
    " 'condition',\n",
    " 'grade_clean',\n",
    " 'sqft_above',\n",
    " 'sqft_basement',\n",
    "\n",
    " 'yr_built',\n",
    " 'yr_renovated',\n",
    "# 'renovated',\n",
    "#  'house_age',\n",
    "\n",
    " 'sqft_living15',\n",
    " 'sqft_lot15',\n",
    " 'year_sold',\n",
    "#  'month_sold',\n",
    "\n",
    " 'lat',\n",
    " 'long',\n",
    " 'zipcode',\n",
    "#  'loc_clusters'\n",
    " ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dc45d865",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>r2_score</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td>0.740</td>\n",
       "      <td>161946.138</td>\n",
       "      <td>113600.625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>0.742</td>\n",
       "      <td>161800.948</td>\n",
       "      <td>113568.074</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       r2_score        RMSE         MAE\n",
       "train     0.740  161946.138  113600.625\n",
       "test      0.742  161800.948  113568.074"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_train(king_hs_X_clean_im[baseline_columns], king_hs_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "df88ad8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.0188241 , 0.01935625, 0.02067184]),\n",
       " 'score_time': array([0.00856614, 0.00598192, 0.00649142]),\n",
       " 'test_r2': array([0.74458101, 0.73436559, 0.72639433]),\n",
       " 'test_neg_mean_squared_error': array([-2.93283519e+10, -2.75196923e+10, -2.30297842e+10]),\n",
       " 'test_neg_mean_absolute_error': array([-118163.56622889, -115622.88987805, -109347.76430819])}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_cv(king_hs_X_clean[baseline_columns], king_hs_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2febd31",
   "metadata": {},
   "source": [
    "- sqft_above: slight drop in the perfomance\n",
    "- zipcode: Jump **Imporoved  the perfomance** \n",
    "- grade_clean: Slight drop\n",
    "- grade_clean:**Slight improvement**\n",
    "- sold_occ **Slight improvement**\n",
    "- Age: Drop in the perfoemance\n",
    "- month_sold: drop in perfoemance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a26c94",
   "metadata": {},
   "source": [
    "### year_sold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0a7d10e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "king_hs_X_clean_im = king_hs_X_clean.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "667e52c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_columns = [\n",
    "  'id',\n",
    "# 'sold_occ',\n",
    "\n",
    " 'bedrooms',\n",
    " 'bathrooms',\n",
    " 'sqft_living',\n",
    " 'sqft_lot',\n",
    " 'floors',\n",
    " 'waterfront',\n",
    " 'view',\n",
    " 'condition',\n",
    " 'grade_clean',\n",
    " 'sqft_above',\n",
    " 'sqft_basement',\n",
    "\n",
    " 'yr_built',\n",
    " 'yr_renovated',\n",
    "# 'renovated',\n",
    "#  'house_age',\n",
    "\n",
    " 'sqft_living15',\n",
    " 'sqft_lot15',\n",
    "#  'year_sold',\n",
    "#  'month_sold',\n",
    "\n",
    " 'lat',\n",
    " 'long',\n",
    " 'zipcode',\n",
    "#  'loc_clusters'\n",
    " ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "501da11f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>r2_score</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td>0.738</td>\n",
       "      <td>162472.718</td>\n",
       "      <td>114047.185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>0.739</td>\n",
       "      <td>162537.659</td>\n",
       "      <td>114256.884</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       r2_score        RMSE         MAE\n",
       "train     0.738  162472.718  114047.185\n",
       "test      0.739  162537.659  114256.884"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_train(king_hs_X_clean_im[baseline_columns], king_hs_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4e8106b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.01573658, 0.01821685, 0.01592708]),\n",
       " 'score_time': array([0.00862384, 0.00769639, 0.00730085]),\n",
       " 'test_r2': array([0.74304038, 0.73300799, 0.72339592]),\n",
       " 'test_neg_mean_squared_error': array([-2.95052538e+10, -2.76603401e+10, -2.32821648e+10]),\n",
       " 'test_neg_mean_absolute_error': array([-118750.93696457, -116083.76096177, -109796.02204454])}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_cv(king_hs_X_clean[baseline_columns], king_hs_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa837859",
   "metadata": {},
   "source": [
    "- sqft_above: slight drop in the perfomance\n",
    "- zipcode: Jump **Imporoved  the perfomance** \n",
    "- grade_clean: Slight drop\n",
    "- grade_clean:**Slight improvement**\n",
    "- sold_occ **Slight improvement**\n",
    "- Age: Drop in the perfoemance\n",
    "- month_sold: drop in perfoemance\n",
    "- year_sold: drop in perfoamance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a5cb0e",
   "metadata": {},
   "source": [
    "### yr_renovated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a0ada636",
   "metadata": {},
   "outputs": [],
   "source": [
    "king_hs_X_clean_im = king_hs_X_clean.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a516e41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_columns = [\n",
    "  'id',\n",
    "# 'sold_occ',\n",
    "\n",
    " 'bedrooms',\n",
    " 'bathrooms',\n",
    " 'sqft_living',\n",
    " 'sqft_lot',\n",
    " 'floors',\n",
    " 'waterfront',\n",
    " 'view',\n",
    " 'condition',\n",
    " 'grade_clean',\n",
    " 'sqft_above',\n",
    " 'sqft_basement',\n",
    "\n",
    " 'yr_built',\n",
    "#  'yr_renovated',\n",
    "'renovated',\n",
    "#  'house_age',\n",
    "\n",
    " 'sqft_living15',\n",
    " 'sqft_lot15',\n",
    " 'year_sold',\n",
    " 'month_sold',\n",
    "\n",
    " 'lat',\n",
    " 'long',\n",
    "#  'zipcode',\n",
    " 'loc_clusters'\n",
    " ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7ab6e960",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>r2_score</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td>0.751</td>\n",
       "      <td>158429.864</td>\n",
       "      <td>108389.025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>0.754</td>\n",
       "      <td>157995.931</td>\n",
       "      <td>107975.661</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       r2_score        RMSE         MAE\n",
       "train     0.751  158429.864  108389.025\n",
       "test      0.754  157995.931  107975.661"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_train(king_hs_X_clean_im[baseline_columns], king_hs_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b228d408",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.01873302, 0.02067494, 0.01919556]),\n",
       " 'score_time': array([0.00598431, 0.00632811, 0.00626135]),\n",
       " 'test_r2': array([0.75393078, 0.74649638, 0.74186522]),\n",
       " 'test_neg_mean_squared_error': array([-2.82547691e+10, -2.62629440e+10, -2.17275769e+10]),\n",
       " 'test_neg_mean_absolute_error': array([-113606.02199375, -109688.01205396, -103464.29592907])}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_cv(king_hs_X_clean[baseline_columns], king_hs_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9565953",
   "metadata": {},
   "source": [
    "- No effect"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f79870",
   "metadata": {},
   "source": [
    "### Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd7392e2",
   "metadata": {},
   "source": [
    "From the baseline:\n",
    "- The drop of (0 bedrooms 0 bathroom ): jump in the perfoemance\n",
    "\n",
    "- Feature engineering\n",
    "    - drop sqft_above: slight drop in the perfomance\n",
    "    - replace with clustes: zipcode: Jump **Imporoved  the perfomance** \n",
    "    - change categories: grade_clean: Slight drop\n",
    "    - flag instead of id sold_occ **Slight improvement**\n",
    "    - replace build and renovated year Age: Drop in the perfoemance\n",
    "    - drop month_sold: drop in perfoemance\n",
    "    - drop year_sold: drop in perfoamance\n",
    "    - no effect yr_renovated no effect to bool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80974423",
   "metadata": {},
   "source": [
    "### Best LinearRegression after feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "57727c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Dropped features\n",
    "# 'id', 'date', 'house_age', 'years_since_renovation', 'sqft_per_bedroom', 'zipcode', 'sqft_per_bedroom', 'grade_clean','yr_renovated', '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "db7c7fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_features= [\n",
    " 'bedrooms',\n",
    " 'bathrooms',\n",
    "\n",
    " 'sqft_living',\n",
    " 'sqft_lot',\n",
    "\n",
    " 'floors',\n",
    " 'waterfront',\n",
    " 'view',\n",
    " 'condition',\n",
    "\n",
    " 'grade',\n",
    " 'sqft_above',\n",
    " 'sqft_basement',\n",
    "\n",
    " 'yr_built',\n",
    " 'renovated',\n",
    "\n",
    " 'sqft_living15',\n",
    " 'sqft_lot15',\n",
    "\n",
    " 'year_sold',\n",
    " 'month_sold',\n",
    "\n",
    "  'lat',\n",
    " 'long',\n",
    " 'loc_clusters',  \n",
    " 'sold_occ'\n",
    " ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fc68a166",
   "metadata": {},
   "outputs": [],
   "source": [
    "king_hs_X_clean_im = king_hs_X_clean.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d2872390",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>r2_score</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td>0.748</td>\n",
       "      <td>159366.572</td>\n",
       "      <td>108806.532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>0.754</td>\n",
       "      <td>157915.963</td>\n",
       "      <td>108415.630</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       r2_score        RMSE         MAE\n",
       "train     0.748  159366.572  108806.532\n",
       "test      0.754  157915.963  108415.630"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_train(king_hs_X_clean_im[best_features], king_hs_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9a3cd272",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.02037716, 0.01915598, 0.02081728]),\n",
       " 'score_time': array([0.0082643 , 0.00727558, 0.0106616 ]),\n",
       " 'test_r2': array([0.75072294, 0.74348497, 0.73964885]),\n",
       " 'test_neg_mean_squared_error': array([-2.86231077e+10, -2.65749260e+10, -2.19141318e+10]),\n",
       " 'test_neg_mean_absolute_error': array([-113310.70078618, -110253.95850922, -104664.68540961])}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_cv(king_hs_X_clean[best_features], king_hs_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3985c8d",
   "metadata": {},
   "source": [
    "### Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c7687067",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "}\n",
       "\n",
       "#sk-container-id-1.light {\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: black;\n",
       "  --sklearn-color-background: white;\n",
       "  --sklearn-color-border-box: black;\n",
       "  --sklearn-color-icon: #696969;\n",
       "}\n",
       "\n",
       "#sk-container-id-1.dark {\n",
       "  --sklearn-color-text-on-default-background: white;\n",
       "  --sklearn-color-background: #111;\n",
       "  --sklearn-color-border-box: white;\n",
       "  --sklearn-color-icon: #878787;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: center;\n",
       "  justify-content: center;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"â¸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"â¾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-3) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  border: var(--sklearn-color-fitted-level-0) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-0);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  border: var(--sklearn-color-fitted-level-0) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-0);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table {\n",
       "    font-family: monospace;\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table summary::marker {\n",
       "    font-size: 0.7rem;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "    margin-top: 0;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       "/*\n",
       "    `table td`is set in notebook with right text-align.\n",
       "    We need to overwrite it.\n",
       "*/\n",
       ".estimator-table table td.param {\n",
       "    text-align: left;\n",
       "    position: relative;\n",
       "    padding: 0;\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left !important;\n",
       "}\n",
       "\n",
       ".user-set td.value {\n",
       "    color:rgb(255, 94, 0);\n",
       "    background-color: transparent;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left !important;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       "/*\n",
       "    Styles for parameter documentation links\n",
       "    We need styling for visited so jupyter doesn't overwrite it\n",
       "*/\n",
       "a.param-doc-link,\n",
       "a.param-doc-link:link,\n",
       "a.param-doc-link:visited {\n",
       "    text-decoration: underline dashed;\n",
       "    text-underline-offset: .3em;\n",
       "    color: inherit;\n",
       "    display: block;\n",
       "    padding: .5em;\n",
       "}\n",
       "\n",
       "/* \"hack\" to make the entire area of the cell containing the link clickable */\n",
       "a.param-doc-link::before {\n",
       "    position: absolute;\n",
       "    content: \"\";\n",
       "    inset: 0;\n",
       "}\n",
       "\n",
       ".param-doc-description {\n",
       "    display: none;\n",
       "    position: absolute;\n",
       "    z-index: 9999;\n",
       "    left: 0;\n",
       "    padding: .5ex;\n",
       "    margin-left: 1.5em;\n",
       "    color: var(--sklearn-color-text);\n",
       "    box-shadow: .3em .3em .4em #999;\n",
       "    width: max-content;\n",
       "    text-align: left;\n",
       "    max-height: 10em;\n",
       "    overflow-y: auto;\n",
       "\n",
       "    /* unfitted */\n",
       "    background: var(--sklearn-color-unfitted-level-0);\n",
       "    border: thin solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       "/* Fitted state for parameter tooltips */\n",
       ".fitted .param-doc-description {\n",
       "    /* fitted */\n",
       "    background: var(--sklearn-color-fitted-level-0);\n",
       "    border: thin solid var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".param-doc-link:hover .param-doc-description {\n",
       "    display: block;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LinearRegression</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LinearRegression.html\">?<span>Documentation for LinearRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('fit_intercept',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LinearRegression.html#:~:text=fit_intercept,-bool%2C%20default%3DTrue\">\n",
       "            fit_intercept\n",
       "            <span class=\"param-doc-description\">fit_intercept: bool, default=True<br><br>Whether to calculate the intercept for this model. If set<br>to False, no intercept will be used in calculations<br>(i.e. data is expected to be centered).</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('copy_X',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LinearRegression.html#:~:text=copy_X,-bool%2C%20default%3DTrue\">\n",
       "            copy_X\n",
       "            <span class=\"param-doc-description\">copy_X: bool, default=True<br><br>If True, X will be copied; else, it may be overwritten.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('tol',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LinearRegression.html#:~:text=tol,-float%2C%20default%3D1e-6\">\n",
       "            tol\n",
       "            <span class=\"param-doc-description\">tol: float, default=1e-6<br><br>The precision of the solution (`coef_`) is determined by `tol` which<br>specifies a different convergence criterion for the `lsqr` solver.<br>`tol` is set as `atol` and `btol` of :func:`scipy.sparse.linalg.lsqr` when<br>fitting on sparse training data. This parameter has no effect when fitting<br>on dense data.<br><br>.. versionadded:: 1.7</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">1e-06</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_jobs',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LinearRegression.html#:~:text=n_jobs,-int%2C%20default%3DNone\">\n",
       "            n_jobs\n",
       "            <span class=\"param-doc-description\">n_jobs: int, default=None<br><br>The number of jobs to use for the computation. This will only provide<br>speedup in case of sufficiently large problems, that is if firstly<br>`n_targets > 1` and secondly `X` is sparse or if `positive` is set<br>to `True`. ``None`` means 1 unless in a<br>:obj:`joblib.parallel_backend` context. ``-1`` means using all<br>processors. See :term:`Glossary <n_jobs>` for more details.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('positive',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LinearRegression.html#:~:text=positive,-bool%2C%20default%3DFalse\">\n",
       "            positive\n",
       "            <span class=\"param-doc-description\">positive: bool, default=False<br><br>When set to ``True``, forces the coefficients to be positive. This<br>option is only supported for dense arrays.<br><br>For a comparison between a linear regression model with positive constraints<br>on the regression coefficients and a linear regression without such constraints,<br>see :ref:`sphx_glr_auto_examples_linear_model_plot_nnls.py`.<br><br>.. versionadded:: 0.24</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.copy-paste-icon').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling\n",
       "        .textContent.trim().split(' ')[0];\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "\n",
       "\n",
       "/**\n",
       " * Adapted from Skrub\n",
       " * https://github.com/skrub-data/skrub/blob/403466d1d5d4dc76a7ef569b3f8228db59a31dc3/skrub/_reporting/_data/templates/report.js#L789\n",
       " * @returns \"light\" or \"dark\"\n",
       " */\n",
       "function detectTheme(element) {\n",
       "    const body = document.querySelector('body');\n",
       "\n",
       "    // Check VSCode theme\n",
       "    const themeKindAttr = body.getAttribute('data-vscode-theme-kind');\n",
       "    const themeNameAttr = body.getAttribute('data-vscode-theme-name');\n",
       "\n",
       "    if (themeKindAttr && themeNameAttr) {\n",
       "        const themeKind = themeKindAttr.toLowerCase();\n",
       "        const themeName = themeNameAttr.toLowerCase();\n",
       "\n",
       "        if (themeKind.includes(\"dark\") || themeName.includes(\"dark\")) {\n",
       "            return \"dark\";\n",
       "        }\n",
       "        if (themeKind.includes(\"light\") || themeName.includes(\"light\")) {\n",
       "            return \"light\";\n",
       "        }\n",
       "    }\n",
       "\n",
       "    // Check Jupyter theme\n",
       "    if (body.getAttribute('data-jp-theme-light') === 'false') {\n",
       "        return 'dark';\n",
       "    } else if (body.getAttribute('data-jp-theme-light') === 'true') {\n",
       "        return 'light';\n",
       "    }\n",
       "\n",
       "    // Guess based on a parent element's color\n",
       "    const color = window.getComputedStyle(element.parentNode, null).getPropertyValue('color');\n",
       "    const match = color.match(/^rgb\\s*\\(\\s*(\\d+)\\s*,\\s*(\\d+)\\s*,\\s*(\\d+)\\s*\\)\\s*$/i);\n",
       "    if (match) {\n",
       "        const [r, g, b] = [\n",
       "            parseFloat(match[1]),\n",
       "            parseFloat(match[2]),\n",
       "            parseFloat(match[3])\n",
       "        ];\n",
       "\n",
       "        // https://en.wikipedia.org/wiki/HSL_and_HSV#Lightness\n",
       "        const luma = 0.299 * r + 0.587 * g + 0.114 * b;\n",
       "\n",
       "        if (luma > 180) {\n",
       "            // If the text is very bright we have a dark theme\n",
       "            return 'dark';\n",
       "        }\n",
       "        if (luma < 75) {\n",
       "            // If the text is very dark we have a light theme\n",
       "            return 'light';\n",
       "        }\n",
       "        // Otherwise fall back to the next heuristic.\n",
       "    }\n",
       "\n",
       "    // Fallback to system preference\n",
       "    return window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'light';\n",
       "}\n",
       "\n",
       "\n",
       "function forceTheme(elementId) {\n",
       "    const estimatorElement = document.querySelector(`#${elementId}`);\n",
       "    if (estimatorElement === null) {\n",
       "        console.error(`Element with id ${elementId} not found.`);\n",
       "    } else {\n",
       "        const theme = detectTheme(estimatorElement);\n",
       "        estimatorElement.classList.add(theme);\n",
       "    }\n",
       "}\n",
       "\n",
       "forceTheme('sk-container-id-1');</script></body>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(king_hs_X_clean[best_features], king_hs_y, random_state=random_state, test_size=0.2, shuffle=True)\n",
    "\n",
    "### Prepare the baseline \n",
    "lin_improve = LinearRegression()\n",
    "lin_improve.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a612d13b",
   "metadata": {},
   "outputs": [],
   "source": [
    "selector = RFE(lin_improve, n_features_to_select=10, step=1) ##xgb_reg, lin_baseline\n",
    "selector = selector.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "43b84559",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features ordered by importance:\n",
      "          Feature  Ranking  Selected\n",
      "1       bathrooms        1      True\n",
      "7       condition        1      True\n",
      "6            view        1      True\n",
      "5      waterfront        1      True\n",
      "12      renovated        1      True\n",
      "8           grade        1      True\n",
      "18           long        1      True\n",
      "17            lat        1      True\n",
      "20       sold_occ        1      True\n",
      "19   loc_clusters        1      True\n",
      "15      year_sold        2     False\n",
      "0        bedrooms        3     False\n",
      "4          floors        4     False\n",
      "11       yr_built        5     False\n",
      "16     month_sold        6     False\n",
      "9      sqft_above        7     False\n",
      "10  sqft_basement        8     False\n",
      "13  sqft_living15        9     False\n",
      "2     sqft_living       10     False\n",
      "14     sqft_lot15       11     False\n",
      "3        sqft_lot       12     False\n",
      "\n",
      "Top 5 Selected Features:\n",
      "['bathrooms', 'condition', 'view', 'waterfront', 'renovated', 'grade', 'long', 'lat', 'sold_occ', 'loc_clusters']\n"
     ]
    }
   ],
   "source": [
    "# Get feature names and rankings\n",
    "feature_ranking = pd.DataFrame({\n",
    "    'Feature': X_train.columns,\n",
    "    'Ranking': selector.ranking_,\n",
    "    'Selected': selector.support_\n",
    "}).sort_values('Ranking')\n",
    "\n",
    "print(\"Features ordered by importance:\")\n",
    "print(feature_ranking)\n",
    "\n",
    "# Just the top 5 selected features\n",
    "print(\"\\nTop 5 Selected Features:\")\n",
    "print(feature_ranking[feature_ranking['Selected'] == True]['Feature'].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c6f8e4a",
   "metadata": {},
   "source": [
    "## Model side: XGBOOST with hyperparameter tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa1e32f",
   "metadata": {},
   "source": [
    "### XgBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f2821a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgb_train(king_hs_X_clean, king_hs_y):\n",
    "    import xgboost as xgb\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(king_hs_X_clean, king_hs_y, random_state=random_state, test_size=0.2)\n",
    "\n",
    "    ### Prepare the baseline \n",
    "    xgb = xgb.XGBRegressor()\n",
    "    xgb.fit(X_train, y_train)\n",
    "\n",
    "    eval_tr = Reg_eval(X_train, y_train, xgb)\n",
    "    eval_ts = Reg_eval(X_test, y_test, xgb)\n",
    "\n",
    "    eval = pd.concat([eval_tr,eval_ts])\n",
    "    eval.index=['train', 'test']\n",
    "    return eval\n",
    "\n",
    "def xgb_cv(king_hs_X_clean, king_hs_y):\n",
    "    from sklearn.model_selection import cross_validate\n",
    "    import xgboost as xgb\n",
    "\n",
    "    ### Prepare the baseline \n",
    "    xgb = xgb.XGBRegressor()\n",
    "\n",
    "    cv_results = cross_validate(xgb, king_hs_X_clean, king_hs_y, cv=3, scoring=('r2', 'neg_mean_squared_error',  'neg_mean_absolute_error'))\n",
    "\n",
    "    return cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "94d21945",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>r2_score</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td>0.971</td>\n",
       "      <td>53874.865</td>\n",
       "      <td>38387.367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>0.912</td>\n",
       "      <td>94508.141</td>\n",
       "      <td>61144.875</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       r2_score       RMSE        MAE\n",
       "train     0.971  53874.865  38387.367\n",
       "test      0.912  94508.141  61144.875"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_train(king_hs_X_clean[best_features], king_hs_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b2b05803",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([ 1.1230545 , -1.69157195,  1.26300406]),\n",
       " 'score_time': array([0.01813388, 0.01980925, 0.01880407]),\n",
       " 'test_r2': array([0.884942  , 0.88263726, 0.88811511]),\n",
       " 'test_neg_mean_squared_error': array([-1.32114780e+10, -1.21587681e+10, -9.41751194e+09]),\n",
       " 'test_neg_mean_absolute_error': array([-70885.53125  , -69179.1640625, -63802.2421875])}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_cv(king_hs_X_clean[best_features], king_hs_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b177d5",
   "metadata": {},
   "source": [
    "#### Fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "115c1b21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Grid Search...\n",
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.8; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.8; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=1.0; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.8; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=1.0; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=1.0; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.8; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=1.0; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=0.8; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=0.8; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=0.8; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=0.8; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=0.8; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=1.0; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=1.0; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=1.0; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=1.0; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.8; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.8; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.8; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.8; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.8; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.8; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.8; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.8; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.8; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.8; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=1.0; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=1.0; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=0.8; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=1.0; total time=   2.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=0.8; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=0.8; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=0.8; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=0.8; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=1.0; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=1.0; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=1.0; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=1.0; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=1.0; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=1.0; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=1.0; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=0.8; total time=   2.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=0.8; total time=   2.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=1.0; total time=   2.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=0.8; total time=   2.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=1.0; total time=   2.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=0.8; total time=   3.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=1.0; total time=   2.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=0.8; total time=   3.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=1.0; total time=   3.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=1.0; total time=   3.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=0.8; total time=   3.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=0.8; total time=   4.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=0.8; total time=   4.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=1.0; total time=   4.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=0.8; total time=   4.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=0.8; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=0.8; total time=   4.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=0.8; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=0.8; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=0.8; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=0.8; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=1.0; total time=   3.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=1.0; total time=   3.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=1.0; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=1.0; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=1.0; total time=   3.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=1.0; total time=   3.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.8; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.8; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.8; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1.0; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1.0; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.8; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.8; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1.0; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1.0; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1.0; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.8; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.8; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.8; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.8; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=1.0; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.8; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=1.0; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=0.8; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=0.8; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=0.8; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=1.0; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=1.0; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=1.0; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=0.8; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=0.8; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=1.0; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=1.0; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=1.0; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=1.0; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=1.0; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=0.8; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=0.8; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=1.0; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=1.0; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=0.8; total time=   2.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=0.8; total time=   2.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=1.0; total time=   2.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=1.0; total time=   2.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=0.8; total time=   2.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=1.0; total time=   2.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.4s[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.4s\n",
      "\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=0.8; total time=   3.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=0.8; total time=   3.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=0.8; total time=   3.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=0.8; total time=   3.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=1.0; total time=   3.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=0.8; total time=   3.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=3, n_estimators=300, subsample=0.8; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=3, n_estimators=300, subsample=0.8; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=3, n_estimators=300, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=3, n_estimators=300, subsample=0.8; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=3, n_estimators=300, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=3, n_estimators=300, subsample=0.8; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=3, n_estimators=300, subsample=0.8; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=3, n_estimators=300, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=1.0; total time=   2.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=1.0; total time=   2.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=3, n_estimators=300, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=3, n_estimators=300, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=1.0; total time=   3.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=5, n_estimators=100, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=5, n_estimators=100, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=5, n_estimators=100, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=5, n_estimators=100, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=5, n_estimators=100, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=1.0; total time=   3.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=5, n_estimators=200, subsample=0.8; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=5, n_estimators=200, subsample=0.8; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=5, n_estimators=200, subsample=0.8; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=5, n_estimators=200, subsample=0.8; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=5, n_estimators=200, subsample=0.8; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=5, n_estimators=200, subsample=1.0; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=5, n_estimators=200, subsample=1.0; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=5, n_estimators=200, subsample=1.0; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=5, n_estimators=200, subsample=1.0; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=5, n_estimators=200, subsample=1.0; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=5, n_estimators=300, subsample=0.8; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=5, n_estimators=300, subsample=0.8; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=5, n_estimators=300, subsample=0.8; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=5, n_estimators=300, subsample=1.0; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=5, n_estimators=300, subsample=0.8; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=5, n_estimators=300, subsample=0.8; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=7, n_estimators=100, subsample=0.8; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=7, n_estimators=100, subsample=0.8; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=7, n_estimators=100, subsample=0.8; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=5, n_estimators=300, subsample=1.0; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=7, n_estimators=100, subsample=0.8; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=5, n_estimators=300, subsample=1.0; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=5, n_estimators=300, subsample=1.0; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=7, n_estimators=100, subsample=0.8; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=7, n_estimators=100, subsample=1.0; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=5, n_estimators=300, subsample=1.0; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=7, n_estimators=100, subsample=1.0; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=7, n_estimators=100, subsample=1.0; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=7, n_estimators=100, subsample=1.0; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=7, n_estimators=100, subsample=1.0; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=7, n_estimators=200, subsample=0.8; total time=   2.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=7, n_estimators=200, subsample=1.0; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=7, n_estimators=200, subsample=0.8; total time=   2.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=7, n_estimators=200, subsample=1.0; total time=   2.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=7, n_estimators=200, subsample=1.0; total time=   2.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=7, n_estimators=200, subsample=0.8; total time=   2.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=7, n_estimators=200, subsample=1.0; total time=   2.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=7, n_estimators=200, subsample=0.8; total time=   2.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=7, n_estimators=200, subsample=0.8; total time=   2.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=7, n_estimators=200, subsample=1.0; total time=   2.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=7, n_estimators=300, subsample=0.8; total time=   3.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=7, n_estimators=300, subsample=0.8; total time=   3.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=7, n_estimators=300, subsample=0.8; total time=   3.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=7, n_estimators=300, subsample=0.8; total time=   3.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=7, n_estimators=300, subsample=0.8; total time=   3.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=7, n_estimators=300, subsample=1.0; total time=   3.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=7, n_estimators=300, subsample=1.0; total time=   2.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=0.8; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=7, n_estimators=300, subsample=1.0; total time=   2.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=0.8; total time=   0.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=0.8; total time=   1.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=0.8; total time=   1.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=0.8; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=7, n_estimators=300, subsample=1.0; total time=   2.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=1.0; total time=   1.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=1.0; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=7, n_estimators=300, subsample=1.0; total time=   3.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.7s[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.7s\n",
      "\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.8; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.8; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.8; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.8; total time=   1.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.8; total time=   1.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0; total time=   1.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0; total time=   1.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=1.0; total time=  -1.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.8; total time=  -1.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.8; total time=  -1.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.8; total time=  -1.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.8; total time=  -1.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.8; total time=  -0.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=1.0; total time=   3.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=0.8; total time=  -1.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=1.0; total time=  -1.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=1.0; total time=  -1.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=1.0; total time=  -1.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=0.8; total time=  -1.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=0.8; total time=  -1.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=0.8; total time=  -1.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=1.0; total time=  -1.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=0.8; total time=  -1.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=1.0; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=1.0; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=1.0; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=1.0; total time=   1.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=0.8; total time=  -2.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=1.0; total time=   2.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=0.8; total time=   2.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=1.0; total time=   2.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=0.8; total time=   2.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=1.0; total time=   2.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=1.0; total time=   2.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=0.8; total time=   3.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=1.0; total time=   2.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=0.8; total time=   3.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=0.8; total time=   3.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=0.8; total time=   3.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=0.8; total time=   3.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=0.8; total time=   3.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=0.8; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=0.8; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=0.8; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=0.8; total time=   4.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=0.8; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=0.8; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=1.0; total time=   3.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=1.0; total time=   4.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.8; total time=   1.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=1.0; total time=   3.7s[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=1.0; total time=   0.8s\n",
      "\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.8; total time=   1.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1.0; total time=   1.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1.0; total time=   1.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.8; total time=   1.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=1.0; total time=   3.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=1.0; total time=   4.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.8; total time=   1.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=1.0; total time=   1.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.8; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.8; total time=   1.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.8; total time=   1.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=1.0; total time=   1.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1.0; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1.0; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=0.8; total time=   1.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=0.8; total time=   1.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1.0; total time=   1.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=1.0; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=0.8; total time=   1.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.8; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=1.0; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.8; total time=   1.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=1.0; total time=   1.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=1.0; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=1.0; total time=   1.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=0.8; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=1.0; total time=   1.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=0.8; total time=   1.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.8; total time=   1.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=1.0; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=0.8; total time=   2.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=1.0; total time=   1.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=0.8; total time=   2.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=0.8; total time=   2.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=0.8; total time=   2.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=1.0; total time=   2.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=1.0; total time=   2.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=1.0; total time=   2.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=1.0; total time=   2.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=1.0; total time=   2.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=0.8; total time=   2.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=0.8; total time=   3.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=1.0; total time=   3.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=0.8; total time=   3.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=0.8; total time=   3.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=0.8; total time=   3.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=1.0; total time=   2.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=1.0; total time=   3.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=0.8; total time=   3.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=1.0; total time=   2.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=1.0; total time=   2.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=3, n_estimators=300, subsample=0.8; total time=   0.8s[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=3, n_estimators=300, subsample=0.8; total time=   0.8s\n",
      "\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=3, n_estimators=300, subsample=0.8; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=3, n_estimators=300, subsample=0.8; total time=   0.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=3, n_estimators=300, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=3, n_estimators=300, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=3, n_estimators=300, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=3, n_estimators=300, subsample=0.8; total time=   0.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=5, n_estimators=100, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=3, n_estimators=300, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=3, n_estimators=300, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=5, n_estimators=100, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=5, n_estimators=100, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=5, n_estimators=100, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=5, n_estimators=100, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=5, n_estimators=200, subsample=0.8; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=5, n_estimators=200, subsample=0.8; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=5, n_estimators=200, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=5, n_estimators=200, subsample=0.8; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=5, n_estimators=200, subsample=0.8; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=5, n_estimators=200, subsample=0.8; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=5, n_estimators=200, subsample=1.0; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=5, n_estimators=200, subsample=1.0; total time=   1.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=5, n_estimators=200, subsample=1.0; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=5, n_estimators=200, subsample=1.0; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=5, n_estimators=300, subsample=0.8; total time=   1.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=5, n_estimators=300, subsample=0.8; total time=   1.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=5, n_estimators=300, subsample=0.8; total time=   1.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=5, n_estimators=300, subsample=1.0; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=5, n_estimators=300, subsample=0.8; total time=   1.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=5, n_estimators=300, subsample=0.8; total time=   1.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=7, n_estimators=100, subsample=0.8; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=7, n_estimators=100, subsample=0.8; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=7, n_estimators=100, subsample=1.0; total time=   1.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=7, n_estimators=100, subsample=0.8; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=7, n_estimators=100, subsample=0.8; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=7, n_estimators=100, subsample=0.8; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=5, n_estimators=300, subsample=1.0; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=5, n_estimators=300, subsample=1.0; total time=   1.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=5, n_estimators=300, subsample=1.0; total time=   1.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=5, n_estimators=300, subsample=1.0; total time=   1.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=7, n_estimators=100, subsample=1.0; total time=   1.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=7, n_estimators=100, subsample=1.0; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=7, n_estimators=100, subsample=1.0; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=7, n_estimators=100, subsample=1.0; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=7, n_estimators=200, subsample=1.0; total time=   1.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=7, n_estimators=200, subsample=0.8; total time=   2.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=7, n_estimators=200, subsample=1.0; total time=   1.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=7, n_estimators=200, subsample=0.8; total time=   2.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=7, n_estimators=200, subsample=0.8; total time=   2.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=7, n_estimators=200, subsample=1.0; total time=   2.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=7, n_estimators=200, subsample=1.0; total time=   2.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=7, n_estimators=200, subsample=0.8; total time=   2.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=7, n_estimators=200, subsample=1.0; total time=   2.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=7, n_estimators=200, subsample=0.8; total time=   2.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=7, n_estimators=300, subsample=0.8; total time=   2.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=7, n_estimators=300, subsample=0.8; total time=   2.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=7, n_estimators=300, subsample=0.8; total time=   2.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=7, n_estimators=300, subsample=1.0; total time=   2.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=7, n_estimators=300, subsample=0.8; total time=   2.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=7, n_estimators=300, subsample=0.8; total time=   2.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=7, n_estimators=300, subsample=1.0; total time=   2.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=7, n_estimators=300, subsample=1.0; total time=   2.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=7, n_estimators=300, subsample=1.0; total time=   2.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=7, n_estimators=300, subsample=1.0; total time=   2.0s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "}\n",
       "\n",
       "#sk-container-id-2.light {\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: black;\n",
       "  --sklearn-color-background: white;\n",
       "  --sklearn-color-border-box: black;\n",
       "  --sklearn-color-icon: #696969;\n",
       "}\n",
       "\n",
       "#sk-container-id-2.dark {\n",
       "  --sklearn-color-text-on-default-background: white;\n",
       "  --sklearn-color-background: #111;\n",
       "  --sklearn-color-border-box: white;\n",
       "  --sklearn-color-icon: #878787;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: center;\n",
       "  justify-content: center;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"â¸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"â¾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-3) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  border: var(--sklearn-color-fitted-level-0) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-0);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  border: var(--sklearn-color-fitted-level-0) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-0);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table {\n",
       "    font-family: monospace;\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table summary::marker {\n",
       "    font-size: 0.7rem;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "    margin-top: 0;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       "/*\n",
       "    `table td`is set in notebook with right text-align.\n",
       "    We need to overwrite it.\n",
       "*/\n",
       ".estimator-table table td.param {\n",
       "    text-align: left;\n",
       "    position: relative;\n",
       "    padding: 0;\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left !important;\n",
       "}\n",
       "\n",
       ".user-set td.value {\n",
       "    color:rgb(255, 94, 0);\n",
       "    background-color: transparent;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left !important;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       "/*\n",
       "    Styles for parameter documentation links\n",
       "    We need styling for visited so jupyter doesn't overwrite it\n",
       "*/\n",
       "a.param-doc-link,\n",
       "a.param-doc-link:link,\n",
       "a.param-doc-link:visited {\n",
       "    text-decoration: underline dashed;\n",
       "    text-underline-offset: .3em;\n",
       "    color: inherit;\n",
       "    display: block;\n",
       "    padding: .5em;\n",
       "}\n",
       "\n",
       "/* \"hack\" to make the entire area of the cell containing the link clickable */\n",
       "a.param-doc-link::before {\n",
       "    position: absolute;\n",
       "    content: \"\";\n",
       "    inset: 0;\n",
       "}\n",
       "\n",
       ".param-doc-description {\n",
       "    display: none;\n",
       "    position: absolute;\n",
       "    z-index: 9999;\n",
       "    left: 0;\n",
       "    padding: .5ex;\n",
       "    margin-left: 1.5em;\n",
       "    color: var(--sklearn-color-text);\n",
       "    box-shadow: .3em .3em .4em #999;\n",
       "    width: max-content;\n",
       "    text-align: left;\n",
       "    max-height: 10em;\n",
       "    overflow-y: auto;\n",
       "\n",
       "    /* unfitted */\n",
       "    background: var(--sklearn-color-unfitted-level-0);\n",
       "    border: thin solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       "/* Fitted state for parameter tooltips */\n",
       ".fitted .param-doc-description {\n",
       "    /* fitted */\n",
       "    background: var(--sklearn-color-fitted-level-0);\n",
       "    border: thin solid var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".param-doc-link:hover .param-doc-description {\n",
       "    display: block;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                    callbacks=None, colsample_bylevel=None,\n",
       "                                    colsample_bynode=None,\n",
       "                                    colsample_bytree=None, device=None,\n",
       "                                    early_stopping_rounds=None,\n",
       "                                    enable_categorical=False, eval_metric=None,\n",
       "                                    feature_types=None, feature_weights=None,\n",
       "                                    gamma=None, grow_policy=None,\n",
       "                                    importance_type=None,\n",
       "                                    interaction_constraints=None...\n",
       "                                    max_depth=None, max_leaves=None,\n",
       "                                    min_child_weight=None, missing=nan,\n",
       "                                    monotone_constraints=None,\n",
       "                                    multi_strategy=None, n_estimators=None,\n",
       "                                    n_jobs=None, num_parallel_tree=None, ...),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;colsample_bytree&#x27;: [0.8, 1.0],\n",
       "                         &#x27;learning_rate&#x27;: [0.01, 0.1, 0.3],\n",
       "                         &#x27;max_depth&#x27;: [3, 5, 7],\n",
       "                         &#x27;n_estimators&#x27;: [100, 200, 300],\n",
       "                         &#x27;subsample&#x27;: [0.8, 1.0]},\n",
       "             scoring=&#x27;neg_mean_squared_error&#x27;, verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>GridSearchCV</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html\">?<span>Documentation for GridSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('estimator',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=estimator,-estimator%20object\">\n",
       "            estimator\n",
       "            <span class=\"param-doc-description\">estimator: estimator object<br><br>This is assumed to implement the scikit-learn estimator interface.<br>Either estimator needs to provide a ``score`` function,<br>or ``scoring`` must be passed.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">XGBRegressor(...ree=None, ...)</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('param_grid',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=param_grid,-dict%20or%20list%20of%20dictionaries\">\n",
       "            param_grid\n",
       "            <span class=\"param-doc-description\">param_grid: dict or list of dictionaries<br><br>Dictionary with parameters names (`str`) as keys and lists of<br>parameter settings to try as values, or a list of such<br>dictionaries, in which case the grids spanned by each dictionary<br>in the list are explored. This enables searching over any sequence<br>of parameter settings.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">{&#x27;colsample_bytree&#x27;: [0.8, 1.0], &#x27;learning_rate&#x27;: [0.01, 0.1, ...], &#x27;max_depth&#x27;: [3, 5, ...], &#x27;n_estimators&#x27;: [100, 200, ...], ...}</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('scoring',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=scoring,-str%2C%20callable%2C%20list%2C%20tuple%20or%20dict%2C%20default%3DNone\">\n",
       "            scoring\n",
       "            <span class=\"param-doc-description\">scoring: str, callable, list, tuple or dict, default=None<br><br>Strategy to evaluate the performance of the cross-validated model on<br>the test set.<br><br>If `scoring` represents a single score, one can use:<br><br>- a single string (see :ref:`scoring_string_names`);<br>- a callable (see :ref:`scoring_callable`) that returns a single value;<br>- `None`, the `estimator`'s<br>  :ref:`default evaluation criterion <scoring_api_overview>` is used.<br><br>If `scoring` represents multiple scores, one can use:<br><br>- a list or tuple of unique strings;<br>- a callable returning a dictionary where the keys are the metric<br>  names and the values are the metric scores;<br>- a dictionary with metric names as keys and callables as values.<br><br>See :ref:`multimetric_grid_search` for an example.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">&#x27;neg_mean_squared_error&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_jobs',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=n_jobs,-int%2C%20default%3DNone\">\n",
       "            n_jobs\n",
       "            <span class=\"param-doc-description\">n_jobs: int, default=None<br><br>Number of jobs to run in parallel.<br>``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.<br>``-1`` means using all processors. See :term:`Glossary <n_jobs>`<br>for more details.<br><br>.. versionchanged:: v0.20<br>   `n_jobs` default changed from 1 to None</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">-1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('refit',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=refit,-bool%2C%20str%2C%20or%20callable%2C%20default%3DTrue\">\n",
       "            refit\n",
       "            <span class=\"param-doc-description\">refit: bool, str, or callable, default=True<br><br>Refit an estimator using the best found parameters on the whole<br>dataset.<br><br>For multiple metric evaluation, this needs to be a `str` denoting the<br>scorer that would be used to find the best parameters for refitting<br>the estimator at the end.<br><br>Where there are considerations other than maximum score in<br>choosing a best estimator, ``refit`` can be set to a function which<br>returns the selected ``best_index_`` given ``cv_results_``. In that<br>case, the ``best_estimator_`` and ``best_params_`` will be set<br>according to the returned ``best_index_`` while the ``best_score_``<br>attribute will not be available.<br><br>The refitted estimator is made available at the ``best_estimator_``<br>attribute and permits using ``predict`` directly on this<br>``GridSearchCV`` instance.<br><br>Also for multiple metric evaluation, the attributes ``best_index_``,<br>``best_score_`` and ``best_params_`` will only be available if<br>``refit`` is set and all of them will be determined w.r.t this specific<br>scorer.<br><br>See ``scoring`` parameter to know more about multiple metric<br>evaluation.<br><br>See :ref:`sphx_glr_auto_examples_model_selection_plot_grid_search_digits.py`<br>to see how to design a custom selection strategy using a callable<br>via `refit`.<br><br>See :ref:`this example<br><sphx_glr_auto_examples_model_selection_plot_grid_search_refit_callable.py>`<br>for an example of how to use ``refit=callable`` to balance model<br>complexity and cross-validated score.<br><br>.. versionchanged:: 0.20<br>    Support for callable added.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('cv',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=cv,-int%2C%20cross-validation%20generator%20or%20an%20iterable%2C%20default%3DNone\">\n",
       "            cv\n",
       "            <span class=\"param-doc-description\">cv: int, cross-validation generator or an iterable, default=None<br><br>Determines the cross-validation splitting strategy.<br>Possible inputs for cv are:<br><br>- None, to use the default 5-fold cross validation,<br>- integer, to specify the number of folds in a `(Stratified)KFold`,<br>- :term:`CV splitter`,<br>- An iterable yielding (train, test) splits as arrays of indices.<br><br>For integer/None inputs, if the estimator is a classifier and ``y`` is<br>either binary or multiclass, :class:`StratifiedKFold` is used. In all<br>other cases, :class:`KFold` is used. These splitters are instantiated<br>with `shuffle=False` so the splits will be the same across calls.<br><br>Refer :ref:`User Guide <cross_validation>` for the various<br>cross-validation strategies that can be used here.<br><br>.. versionchanged:: 0.22<br>    ``cv`` default value if None changed from 3-fold to 5-fold.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">5</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbose',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=verbose,-int\">\n",
       "            verbose\n",
       "            <span class=\"param-doc-description\">verbose: int<br><br>Controls the verbosity: the higher, the more messages.<br><br>- >1 : the computation time for each fold and parameter candidate is<br>  displayed;<br>- >2 : the score is also displayed;<br>- >3 : the fold and candidate parameter indexes are also displayed<br>  together with the starting time of the computation.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">2</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('pre_dispatch',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=pre_dispatch,-int%2C%20or%20str%2C%20default%3D%272%2An_jobs%27\">\n",
       "            pre_dispatch\n",
       "            <span class=\"param-doc-description\">pre_dispatch: int, or str, default='2*n_jobs'<br><br>Controls the number of jobs that get dispatched during parallel<br>execution. Reducing this number can be useful to avoid an<br>explosion of memory consumption when more jobs get dispatched<br>than CPUs can process. This parameter can be:<br><br>- None, in which case all the jobs are immediately created and spawned. Use<br>  this for lightweight and fast-running jobs, to avoid delays due to on-demand<br>  spawning of the jobs<br>- An int, giving the exact number of total jobs that are spawned<br>- A str, giving an expression as a function of n_jobs, as in '2*n_jobs'</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">&#x27;2*n_jobs&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('error_score',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=error_score,-%27raise%27%20or%20numeric%2C%20default%3Dnp.nan\">\n",
       "            error_score\n",
       "            <span class=\"param-doc-description\">error_score: 'raise' or numeric, default=np.nan<br><br>Value to assign to the score if an error occurs in estimator fitting.<br>If set to 'raise', the error is raised. If a numeric value is given,<br>FitFailedWarning is raised. This parameter does not affect the refit<br>step, which will always raise the error.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">nan</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('return_train_score',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=return_train_score,-bool%2C%20default%3DFalse\">\n",
       "            return_train_score\n",
       "            <span class=\"param-doc-description\">return_train_score: bool, default=False<br><br>If ``False``, the ``cv_results_`` attribute will not include training<br>scores.<br>Computing training scores is used to get insights on how different<br>parameter settings impact the overfitting/underfitting trade-off.<br>However computing the scores on the training set can be computationally<br>expensive and is not strictly required to select the parameters that<br>yield the best generalization performance.<br><br>.. versionadded:: 0.19<br><br>.. versionchanged:: 0.21<br>    Default value was changed from ``True`` to ``False``</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>best_estimator_: XGBRegressor</div></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"best_estimator___\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=0.8, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             feature_weights=None, gamma=None, grow_policy=None,\n",
       "             importance_type=None, interaction_constraints=None,\n",
       "             learning_rate=0.1, max_bin=None, max_cat_threshold=None,\n",
       "             max_cat_to_onehot=None, max_delta_step=None, max_depth=7,\n",
       "             max_leaves=None, min_child_weight=None, missing=nan,\n",
       "             monotone_constraints=None, multi_strategy=None, n_estimators=300,\n",
       "             n_jobs=None, num_parallel_tree=None, ...)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>XGBRegressor</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor\">?<span>Documentation for XGBRegressor</span></a></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"best_estimator___\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('objective',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=objective,-str%20%7C%20xgboost.sklearn._SklObjWProto%20%7C%20typing.Callable%5B%5Btyping.Any%2C%20typing.Any%5D%2C%20typing.Tuple%5Bnumpy.ndarray%2C%20numpy.ndarray%5D%5D%20%7C%20None\">\n",
       "            objective\n",
       "            <span class=\"param-doc-description\">objective: str | xgboost.sklearn._SklObjWProto | typing.Callable[[typing.Any, typing.Any], typing.Tuple[numpy.ndarray, numpy.ndarray]] | None<br><br>Specify the learning task and the corresponding learning objective or a custom<br>objective function to be used.<br><br>For custom objective, see :doc:`/tutorials/custom_metric_obj` and<br>:ref:`custom-obj-metric` for more information, along with the end note for<br>function signatures.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">&#x27;reg:squarederror&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('base_score',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=base_score,-float%20%7C%20typing.List%5Bfloat%5D%20%7C%20None\">\n",
       "            base_score\n",
       "            <span class=\"param-doc-description\">base_score: float | typing.List[float] | None<br><br>The initial prediction score of all instances, global bias.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('booster',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">booster</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('callbacks',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=callbacks,-typing.List%5Bxgboost.callback.TrainingCallback%5D%20%7C%20None\">\n",
       "            callbacks\n",
       "            <span class=\"param-doc-description\">callbacks: typing.List[xgboost.callback.TrainingCallback] | None<br><br>List of callback functions that are applied at end of each iteration.<br>It is possible to use predefined callbacks by using<br>:ref:`Callback API <callback_api>`.<br><br>.. note::<br><br>   States in callback are not preserved during training, which means callback<br>   objects can not be reused for multiple training sessions without<br>   reinitialization or deepcopy.<br><br>.. code-block:: python<br><br>    for params in parameters_grid:<br>        # be sure to (re)initialize the callbacks before each run<br>        callbacks = [xgb.callback.LearningRateScheduler(custom_rates)]<br>        reg = xgboost.XGBRegressor(**params, callbacks=callbacks)<br>        reg.fit(X, y)</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('colsample_bylevel',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=colsample_bylevel,-float%20%7C%20None\">\n",
       "            colsample_bylevel\n",
       "            <span class=\"param-doc-description\">colsample_bylevel: float | None<br><br>Subsample ratio of columns for each level.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('colsample_bynode',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=colsample_bynode,-float%20%7C%20None\">\n",
       "            colsample_bynode\n",
       "            <span class=\"param-doc-description\">colsample_bynode: float | None<br><br>Subsample ratio of columns for each split.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('colsample_bytree',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=colsample_bytree,-float%20%7C%20None\">\n",
       "            colsample_bytree\n",
       "            <span class=\"param-doc-description\">colsample_bytree: float | None<br><br>Subsample ratio of columns when constructing each tree.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0.8</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('device',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=device,-str%20%7C%20None\">\n",
       "            device\n",
       "            <span class=\"param-doc-description\">device: str | None<br><br>.. versionadded:: 2.0.0<br><br>Device ordinal, available options are `cpu`, `cuda`, and `gpu`.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('early_stopping_rounds',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=early_stopping_rounds,-int%20%7C%20None\">\n",
       "            early_stopping_rounds\n",
       "            <span class=\"param-doc-description\">early_stopping_rounds: int | None<br><br>.. versionadded:: 1.6.0<br><br>- Activates early stopping. Validation metric needs to improve at least once in<br>  every **early_stopping_rounds** round(s) to continue training.  Requires at<br>  least one item in **eval_set** in :py:meth:`fit`.<br><br>- If early stopping occurs, the model will have two additional attributes:<br>  :py:attr:`best_score` and :py:attr:`best_iteration`. These are used by the<br>  :py:meth:`predict` and :py:meth:`apply` methods to determine the optimal<br>  number of trees during inference. If users want to access the full model<br>  (including trees built after early stopping), they can specify the<br>  `iteration_range` in these inference methods. In addition, other utilities<br>  like model plotting can also use the entire model.<br><br>- If you prefer to discard the trees after `best_iteration`, consider using the<br>  callback function :py:class:`xgboost.callback.EarlyStopping`.<br><br>- If there's more than one item in **eval_set**, the last entry will be used for<br>  early stopping.  If there's more than one metric in **eval_metric**, the last<br>  metric will be used for early stopping.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('enable_categorical',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=enable_categorical,-bool\">\n",
       "            enable_categorical\n",
       "            <span class=\"param-doc-description\">enable_categorical: bool<br><br>See the same parameter of :py:class:`DMatrix` for details.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('eval_metric',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=eval_metric,-str%20%7C%20typing.List%5Bstr%20%7C%20typing.Callable%5D%20%7C%20typing.Callable%20%7C%20None\">\n",
       "            eval_metric\n",
       "            <span class=\"param-doc-description\">eval_metric: str | typing.List[str | typing.Callable] | typing.Callable | None<br><br>.. versionadded:: 1.6.0<br><br>Metric used for monitoring the training result and early stopping.  It can be a<br>string or list of strings as names of predefined metric in XGBoost (See<br>:doc:`/parameter`), one of the metrics in :py:mod:`sklearn.metrics`, or any<br>other user defined metric that looks like `sklearn.metrics`.<br><br>If custom objective is also provided, then custom metric should implement the<br>corresponding reverse link function.<br><br>Unlike the `scoring` parameter commonly used in scikit-learn, when a callable<br>object is provided, it's assumed to be a cost function and by default XGBoost<br>will minimize the result during early stopping.<br><br>For advanced usage on Early stopping like directly choosing to maximize instead<br>of minimize, see :py:obj:`xgboost.callback.EarlyStopping`.<br><br>See :doc:`/tutorials/custom_metric_obj` and :ref:`custom-obj-metric` for more<br>information.<br><br>.. code-block:: python<br><br>    from sklearn.datasets import load_diabetes<br>    from sklearn.metrics import mean_absolute_error<br>    X, y = load_diabetes(return_X_y=True)<br>    reg = xgb.XGBRegressor(<br>        tree_method=\"hist\",<br>        eval_metric=mean_absolute_error,<br>    )<br>    reg.fit(X, y, eval_set=[(X, y)])</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('feature_types',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=feature_types,-typing.Sequence%5Bstr%5D%20%7C%20None\">\n",
       "            feature_types\n",
       "            <span class=\"param-doc-description\">feature_types: typing.Sequence[str] | None<br><br>.. versionadded:: 1.7.0<br><br>Used for specifying feature types without constructing a dataframe. See<br>the :py:class:`DMatrix` for details.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('feature_weights',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=feature_weights,-Optional%5BArrayLike%5D\">\n",
       "            feature_weights\n",
       "            <span class=\"param-doc-description\">feature_weights: Optional[ArrayLike]<br><br>Weight for each feature, defines the probability of each feature being selected<br>when colsample is being used.  All values must be greater than 0, otherwise a<br>`ValueError` is thrown.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('gamma',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=gamma,-float%20%7C%20None\">\n",
       "            gamma\n",
       "            <span class=\"param-doc-description\">gamma: float | None<br><br>(min_split_loss) Minimum loss reduction required to make a further partition on<br>a leaf node of the tree.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('grow_policy',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=grow_policy,-str%20%7C%20None\">\n",
       "            grow_policy\n",
       "            <span class=\"param-doc-description\">grow_policy: str | None<br><br>Tree growing policy.<br><br>- depthwise: Favors splitting at nodes closest to the node,<br>- lossguide: Favors splitting at nodes with highest loss change.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('importance_type',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">importance_type</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('interaction_constraints',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=interaction_constraints,-str%20%7C%20typing.List%5Btyping.Tuple%5Bstr%5D%5D%20%7C%20None\">\n",
       "            interaction_constraints\n",
       "            <span class=\"param-doc-description\">interaction_constraints: str | typing.List[typing.Tuple[str]] | None<br><br>Constraints for interaction representing permitted interactions.  The<br>constraints must be specified in the form of a nested list, e.g. ``[[0, 1], [2,<br>3, 4]]``, where each inner list is a group of indices of features that are<br>allowed to interact with each other.  See :doc:`tutorial<br></tutorials/feature_interaction_constraint>` for more information</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('learning_rate',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=learning_rate,-float%20%7C%20None\">\n",
       "            learning_rate\n",
       "            <span class=\"param-doc-description\">learning_rate: float | None<br><br>Boosting learning rate (xgb's \"eta\")</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0.1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_bin',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=max_bin,-int%20%7C%20None\">\n",
       "            max_bin\n",
       "            <span class=\"param-doc-description\">max_bin: int | None<br><br>If using histogram-based algorithm, maximum number of bins per feature</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_cat_threshold',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=max_cat_threshold,-int%20%7C%20None\">\n",
       "            max_cat_threshold\n",
       "            <span class=\"param-doc-description\">max_cat_threshold: int | None<br><br>.. versionadded:: 1.7.0<br><br>.. note:: This parameter is experimental<br><br>Maximum number of categories considered for each split. Used only by<br>partition-based splits for preventing over-fitting. Also, `enable_categorical`<br>needs to be set to have categorical feature support. See :doc:`Categorical Data<br></tutorials/categorical>` and :ref:`cat-param` for details.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_cat_to_onehot',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=max_cat_to_onehot,-Optional%5Bint%5D\">\n",
       "            max_cat_to_onehot\n",
       "            <span class=\"param-doc-description\">max_cat_to_onehot: Optional[int]<br><br>.. versionadded:: 1.6.0<br><br>.. note:: This parameter is experimental<br><br>A threshold for deciding whether XGBoost should use one-hot encoding based split<br>for categorical data.  When number of categories is lesser than the threshold<br>then one-hot encoding is chosen, otherwise the categories will be partitioned<br>into children nodes. Also, `enable_categorical` needs to be set to have<br>categorical feature support. See :doc:`Categorical Data<br></tutorials/categorical>` and :ref:`cat-param` for details.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_delta_step',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=max_delta_step,-float%20%7C%20None\">\n",
       "            max_delta_step\n",
       "            <span class=\"param-doc-description\">max_delta_step: float | None<br><br>Maximum delta step we allow each tree's weight estimation to be.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_depth',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=max_depth,-%20int%20%7C%20None\">\n",
       "            max_depth\n",
       "            <span class=\"param-doc-description\">max_depth:  int | None<br><br>Maximum tree depth for base learners.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">7</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_leaves',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=max_leaves,-int%20%7C%20None\">\n",
       "            max_leaves\n",
       "            <span class=\"param-doc-description\">max_leaves: int | None<br><br>Maximum number of leaves; 0 indicates no limit.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_child_weight',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=min_child_weight,-float%20%7C%20None\">\n",
       "            min_child_weight\n",
       "            <span class=\"param-doc-description\">min_child_weight: float | None<br><br>Minimum sum of instance weight(hessian) needed in a child.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('missing',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=missing,-float\">\n",
       "            missing\n",
       "            <span class=\"param-doc-description\">missing: float<br><br>Value in the data which needs to be present as a missing value. Default to<br>:py:data:`numpy.nan`.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">nan</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('monotone_constraints',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=monotone_constraints,-typing.Dict%5Bstr%2C%20int%5D%20%7C%20str%20%7C%20None\">\n",
       "            monotone_constraints\n",
       "            <span class=\"param-doc-description\">monotone_constraints: typing.Dict[str, int] | str | None<br><br>Constraint of variable monotonicity.  See :doc:`tutorial </tutorials/monotonic>`<br>for more information.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('multi_strategy',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=multi_strategy,-str%20%7C%20None\">\n",
       "            multi_strategy\n",
       "            <span class=\"param-doc-description\">multi_strategy: str | None<br><br>.. versionadded:: 2.0.0<br><br>.. note:: This parameter is working-in-progress.<br><br>The strategy used for training multi-target models, including multi-target<br>regression and multi-class classification. See :doc:`/tutorials/multioutput` for<br>more information.<br><br>- ``one_output_per_tree``: One model for each target.<br>- ``multi_output_tree``:  Use multi-target trees.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_estimators',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=n_estimators,-int%20%7C%20None\">\n",
       "            n_estimators\n",
       "            <span class=\"param-doc-description\">n_estimators: int | None<br><br>Number of gradient boosted trees.  Equivalent to number of boosting<br>rounds.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">300</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_jobs',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=n_jobs,-int%20%7C%20None\">\n",
       "            n_jobs\n",
       "            <span class=\"param-doc-description\">n_jobs: int | None<br><br>Number of parallel threads used to run xgboost.  When used with other<br>Scikit-Learn algorithms like grid search, you may choose which algorithm to<br>parallelize and balance the threads.  Creating thread contention will<br>significantly slow down both algorithms.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('num_parallel_tree',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">num_parallel_tree</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('random_state',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=random_state,-numpy.random.mtrand.RandomState%20%7C%20numpy.random._generator.Generator%20%7C%20int%20%7C%20None\">\n",
       "            random_state\n",
       "            <span class=\"param-doc-description\">random_state: numpy.random.mtrand.RandomState | numpy.random._generator.Generator | int | None<br><br>Random number seed.<br><br>.. note::<br><br>   Using gblinear booster with shotgun updater is nondeterministic as<br>   it uses Hogwild algorithm.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">5</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('reg_alpha',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=reg_alpha,-float%20%7C%20None\">\n",
       "            reg_alpha\n",
       "            <span class=\"param-doc-description\">reg_alpha: float | None<br><br>L1 regularization term on weights (xgb's alpha).</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('reg_lambda',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=reg_lambda,-float%20%7C%20None\">\n",
       "            reg_lambda\n",
       "            <span class=\"param-doc-description\">reg_lambda: float | None<br><br>L2 regularization term on weights (xgb's lambda).</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('sampling_method',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=sampling_method,-str%20%7C%20None\">\n",
       "            sampling_method\n",
       "            <span class=\"param-doc-description\">sampling_method: str | None<br><br>Sampling method. Used only by the GPU version of ``hist`` tree method.<br><br>- ``uniform``: Select random training instances uniformly.<br>- ``gradient_based``: Select random training instances with higher probability<br>    when the gradient and hessian are larger. (cf. CatBoost)</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('scale_pos_weight',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=scale_pos_weight,-float%20%7C%20None\">\n",
       "            scale_pos_weight\n",
       "            <span class=\"param-doc-description\">scale_pos_weight: float | None<br><br>Balancing of positive and negative weights.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('subsample',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=subsample,-float%20%7C%20None\">\n",
       "            subsample\n",
       "            <span class=\"param-doc-description\">subsample: float | None<br><br>Subsample ratio of the training instance.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0.8</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('tree_method',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=tree_method,-str%20%7C%20None\">\n",
       "            tree_method\n",
       "            <span class=\"param-doc-description\">tree_method: str | None<br><br>Specify which tree method to use.  Default to auto.  If this parameter is set to<br>default, XGBoost will choose the most conservative option available.  It's<br>recommended to study this option from the parameters document :doc:`tree method<br></treemethod>`</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('validate_parameters',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=validate_parameters,-bool%20%7C%20None\">\n",
       "            validate_parameters\n",
       "            <span class=\"param-doc-description\">validate_parameters: bool | None<br><br>Give warnings for unknown parameter.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbosity',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=verbosity,-int%20%7C%20None\">\n",
       "            verbosity\n",
       "            <span class=\"param-doc-description\">verbosity: int | None<br><br>The degree of verbosity. Valid values are 0 (silent) - 3 (debug).</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div></div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.copy-paste-icon').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling\n",
       "        .textContent.trim().split(' ')[0];\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "\n",
       "\n",
       "/**\n",
       " * Adapted from Skrub\n",
       " * https://github.com/skrub-data/skrub/blob/403466d1d5d4dc76a7ef569b3f8228db59a31dc3/skrub/_reporting/_data/templates/report.js#L789\n",
       " * @returns \"light\" or \"dark\"\n",
       " */\n",
       "function detectTheme(element) {\n",
       "    const body = document.querySelector('body');\n",
       "\n",
       "    // Check VSCode theme\n",
       "    const themeKindAttr = body.getAttribute('data-vscode-theme-kind');\n",
       "    const themeNameAttr = body.getAttribute('data-vscode-theme-name');\n",
       "\n",
       "    if (themeKindAttr && themeNameAttr) {\n",
       "        const themeKind = themeKindAttr.toLowerCase();\n",
       "        const themeName = themeNameAttr.toLowerCase();\n",
       "\n",
       "        if (themeKind.includes(\"dark\") || themeName.includes(\"dark\")) {\n",
       "            return \"dark\";\n",
       "        }\n",
       "        if (themeKind.includes(\"light\") || themeName.includes(\"light\")) {\n",
       "            return \"light\";\n",
       "        }\n",
       "    }\n",
       "\n",
       "    // Check Jupyter theme\n",
       "    if (body.getAttribute('data-jp-theme-light') === 'false') {\n",
       "        return 'dark';\n",
       "    } else if (body.getAttribute('data-jp-theme-light') === 'true') {\n",
       "        return 'light';\n",
       "    }\n",
       "\n",
       "    // Guess based on a parent element's color\n",
       "    const color = window.getComputedStyle(element.parentNode, null).getPropertyValue('color');\n",
       "    const match = color.match(/^rgb\\s*\\(\\s*(\\d+)\\s*,\\s*(\\d+)\\s*,\\s*(\\d+)\\s*\\)\\s*$/i);\n",
       "    if (match) {\n",
       "        const [r, g, b] = [\n",
       "            parseFloat(match[1]),\n",
       "            parseFloat(match[2]),\n",
       "            parseFloat(match[3])\n",
       "        ];\n",
       "\n",
       "        // https://en.wikipedia.org/wiki/HSL_and_HSV#Lightness\n",
       "        const luma = 0.299 * r + 0.587 * g + 0.114 * b;\n",
       "\n",
       "        if (luma > 180) {\n",
       "            // If the text is very bright we have a dark theme\n",
       "            return 'dark';\n",
       "        }\n",
       "        if (luma < 75) {\n",
       "            // If the text is very dark we have a light theme\n",
       "            return 'light';\n",
       "        }\n",
       "        // Otherwise fall back to the next heuristic.\n",
       "    }\n",
       "\n",
       "    // Fallback to system preference\n",
       "    return window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'light';\n",
       "}\n",
       "\n",
       "\n",
       "function forceTheme(elementId) {\n",
       "    const estimatorElement = document.querySelector(`#${elementId}`);\n",
       "    if (estimatorElement === null) {\n",
       "        console.error(`Element with id ${elementId} not found.`);\n",
       "    } else {\n",
       "        const theme = detectTheme(estimatorElement);\n",
       "        estimatorElement.classList.add(theme);\n",
       "    }\n",
       "}\n",
       "\n",
       "forceTheme('sk-container-id-2');</script></body>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                    callbacks=None, colsample_bylevel=None,\n",
       "                                    colsample_bynode=None,\n",
       "                                    colsample_bytree=None, device=None,\n",
       "                                    early_stopping_rounds=None,\n",
       "                                    enable_categorical=False, eval_metric=None,\n",
       "                                    feature_types=None, feature_weights=None,\n",
       "                                    gamma=None, grow_policy=None,\n",
       "                                    importance_type=None,\n",
       "                                    interaction_constraints=None...\n",
       "                                    max_depth=None, max_leaves=None,\n",
       "                                    min_child_weight=None, missing=nan,\n",
       "                                    monotone_constraints=None,\n",
       "                                    multi_strategy=None, n_estimators=None,\n",
       "                                    n_jobs=None, num_parallel_tree=None, ...),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'colsample_bytree': [0.8, 1.0],\n",
       "                         'learning_rate': [0.01, 0.1, 0.3],\n",
       "                         'max_depth': [3, 5, 7],\n",
       "                         'n_estimators': [100, 200, 300],\n",
       "                         'subsample': [0.8, 1.0]},\n",
       "             scoring='neg_mean_squared_error', verbose=2)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## use GridSearchCV search\n",
    "X_train, X_test, y_train, y_test = train_test_split(king_hs_X_clean[best_features], king_hs_y, random_state=random_state, test_size=0.2)\n",
    "\n",
    "# Define the XGBoost model\n",
    "xgb_model = XGBRegressor(random_state=random_state, objective='reg:squarederror')\n",
    "\n",
    "# Define parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.01, 0.1, 0.3],\n",
    "    'subsample': [0.8, 1.0],\n",
    "    'colsample_bytree': [0.8, 1.0]\n",
    "}\n",
    "\n",
    "# Create GridSearchCV\n",
    "grid_search = GridSearchCV( ##RandomizedSearchCV , GridSearchCV\n",
    "    estimator=xgb_model,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,\n",
    "    scoring='neg_mean_squared_error',  # or 'r2', 'neg_mean_absolute_error'\n",
    "    verbose=2,\n",
    "    n_jobs=-1  # Use all processors\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "print(\"Starting Grid Search...\")\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "dccf96fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "BEST PARAMETERS:\n",
      "======================================================================\n",
      "{'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 300, 'subsample': 0.8}\n",
      "\n",
      "======================================================================\n",
      "BEST SCORE (CV):\n",
      "======================================================================\n",
      "Best CV Score: 9448263884.8000\n"
     ]
    }
   ],
   "source": [
    "# Best parameters and score\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"BEST PARAMETERS:\")\n",
    "print(\"=\"*70)\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"BEST SCORE (CV):\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Best CV Score: {-grid_search.best_score_:.4f}\")  # Negative because of neg_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e473c6fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>r2_score</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td>0.985048</td>\n",
       "      <td>38825.41683</td>\n",
       "      <td>28170.755859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>0.916756</td>\n",
       "      <td>91873.29292</td>\n",
       "      <td>58558.921875</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       r2_score         RMSE           MAE\n",
       "train  0.985048  38825.41683  28170.755859\n",
       "test   0.916756  91873.29292  58558.921875"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the best model\n",
    "best_xgb = grid_search.best_estimator_\n",
    "\n",
    "### On train set\n",
    "y_pred_tr = best_xgb.predict(X_train)\n",
    "eval_tr = pd.DataFrame([r2_score(y_train, y_pred_tr), np.sqrt(mean_squared_error(y_train, y_pred_tr)), mean_absolute_error(y_train, y_pred_tr)], index=['r2_score', 'RMSE', 'MAE']).T\n",
    "\n",
    "# Evaluate on test set\n",
    "y_pred = best_xgb.predict(X_test)\n",
    "eval_ts = pd.DataFrame([r2_score(y_test, y_pred), np.sqrt(mean_squared_error(y_test, y_pred)), mean_absolute_error(y_test, y_pred)], index=['r2_score', 'RMSE', 'MAE']).T\n",
    "\n",
    "eval = pd.concat([eval_tr,eval_ts])\n",
    "eval.index=['train', 'test']\n",
    "eval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab604535",
   "metadata": {},
   "source": [
    "### With scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f61e4d1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Grid Search...\n",
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.5s[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.5s\n",
      "\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=0.8; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=0.8; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=0.8; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=0.8; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=0.8; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.8; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.8; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.8; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.8; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.8; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.8; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.8; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.8; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.8; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=1.0; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.8; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=0.8; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=0.8; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=0.8; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=0.8; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=1.0; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=0.8; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=1.0; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=1.0; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=1.0; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=1.0; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=1.0; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=1.0; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=1.0; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=1.0; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=0.8; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=0.8; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=0.8; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=0.8; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=1.0; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=0.8; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=1.0; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=1.0; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=1.0; total time=   2.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=1.0; total time=   2.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.3s[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.2s\n",
      "\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=0.8; total time=   3.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=0.8; total time=   3.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=0.8; total time=   3.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=0.8; total time=   3.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=0.8; total time=   3.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=1.0; total time=   3.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=0.8; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=0.8; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=0.8; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=0.8; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=0.8; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=1.0; total time=   0.5s[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=1.0; total time=   0.5s\n",
      "\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=1.0; total time=   2.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=1.0; total time=   2.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=1.0; total time=   3.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.8; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.8; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.8; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.8; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=1.0; total time=   3.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.8; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1.0; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1.0; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.8; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.8; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=0.8; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.8; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.8; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=1.0; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=1.0; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.8; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=1.0; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=1.0; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=0.8; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=0.8; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=1.0; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=0.8; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=0.8; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=1.0; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=1.0; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=1.0; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=1.0; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=1.0; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=0.8; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=1.0; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=0.8; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=1.0; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=0.8; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=0.8; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=1.0; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=1.0; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=0.8; total time=   2.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=1.0; total time=   2.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=1.0; total time=  -2.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=1.0; total time=  -2.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=1.0; total time=  -2.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=1.0; total time=  -2.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=0.8; total time=  -0.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=3, n_estimators=200, subsample=0.8; total time=  -2.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=0.8; total time=  -0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=0.8; total time=  -0.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=3, n_estimators=200, subsample=0.8; total time=   5.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=3, n_estimators=200, subsample=0.8; total time=   3.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=0.8; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=1.0; total time=  -0.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=0.8; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=3, n_estimators=300, subsample=0.8; total time=  -4.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=3, n_estimators=300, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=3, n_estimators=300, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=3, n_estimators=300, subsample=0.8; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=3, n_estimators=300, subsample=0.8; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=3, n_estimators=300, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=3, n_estimators=300, subsample=0.8; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=3, n_estimators=300, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=1.0; total time=  -0.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=1.0; total time=  -0.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=3, n_estimators=300, subsample=0.8; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=1.0; total time=  -0.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=5, n_estimators=100, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=5, n_estimators=100, subsample=1.0; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=5, n_estimators=100, subsample=1.0; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=5, n_estimators=100, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=3, n_estimators=300, subsample=1.0; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=5, n_estimators=100, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=5, n_estimators=200, subsample=0.8; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=5, n_estimators=200, subsample=0.8; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=5, n_estimators=200, subsample=0.8; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=5, n_estimators=200, subsample=1.0; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=5, n_estimators=200, subsample=0.8; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=5, n_estimators=200, subsample=1.0; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=7, n_estimators=100, subsample=0.8; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=5, n_estimators=200, subsample=0.8; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=5, n_estimators=300, subsample=1.0; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=5, n_estimators=300, subsample=1.0; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=5, n_estimators=300, subsample=0.8; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=7, n_estimators=100, subsample=0.8; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=5, n_estimators=300, subsample=0.8; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=5, n_estimators=300, subsample=0.8; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=7, n_estimators=100, subsample=1.0; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=7, n_estimators=100, subsample=1.0; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=7, n_estimators=100, subsample=0.8; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=5, n_estimators=200, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=5, n_estimators=200, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=5, n_estimators=200, subsample=1.0; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=7, n_estimators=100, subsample=0.8; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=7, n_estimators=100, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=5, n_estimators=300, subsample=1.0; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=7, n_estimators=200, subsample=0.8; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=7, n_estimators=100, subsample=0.8; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=7, n_estimators=200, subsample=0.8; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=5, n_estimators=300, subsample=1.0; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=5, n_estimators=300, subsample=0.8; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=7, n_estimators=100, subsample=1.0; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=5, n_estimators=300, subsample=1.0; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=7, n_estimators=100, subsample=1.0; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=5, n_estimators=300, subsample=0.8; total time=   1.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=7, n_estimators=200, subsample=0.8; total time=   2.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=7, n_estimators=200, subsample=1.0; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=7, n_estimators=200, subsample=1.0; total time=   1.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=7, n_estimators=200, subsample=0.8; total time=   1.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=7, n_estimators=200, subsample=0.8; total time=   1.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=7, n_estimators=300, subsample=0.8; total time=   2.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=7, n_estimators=300, subsample=0.8; total time=   2.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=0.8; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=7, n_estimators=300, subsample=1.0; total time=   2.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=0.8; total time=   0.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=7, n_estimators=200, subsample=1.0; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=7, n_estimators=200, subsample=1.0; total time=   1.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=0.8; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=0.8; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=1.0; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=7, n_estimators=300, subsample=0.8; total time=   2.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=0.8; total time=   1.2s[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=7, n_estimators=200, subsample=1.0; total time=   1.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=1.0; total time=   0.9s\n",
      "\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=7, n_estimators=300, subsample=1.0; total time=   3.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=1.0; total time=   1.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=1.0; total time=   1.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.8; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.8; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.8; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.8; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.8; total time=   1.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=7, n_estimators=300, subsample=0.8; total time=   2.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0; total time=   1.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=7, n_estimators=300, subsample=1.0; total time=   2.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=7, n_estimators=300, subsample=0.8; total time=   3.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=7, n_estimators=300, subsample=1.0; total time=   2.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.8; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=7, n_estimators=300, subsample=1.0; total time=   3.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.8; total time=   1.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.8; total time=   1.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=1.0; total time=   1.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=1.0; total time=   1.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.8; total time=   1.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=1.0; total time=   1.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.8; total time=   1.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=0.8; total time=   1.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=0.8; total time=   1.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=1.0; total time=   1.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=0.8; total time=   1.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=0.8; total time=   1.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=1.0; total time=   2.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=0.8; total time=   1.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=1.0; total time=   1.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=1.0; total time=   1.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=1.0; total time=   1.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=1.0; total time=   1.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=1.0; total time=   1.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=0.8; total time=   2.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=0.8; total time=   2.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=0.8; total time=   2.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=0.8; total time=   2.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=1.0; total time=   2.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=0.8; total time=   2.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=1.0; total time=   2.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=1.0; total time=   2.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=1.0; total time=   3.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=1.0; total time=   3.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=0.8; total time=   4.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=0.8; total time=   4.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.6s[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.5s\n",
      "\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=0.8; total time=   3.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=0.8; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=0.8; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=0.8; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=1.0; total time=   4.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=0.8; total time=   4.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=0.8; total time=   0.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=0.8; total time=   0.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=0.8; total time=   4.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=1.0; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=1.0; total time=   1.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=1.0; total time=   1.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=1.0; total time=   3.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=1.0; total time=   3.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=1.0; total time=   4.0s[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=1.0; total time=   0.9s\n",
      "\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=1.0; total time=   3.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.8; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.8; total time=   1.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.8; total time=   1.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1.0; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.8; total time=   1.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1.0; total time=   1.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1.0; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1.0; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.8; total time=   1.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1.0; total time=   1.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.8; total time=   1.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.8; total time=   1.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.8; total time=   1.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=1.0; total time=   1.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.8; total time=   1.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=0.8; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=1.0; total time=   1.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=1.0; total time=   1.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=0.8; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.8; total time=   1.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=1.0; total time=   1.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=0.8; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=1.0; total time=   1.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=0.8; total time=   1.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=1.0; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=1.0; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=1.0; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=1.0; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=1.0; total time=   1.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=0.8; total time=   1.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=0.8; total time=   2.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=1.0; total time=   2.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=0.8; total time=   2.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=1.0; total time=   2.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=0.8; total time=   2.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=0.8; total time=   2.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=0.8; total time=   2.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=1.0; total time=   2.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.3s[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.3s\n",
      "\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=1.0; total time=   2.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=1.0; total time=   2.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=0.8; total time=   3.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=0.8; total time=   3.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=0.8; total time=   3.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=0.8; total time=   3.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=3, n_estimators=300, subsample=0.8; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=3, n_estimators=300, subsample=0.8; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=3, n_estimators=300, subsample=0.8; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=3, n_estimators=300, subsample=0.8; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=3, n_estimators=300, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=3, n_estimators=300, subsample=0.8; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=3, n_estimators=300, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=3, n_estimators=300, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=3, n_estimators=300, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=1.0; total time=   3.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=1.0; total time=   2.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=0.8; total time=   4.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=1.0; total time=   2.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=3, n_estimators=300, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=1.0; total time=   2.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=5, n_estimators=100, subsample=1.0; total time=   0.5s[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.5s\n",
      "\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=1.0; total time=   3.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=5, n_estimators=100, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=5, n_estimators=100, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=5, n_estimators=100, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=5, n_estimators=100, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=5, n_estimators=200, subsample=0.8; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=5, n_estimators=200, subsample=0.8; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=5, n_estimators=200, subsample=1.0; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=5, n_estimators=200, subsample=0.8; total time=   1.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=5, n_estimators=200, subsample=0.8; total time=   1.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=5, n_estimators=200, subsample=1.0; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=5, n_estimators=200, subsample=0.8; total time=   1.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=5, n_estimators=200, subsample=1.0; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=5, n_estimators=200, subsample=1.0; total time=   1.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=5, n_estimators=200, subsample=1.0; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=5, n_estimators=300, subsample=0.8; total time=   1.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=5, n_estimators=300, subsample=0.8; total time=   1.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=5, n_estimators=300, subsample=0.8; total time=   1.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=5, n_estimators=300, subsample=0.8; total time=   1.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=5, n_estimators=300, subsample=0.8; total time=   1.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=5, n_estimators=300, subsample=1.0; total time=   1.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=7, n_estimators=100, subsample=0.8; total time=   1.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=7, n_estimators=100, subsample=0.8; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=7, n_estimators=100, subsample=0.8; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=7, n_estimators=100, subsample=0.8; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=5, n_estimators=300, subsample=1.0; total time=   1.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=5, n_estimators=300, subsample=1.0; total time=   1.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=7, n_estimators=100, subsample=1.0; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=7, n_estimators=100, subsample=0.8; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=5, n_estimators=300, subsample=1.0; total time=   1.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=5, n_estimators=300, subsample=1.0; total time=   1.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=7, n_estimators=100, subsample=1.0; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=7, n_estimators=100, subsample=1.0; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=7, n_estimators=100, subsample=1.0; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=7, n_estimators=100, subsample=1.0; total time=   1.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=7, n_estimators=200, subsample=0.8; total time=   2.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=7, n_estimators=200, subsample=0.8; total time=   2.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=7, n_estimators=200, subsample=1.0; total time=   2.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=7, n_estimators=200, subsample=0.8; total time=   2.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=7, n_estimators=200, subsample=0.8; total time=   2.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=7, n_estimators=200, subsample=0.8; total time=   2.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=7, n_estimators=200, subsample=1.0; total time=   2.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=7, n_estimators=200, subsample=1.0; total time=   2.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=7, n_estimators=200, subsample=1.0; total time=   2.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=7, n_estimators=200, subsample=1.0; total time=   2.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=7, n_estimators=300, subsample=0.8; total time=   3.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=7, n_estimators=300, subsample=0.8; total time=   2.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=7, n_estimators=300, subsample=0.8; total time=   3.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=7, n_estimators=300, subsample=0.8; total time=   3.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=7, n_estimators=300, subsample=0.8; total time=   3.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=7, n_estimators=300, subsample=1.0; total time=   3.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=7, n_estimators=300, subsample=1.0; total time=   2.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=7, n_estimators=300, subsample=1.0; total time=   2.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=7, n_estimators=300, subsample=1.0; total time=   2.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=7, n_estimators=300, subsample=1.0; total time=   2.3s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "}\n",
       "\n",
       "#sk-container-id-3.light {\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: black;\n",
       "  --sklearn-color-background: white;\n",
       "  --sklearn-color-border-box: black;\n",
       "  --sklearn-color-icon: #696969;\n",
       "}\n",
       "\n",
       "#sk-container-id-3.dark {\n",
       "  --sklearn-color-text-on-default-background: white;\n",
       "  --sklearn-color-background: #111;\n",
       "  --sklearn-color-border-box: white;\n",
       "  --sklearn-color-icon: #878787;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-3 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: center;\n",
       "  justify-content: center;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"â¸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"â¾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-3 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-3 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-3 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-3) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  border: var(--sklearn-color-fitted-level-0) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-0);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  border: var(--sklearn-color-fitted-level-0) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-0);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-3 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table {\n",
       "    font-family: monospace;\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table summary::marker {\n",
       "    font-size: 0.7rem;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "    margin-top: 0;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       "/*\n",
       "    `table td`is set in notebook with right text-align.\n",
       "    We need to overwrite it.\n",
       "*/\n",
       ".estimator-table table td.param {\n",
       "    text-align: left;\n",
       "    position: relative;\n",
       "    padding: 0;\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left !important;\n",
       "}\n",
       "\n",
       ".user-set td.value {\n",
       "    color:rgb(255, 94, 0);\n",
       "    background-color: transparent;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left !important;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       "/*\n",
       "    Styles for parameter documentation links\n",
       "    We need styling for visited so jupyter doesn't overwrite it\n",
       "*/\n",
       "a.param-doc-link,\n",
       "a.param-doc-link:link,\n",
       "a.param-doc-link:visited {\n",
       "    text-decoration: underline dashed;\n",
       "    text-underline-offset: .3em;\n",
       "    color: inherit;\n",
       "    display: block;\n",
       "    padding: .5em;\n",
       "}\n",
       "\n",
       "/* \"hack\" to make the entire area of the cell containing the link clickable */\n",
       "a.param-doc-link::before {\n",
       "    position: absolute;\n",
       "    content: \"\";\n",
       "    inset: 0;\n",
       "}\n",
       "\n",
       ".param-doc-description {\n",
       "    display: none;\n",
       "    position: absolute;\n",
       "    z-index: 9999;\n",
       "    left: 0;\n",
       "    padding: .5ex;\n",
       "    margin-left: 1.5em;\n",
       "    color: var(--sklearn-color-text);\n",
       "    box-shadow: .3em .3em .4em #999;\n",
       "    width: max-content;\n",
       "    text-align: left;\n",
       "    max-height: 10em;\n",
       "    overflow-y: auto;\n",
       "\n",
       "    /* unfitted */\n",
       "    background: var(--sklearn-color-unfitted-level-0);\n",
       "    border: thin solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       "/* Fitted state for parameter tooltips */\n",
       ".fitted .param-doc-description {\n",
       "    /* fitted */\n",
       "    background: var(--sklearn-color-fitted-level-0);\n",
       "    border: thin solid var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".param-doc-link:hover .param-doc-description {\n",
       "    display: block;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                    callbacks=None, colsample_bylevel=None,\n",
       "                                    colsample_bynode=None,\n",
       "                                    colsample_bytree=None, device=None,\n",
       "                                    early_stopping_rounds=None,\n",
       "                                    enable_categorical=False, eval_metric=None,\n",
       "                                    feature_types=None, feature_weights=None,\n",
       "                                    gamma=None, grow_policy=None,\n",
       "                                    importance_type=None,\n",
       "                                    interaction_constraints=None...\n",
       "                                    max_depth=None, max_leaves=None,\n",
       "                                    min_child_weight=None, missing=nan,\n",
       "                                    monotone_constraints=None,\n",
       "                                    multi_strategy=None, n_estimators=None,\n",
       "                                    n_jobs=None, num_parallel_tree=None, ...),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;colsample_bytree&#x27;: [0.8, 1.0],\n",
       "                         &#x27;learning_rate&#x27;: [0.01, 0.1, 0.3],\n",
       "                         &#x27;max_depth&#x27;: [3, 5, 7],\n",
       "                         &#x27;n_estimators&#x27;: [100, 200, 300],\n",
       "                         &#x27;subsample&#x27;: [0.8, 1.0]},\n",
       "             scoring=&#x27;neg_mean_squared_error&#x27;, verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>GridSearchCV</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html\">?<span>Documentation for GridSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('estimator',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=estimator,-estimator%20object\">\n",
       "            estimator\n",
       "            <span class=\"param-doc-description\">estimator: estimator object<br><br>This is assumed to implement the scikit-learn estimator interface.<br>Either estimator needs to provide a ``score`` function,<br>or ``scoring`` must be passed.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">XGBRegressor(...ree=None, ...)</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('param_grid',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=param_grid,-dict%20or%20list%20of%20dictionaries\">\n",
       "            param_grid\n",
       "            <span class=\"param-doc-description\">param_grid: dict or list of dictionaries<br><br>Dictionary with parameters names (`str`) as keys and lists of<br>parameter settings to try as values, or a list of such<br>dictionaries, in which case the grids spanned by each dictionary<br>in the list are explored. This enables searching over any sequence<br>of parameter settings.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">{&#x27;colsample_bytree&#x27;: [0.8, 1.0], &#x27;learning_rate&#x27;: [0.01, 0.1, ...], &#x27;max_depth&#x27;: [3, 5, ...], &#x27;n_estimators&#x27;: [100, 200, ...], ...}</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('scoring',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=scoring,-str%2C%20callable%2C%20list%2C%20tuple%20or%20dict%2C%20default%3DNone\">\n",
       "            scoring\n",
       "            <span class=\"param-doc-description\">scoring: str, callable, list, tuple or dict, default=None<br><br>Strategy to evaluate the performance of the cross-validated model on<br>the test set.<br><br>If `scoring` represents a single score, one can use:<br><br>- a single string (see :ref:`scoring_string_names`);<br>- a callable (see :ref:`scoring_callable`) that returns a single value;<br>- `None`, the `estimator`'s<br>  :ref:`default evaluation criterion <scoring_api_overview>` is used.<br><br>If `scoring` represents multiple scores, one can use:<br><br>- a list or tuple of unique strings;<br>- a callable returning a dictionary where the keys are the metric<br>  names and the values are the metric scores;<br>- a dictionary with metric names as keys and callables as values.<br><br>See :ref:`multimetric_grid_search` for an example.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">&#x27;neg_mean_squared_error&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_jobs',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=n_jobs,-int%2C%20default%3DNone\">\n",
       "            n_jobs\n",
       "            <span class=\"param-doc-description\">n_jobs: int, default=None<br><br>Number of jobs to run in parallel.<br>``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.<br>``-1`` means using all processors. See :term:`Glossary <n_jobs>`<br>for more details.<br><br>.. versionchanged:: v0.20<br>   `n_jobs` default changed from 1 to None</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">-1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('refit',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=refit,-bool%2C%20str%2C%20or%20callable%2C%20default%3DTrue\">\n",
       "            refit\n",
       "            <span class=\"param-doc-description\">refit: bool, str, or callable, default=True<br><br>Refit an estimator using the best found parameters on the whole<br>dataset.<br><br>For multiple metric evaluation, this needs to be a `str` denoting the<br>scorer that would be used to find the best parameters for refitting<br>the estimator at the end.<br><br>Where there are considerations other than maximum score in<br>choosing a best estimator, ``refit`` can be set to a function which<br>returns the selected ``best_index_`` given ``cv_results_``. In that<br>case, the ``best_estimator_`` and ``best_params_`` will be set<br>according to the returned ``best_index_`` while the ``best_score_``<br>attribute will not be available.<br><br>The refitted estimator is made available at the ``best_estimator_``<br>attribute and permits using ``predict`` directly on this<br>``GridSearchCV`` instance.<br><br>Also for multiple metric evaluation, the attributes ``best_index_``,<br>``best_score_`` and ``best_params_`` will only be available if<br>``refit`` is set and all of them will be determined w.r.t this specific<br>scorer.<br><br>See ``scoring`` parameter to know more about multiple metric<br>evaluation.<br><br>See :ref:`sphx_glr_auto_examples_model_selection_plot_grid_search_digits.py`<br>to see how to design a custom selection strategy using a callable<br>via `refit`.<br><br>See :ref:`this example<br><sphx_glr_auto_examples_model_selection_plot_grid_search_refit_callable.py>`<br>for an example of how to use ``refit=callable`` to balance model<br>complexity and cross-validated score.<br><br>.. versionchanged:: 0.20<br>    Support for callable added.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('cv',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=cv,-int%2C%20cross-validation%20generator%20or%20an%20iterable%2C%20default%3DNone\">\n",
       "            cv\n",
       "            <span class=\"param-doc-description\">cv: int, cross-validation generator or an iterable, default=None<br><br>Determines the cross-validation splitting strategy.<br>Possible inputs for cv are:<br><br>- None, to use the default 5-fold cross validation,<br>- integer, to specify the number of folds in a `(Stratified)KFold`,<br>- :term:`CV splitter`,<br>- An iterable yielding (train, test) splits as arrays of indices.<br><br>For integer/None inputs, if the estimator is a classifier and ``y`` is<br>either binary or multiclass, :class:`StratifiedKFold` is used. In all<br>other cases, :class:`KFold` is used. These splitters are instantiated<br>with `shuffle=False` so the splits will be the same across calls.<br><br>Refer :ref:`User Guide <cross_validation>` for the various<br>cross-validation strategies that can be used here.<br><br>.. versionchanged:: 0.22<br>    ``cv`` default value if None changed from 3-fold to 5-fold.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">5</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbose',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=verbose,-int\">\n",
       "            verbose\n",
       "            <span class=\"param-doc-description\">verbose: int<br><br>Controls the verbosity: the higher, the more messages.<br><br>- >1 : the computation time for each fold and parameter candidate is<br>  displayed;<br>- >2 : the score is also displayed;<br>- >3 : the fold and candidate parameter indexes are also displayed<br>  together with the starting time of the computation.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">2</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('pre_dispatch',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=pre_dispatch,-int%2C%20or%20str%2C%20default%3D%272%2An_jobs%27\">\n",
       "            pre_dispatch\n",
       "            <span class=\"param-doc-description\">pre_dispatch: int, or str, default='2*n_jobs'<br><br>Controls the number of jobs that get dispatched during parallel<br>execution. Reducing this number can be useful to avoid an<br>explosion of memory consumption when more jobs get dispatched<br>than CPUs can process. This parameter can be:<br><br>- None, in which case all the jobs are immediately created and spawned. Use<br>  this for lightweight and fast-running jobs, to avoid delays due to on-demand<br>  spawning of the jobs<br>- An int, giving the exact number of total jobs that are spawned<br>- A str, giving an expression as a function of n_jobs, as in '2*n_jobs'</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">&#x27;2*n_jobs&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('error_score',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=error_score,-%27raise%27%20or%20numeric%2C%20default%3Dnp.nan\">\n",
       "            error_score\n",
       "            <span class=\"param-doc-description\">error_score: 'raise' or numeric, default=np.nan<br><br>Value to assign to the score if an error occurs in estimator fitting.<br>If set to 'raise', the error is raised. If a numeric value is given,<br>FitFailedWarning is raised. This parameter does not affect the refit<br>step, which will always raise the error.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">nan</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('return_train_score',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=return_train_score,-bool%2C%20default%3DFalse\">\n",
       "            return_train_score\n",
       "            <span class=\"param-doc-description\">return_train_score: bool, default=False<br><br>If ``False``, the ``cv_results_`` attribute will not include training<br>scores.<br>Computing training scores is used to get insights on how different<br>parameter settings impact the overfitting/underfitting trade-off.<br>However computing the scores on the training set can be computationally<br>expensive and is not strictly required to select the parameters that<br>yield the best generalization performance.<br><br>.. versionadded:: 0.19<br><br>.. versionchanged:: 0.21<br>    Default value was changed from ``True`` to ``False``</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>best_estimator_: XGBRegressor</div></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"best_estimator___\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=0.8, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             feature_weights=None, gamma=None, grow_policy=None,\n",
       "             importance_type=None, interaction_constraints=None,\n",
       "             learning_rate=0.1, max_bin=None, max_cat_threshold=None,\n",
       "             max_cat_to_onehot=None, max_delta_step=None, max_depth=7,\n",
       "             max_leaves=None, min_child_weight=None, missing=nan,\n",
       "             monotone_constraints=None, multi_strategy=None, n_estimators=300,\n",
       "             n_jobs=None, num_parallel_tree=None, ...)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>XGBRegressor</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor\">?<span>Documentation for XGBRegressor</span></a></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"best_estimator___\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('objective',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=objective,-str%20%7C%20xgboost.sklearn._SklObjWProto%20%7C%20typing.Callable%5B%5Btyping.Any%2C%20typing.Any%5D%2C%20typing.Tuple%5Bnumpy.ndarray%2C%20numpy.ndarray%5D%5D%20%7C%20None\">\n",
       "            objective\n",
       "            <span class=\"param-doc-description\">objective: str | xgboost.sklearn._SklObjWProto | typing.Callable[[typing.Any, typing.Any], typing.Tuple[numpy.ndarray, numpy.ndarray]] | None<br><br>Specify the learning task and the corresponding learning objective or a custom<br>objective function to be used.<br><br>For custom objective, see :doc:`/tutorials/custom_metric_obj` and<br>:ref:`custom-obj-metric` for more information, along with the end note for<br>function signatures.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">&#x27;reg:squarederror&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('base_score',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=base_score,-float%20%7C%20typing.List%5Bfloat%5D%20%7C%20None\">\n",
       "            base_score\n",
       "            <span class=\"param-doc-description\">base_score: float | typing.List[float] | None<br><br>The initial prediction score of all instances, global bias.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('booster',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">booster</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('callbacks',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=callbacks,-typing.List%5Bxgboost.callback.TrainingCallback%5D%20%7C%20None\">\n",
       "            callbacks\n",
       "            <span class=\"param-doc-description\">callbacks: typing.List[xgboost.callback.TrainingCallback] | None<br><br>List of callback functions that are applied at end of each iteration.<br>It is possible to use predefined callbacks by using<br>:ref:`Callback API <callback_api>`.<br><br>.. note::<br><br>   States in callback are not preserved during training, which means callback<br>   objects can not be reused for multiple training sessions without<br>   reinitialization or deepcopy.<br><br>.. code-block:: python<br><br>    for params in parameters_grid:<br>        # be sure to (re)initialize the callbacks before each run<br>        callbacks = [xgb.callback.LearningRateScheduler(custom_rates)]<br>        reg = xgboost.XGBRegressor(**params, callbacks=callbacks)<br>        reg.fit(X, y)</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('colsample_bylevel',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=colsample_bylevel,-float%20%7C%20None\">\n",
       "            colsample_bylevel\n",
       "            <span class=\"param-doc-description\">colsample_bylevel: float | None<br><br>Subsample ratio of columns for each level.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('colsample_bynode',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=colsample_bynode,-float%20%7C%20None\">\n",
       "            colsample_bynode\n",
       "            <span class=\"param-doc-description\">colsample_bynode: float | None<br><br>Subsample ratio of columns for each split.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('colsample_bytree',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=colsample_bytree,-float%20%7C%20None\">\n",
       "            colsample_bytree\n",
       "            <span class=\"param-doc-description\">colsample_bytree: float | None<br><br>Subsample ratio of columns when constructing each tree.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0.8</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('device',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=device,-str%20%7C%20None\">\n",
       "            device\n",
       "            <span class=\"param-doc-description\">device: str | None<br><br>.. versionadded:: 2.0.0<br><br>Device ordinal, available options are `cpu`, `cuda`, and `gpu`.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('early_stopping_rounds',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=early_stopping_rounds,-int%20%7C%20None\">\n",
       "            early_stopping_rounds\n",
       "            <span class=\"param-doc-description\">early_stopping_rounds: int | None<br><br>.. versionadded:: 1.6.0<br><br>- Activates early stopping. Validation metric needs to improve at least once in<br>  every **early_stopping_rounds** round(s) to continue training.  Requires at<br>  least one item in **eval_set** in :py:meth:`fit`.<br><br>- If early stopping occurs, the model will have two additional attributes:<br>  :py:attr:`best_score` and :py:attr:`best_iteration`. These are used by the<br>  :py:meth:`predict` and :py:meth:`apply` methods to determine the optimal<br>  number of trees during inference. If users want to access the full model<br>  (including trees built after early stopping), they can specify the<br>  `iteration_range` in these inference methods. In addition, other utilities<br>  like model plotting can also use the entire model.<br><br>- If you prefer to discard the trees after `best_iteration`, consider using the<br>  callback function :py:class:`xgboost.callback.EarlyStopping`.<br><br>- If there's more than one item in **eval_set**, the last entry will be used for<br>  early stopping.  If there's more than one metric in **eval_metric**, the last<br>  metric will be used for early stopping.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('enable_categorical',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=enable_categorical,-bool\">\n",
       "            enable_categorical\n",
       "            <span class=\"param-doc-description\">enable_categorical: bool<br><br>See the same parameter of :py:class:`DMatrix` for details.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('eval_metric',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=eval_metric,-str%20%7C%20typing.List%5Bstr%20%7C%20typing.Callable%5D%20%7C%20typing.Callable%20%7C%20None\">\n",
       "            eval_metric\n",
       "            <span class=\"param-doc-description\">eval_metric: str | typing.List[str | typing.Callable] | typing.Callable | None<br><br>.. versionadded:: 1.6.0<br><br>Metric used for monitoring the training result and early stopping.  It can be a<br>string or list of strings as names of predefined metric in XGBoost (See<br>:doc:`/parameter`), one of the metrics in :py:mod:`sklearn.metrics`, or any<br>other user defined metric that looks like `sklearn.metrics`.<br><br>If custom objective is also provided, then custom metric should implement the<br>corresponding reverse link function.<br><br>Unlike the `scoring` parameter commonly used in scikit-learn, when a callable<br>object is provided, it's assumed to be a cost function and by default XGBoost<br>will minimize the result during early stopping.<br><br>For advanced usage on Early stopping like directly choosing to maximize instead<br>of minimize, see :py:obj:`xgboost.callback.EarlyStopping`.<br><br>See :doc:`/tutorials/custom_metric_obj` and :ref:`custom-obj-metric` for more<br>information.<br><br>.. code-block:: python<br><br>    from sklearn.datasets import load_diabetes<br>    from sklearn.metrics import mean_absolute_error<br>    X, y = load_diabetes(return_X_y=True)<br>    reg = xgb.XGBRegressor(<br>        tree_method=\"hist\",<br>        eval_metric=mean_absolute_error,<br>    )<br>    reg.fit(X, y, eval_set=[(X, y)])</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('feature_types',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=feature_types,-typing.Sequence%5Bstr%5D%20%7C%20None\">\n",
       "            feature_types\n",
       "            <span class=\"param-doc-description\">feature_types: typing.Sequence[str] | None<br><br>.. versionadded:: 1.7.0<br><br>Used for specifying feature types without constructing a dataframe. See<br>the :py:class:`DMatrix` for details.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('feature_weights',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=feature_weights,-Optional%5BArrayLike%5D\">\n",
       "            feature_weights\n",
       "            <span class=\"param-doc-description\">feature_weights: Optional[ArrayLike]<br><br>Weight for each feature, defines the probability of each feature being selected<br>when colsample is being used.  All values must be greater than 0, otherwise a<br>`ValueError` is thrown.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('gamma',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=gamma,-float%20%7C%20None\">\n",
       "            gamma\n",
       "            <span class=\"param-doc-description\">gamma: float | None<br><br>(min_split_loss) Minimum loss reduction required to make a further partition on<br>a leaf node of the tree.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('grow_policy',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=grow_policy,-str%20%7C%20None\">\n",
       "            grow_policy\n",
       "            <span class=\"param-doc-description\">grow_policy: str | None<br><br>Tree growing policy.<br><br>- depthwise: Favors splitting at nodes closest to the node,<br>- lossguide: Favors splitting at nodes with highest loss change.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('importance_type',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">importance_type</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('interaction_constraints',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=interaction_constraints,-str%20%7C%20typing.List%5Btyping.Tuple%5Bstr%5D%5D%20%7C%20None\">\n",
       "            interaction_constraints\n",
       "            <span class=\"param-doc-description\">interaction_constraints: str | typing.List[typing.Tuple[str]] | None<br><br>Constraints for interaction representing permitted interactions.  The<br>constraints must be specified in the form of a nested list, e.g. ``[[0, 1], [2,<br>3, 4]]``, where each inner list is a group of indices of features that are<br>allowed to interact with each other.  See :doc:`tutorial<br></tutorials/feature_interaction_constraint>` for more information</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('learning_rate',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=learning_rate,-float%20%7C%20None\">\n",
       "            learning_rate\n",
       "            <span class=\"param-doc-description\">learning_rate: float | None<br><br>Boosting learning rate (xgb's \"eta\")</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0.1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_bin',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=max_bin,-int%20%7C%20None\">\n",
       "            max_bin\n",
       "            <span class=\"param-doc-description\">max_bin: int | None<br><br>If using histogram-based algorithm, maximum number of bins per feature</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_cat_threshold',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=max_cat_threshold,-int%20%7C%20None\">\n",
       "            max_cat_threshold\n",
       "            <span class=\"param-doc-description\">max_cat_threshold: int | None<br><br>.. versionadded:: 1.7.0<br><br>.. note:: This parameter is experimental<br><br>Maximum number of categories considered for each split. Used only by<br>partition-based splits for preventing over-fitting. Also, `enable_categorical`<br>needs to be set to have categorical feature support. See :doc:`Categorical Data<br></tutorials/categorical>` and :ref:`cat-param` for details.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_cat_to_onehot',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=max_cat_to_onehot,-Optional%5Bint%5D\">\n",
       "            max_cat_to_onehot\n",
       "            <span class=\"param-doc-description\">max_cat_to_onehot: Optional[int]<br><br>.. versionadded:: 1.6.0<br><br>.. note:: This parameter is experimental<br><br>A threshold for deciding whether XGBoost should use one-hot encoding based split<br>for categorical data.  When number of categories is lesser than the threshold<br>then one-hot encoding is chosen, otherwise the categories will be partitioned<br>into children nodes. Also, `enable_categorical` needs to be set to have<br>categorical feature support. See :doc:`Categorical Data<br></tutorials/categorical>` and :ref:`cat-param` for details.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_delta_step',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=max_delta_step,-float%20%7C%20None\">\n",
       "            max_delta_step\n",
       "            <span class=\"param-doc-description\">max_delta_step: float | None<br><br>Maximum delta step we allow each tree's weight estimation to be.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_depth',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=max_depth,-%20int%20%7C%20None\">\n",
       "            max_depth\n",
       "            <span class=\"param-doc-description\">max_depth:  int | None<br><br>Maximum tree depth for base learners.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">7</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_leaves',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=max_leaves,-int%20%7C%20None\">\n",
       "            max_leaves\n",
       "            <span class=\"param-doc-description\">max_leaves: int | None<br><br>Maximum number of leaves; 0 indicates no limit.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_child_weight',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=min_child_weight,-float%20%7C%20None\">\n",
       "            min_child_weight\n",
       "            <span class=\"param-doc-description\">min_child_weight: float | None<br><br>Minimum sum of instance weight(hessian) needed in a child.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('missing',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=missing,-float\">\n",
       "            missing\n",
       "            <span class=\"param-doc-description\">missing: float<br><br>Value in the data which needs to be present as a missing value. Default to<br>:py:data:`numpy.nan`.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">nan</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('monotone_constraints',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=monotone_constraints,-typing.Dict%5Bstr%2C%20int%5D%20%7C%20str%20%7C%20None\">\n",
       "            monotone_constraints\n",
       "            <span class=\"param-doc-description\">monotone_constraints: typing.Dict[str, int] | str | None<br><br>Constraint of variable monotonicity.  See :doc:`tutorial </tutorials/monotonic>`<br>for more information.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('multi_strategy',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=multi_strategy,-str%20%7C%20None\">\n",
       "            multi_strategy\n",
       "            <span class=\"param-doc-description\">multi_strategy: str | None<br><br>.. versionadded:: 2.0.0<br><br>.. note:: This parameter is working-in-progress.<br><br>The strategy used for training multi-target models, including multi-target<br>regression and multi-class classification. See :doc:`/tutorials/multioutput` for<br>more information.<br><br>- ``one_output_per_tree``: One model for each target.<br>- ``multi_output_tree``:  Use multi-target trees.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_estimators',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=n_estimators,-int%20%7C%20None\">\n",
       "            n_estimators\n",
       "            <span class=\"param-doc-description\">n_estimators: int | None<br><br>Number of gradient boosted trees.  Equivalent to number of boosting<br>rounds.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">300</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_jobs',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=n_jobs,-int%20%7C%20None\">\n",
       "            n_jobs\n",
       "            <span class=\"param-doc-description\">n_jobs: int | None<br><br>Number of parallel threads used to run xgboost.  When used with other<br>Scikit-Learn algorithms like grid search, you may choose which algorithm to<br>parallelize and balance the threads.  Creating thread contention will<br>significantly slow down both algorithms.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('num_parallel_tree',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">num_parallel_tree</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('random_state',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=random_state,-numpy.random.mtrand.RandomState%20%7C%20numpy.random._generator.Generator%20%7C%20int%20%7C%20None\">\n",
       "            random_state\n",
       "            <span class=\"param-doc-description\">random_state: numpy.random.mtrand.RandomState | numpy.random._generator.Generator | int | None<br><br>Random number seed.<br><br>.. note::<br><br>   Using gblinear booster with shotgun updater is nondeterministic as<br>   it uses Hogwild algorithm.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">5</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('reg_alpha',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=reg_alpha,-float%20%7C%20None\">\n",
       "            reg_alpha\n",
       "            <span class=\"param-doc-description\">reg_alpha: float | None<br><br>L1 regularization term on weights (xgb's alpha).</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('reg_lambda',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=reg_lambda,-float%20%7C%20None\">\n",
       "            reg_lambda\n",
       "            <span class=\"param-doc-description\">reg_lambda: float | None<br><br>L2 regularization term on weights (xgb's lambda).</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('sampling_method',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=sampling_method,-str%20%7C%20None\">\n",
       "            sampling_method\n",
       "            <span class=\"param-doc-description\">sampling_method: str | None<br><br>Sampling method. Used only by the GPU version of ``hist`` tree method.<br><br>- ``uniform``: Select random training instances uniformly.<br>- ``gradient_based``: Select random training instances with higher probability<br>    when the gradient and hessian are larger. (cf. CatBoost)</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('scale_pos_weight',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=scale_pos_weight,-float%20%7C%20None\">\n",
       "            scale_pos_weight\n",
       "            <span class=\"param-doc-description\">scale_pos_weight: float | None<br><br>Balancing of positive and negative weights.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('subsample',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=subsample,-float%20%7C%20None\">\n",
       "            subsample\n",
       "            <span class=\"param-doc-description\">subsample: float | None<br><br>Subsample ratio of the training instance.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0.8</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('tree_method',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=tree_method,-str%20%7C%20None\">\n",
       "            tree_method\n",
       "            <span class=\"param-doc-description\">tree_method: str | None<br><br>Specify which tree method to use.  Default to auto.  If this parameter is set to<br>default, XGBoost will choose the most conservative option available.  It's<br>recommended to study this option from the parameters document :doc:`tree method<br></treemethod>`</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('validate_parameters',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=validate_parameters,-bool%20%7C%20None\">\n",
       "            validate_parameters\n",
       "            <span class=\"param-doc-description\">validate_parameters: bool | None<br><br>Give warnings for unknown parameter.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbosity',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=verbosity,-int%20%7C%20None\">\n",
       "            verbosity\n",
       "            <span class=\"param-doc-description\">verbosity: int | None<br><br>The degree of verbosity. Valid values are 0 (silent) - 3 (debug).</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div></div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.copy-paste-icon').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling\n",
       "        .textContent.trim().split(' ')[0];\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "\n",
       "\n",
       "/**\n",
       " * Adapted from Skrub\n",
       " * https://github.com/skrub-data/skrub/blob/403466d1d5d4dc76a7ef569b3f8228db59a31dc3/skrub/_reporting/_data/templates/report.js#L789\n",
       " * @returns \"light\" or \"dark\"\n",
       " */\n",
       "function detectTheme(element) {\n",
       "    const body = document.querySelector('body');\n",
       "\n",
       "    // Check VSCode theme\n",
       "    const themeKindAttr = body.getAttribute('data-vscode-theme-kind');\n",
       "    const themeNameAttr = body.getAttribute('data-vscode-theme-name');\n",
       "\n",
       "    if (themeKindAttr && themeNameAttr) {\n",
       "        const themeKind = themeKindAttr.toLowerCase();\n",
       "        const themeName = themeNameAttr.toLowerCase();\n",
       "\n",
       "        if (themeKind.includes(\"dark\") || themeName.includes(\"dark\")) {\n",
       "            return \"dark\";\n",
       "        }\n",
       "        if (themeKind.includes(\"light\") || themeName.includes(\"light\")) {\n",
       "            return \"light\";\n",
       "        }\n",
       "    }\n",
       "\n",
       "    // Check Jupyter theme\n",
       "    if (body.getAttribute('data-jp-theme-light') === 'false') {\n",
       "        return 'dark';\n",
       "    } else if (body.getAttribute('data-jp-theme-light') === 'true') {\n",
       "        return 'light';\n",
       "    }\n",
       "\n",
       "    // Guess based on a parent element's color\n",
       "    const color = window.getComputedStyle(element.parentNode, null).getPropertyValue('color');\n",
       "    const match = color.match(/^rgb\\s*\\(\\s*(\\d+)\\s*,\\s*(\\d+)\\s*,\\s*(\\d+)\\s*\\)\\s*$/i);\n",
       "    if (match) {\n",
       "        const [r, g, b] = [\n",
       "            parseFloat(match[1]),\n",
       "            parseFloat(match[2]),\n",
       "            parseFloat(match[3])\n",
       "        ];\n",
       "\n",
       "        // https://en.wikipedia.org/wiki/HSL_and_HSV#Lightness\n",
       "        const luma = 0.299 * r + 0.587 * g + 0.114 * b;\n",
       "\n",
       "        if (luma > 180) {\n",
       "            // If the text is very bright we have a dark theme\n",
       "            return 'dark';\n",
       "        }\n",
       "        if (luma < 75) {\n",
       "            // If the text is very dark we have a light theme\n",
       "            return 'light';\n",
       "        }\n",
       "        // Otherwise fall back to the next heuristic.\n",
       "    }\n",
       "\n",
       "    // Fallback to system preference\n",
       "    return window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'light';\n",
       "}\n",
       "\n",
       "\n",
       "function forceTheme(elementId) {\n",
       "    const estimatorElement = document.querySelector(`#${elementId}`);\n",
       "    if (estimatorElement === null) {\n",
       "        console.error(`Element with id ${elementId} not found.`);\n",
       "    } else {\n",
       "        const theme = detectTheme(estimatorElement);\n",
       "        estimatorElement.classList.add(theme);\n",
       "    }\n",
       "}\n",
       "\n",
       "forceTheme('sk-container-id-3');</script></body>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                    callbacks=None, colsample_bylevel=None,\n",
       "                                    colsample_bynode=None,\n",
       "                                    colsample_bytree=None, device=None,\n",
       "                                    early_stopping_rounds=None,\n",
       "                                    enable_categorical=False, eval_metric=None,\n",
       "                                    feature_types=None, feature_weights=None,\n",
       "                                    gamma=None, grow_policy=None,\n",
       "                                    importance_type=None,\n",
       "                                    interaction_constraints=None...\n",
       "                                    max_depth=None, max_leaves=None,\n",
       "                                    min_child_weight=None, missing=nan,\n",
       "                                    monotone_constraints=None,\n",
       "                                    multi_strategy=None, n_estimators=None,\n",
       "                                    n_jobs=None, num_parallel_tree=None, ...),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'colsample_bytree': [0.8, 1.0],\n",
       "                         'learning_rate': [0.01, 0.1, 0.3],\n",
       "                         'max_depth': [3, 5, 7],\n",
       "                         'n_estimators': [100, 200, 300],\n",
       "                         'subsample': [0.8, 1.0]},\n",
       "             scoring='neg_mean_squared_error', verbose=2)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## With  scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(king_hs_X_clean[best_features], king_hs_y, random_state=random_state, test_size=0.2)\n",
    "\n",
    "# Start fresh - standardize\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Define the XGBoost model\n",
    "xgb_model = XGBRegressor(random_state=random_state, objective='reg:squarederror')\n",
    "\n",
    "# Define parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300], #400, 500, 600\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.01, 0.1, 0.3],\n",
    "    'subsample': [0.8, 1.0],\n",
    "    'colsample_bytree': [0.8, 1.0]\n",
    "}\n",
    "\n",
    "# Create GridSearchCV\n",
    "grid_search = GridSearchCV( ##RandomizedSearchCV , GridSearchCV\n",
    "    estimator=xgb_model,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,\n",
    "    scoring='neg_mean_squared_error',  # or 'r2', 'neg_mean_absolute_error'\n",
    "    verbose=2,\n",
    "    n_jobs=-1  # Use all processors\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "print(\"Starting Grid Search...\")\n",
    "grid_search.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "66aa4277",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "BEST PARAMETERS:\n",
      "======================================================================\n",
      "{'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 300, 'subsample': 0.8}\n",
      "\n",
      "======================================================================\n",
      "BEST SCORE (CV):\n",
      "======================================================================\n",
      "Best CV Score: 9448263884.8000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>r2_score</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td>0.985048</td>\n",
       "      <td>38825.41683</td>\n",
       "      <td>28170.755859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>0.916756</td>\n",
       "      <td>91873.29292</td>\n",
       "      <td>58558.921875</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       r2_score         RMSE           MAE\n",
       "train  0.985048  38825.41683  28170.755859\n",
       "test   0.916756  91873.29292  58558.921875"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Best parameters and score\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"BEST PARAMETERS:\")\n",
    "print(\"=\"*70)\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"BEST SCORE (CV):\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Best CV Score: {-grid_search.best_score_:.4f}\")  # Negative because of neg_mse\n",
    "\n",
    "# Get the best model\n",
    "best_xgb = grid_search.best_estimator_\n",
    "\n",
    "### On train set\n",
    "y_pred_tr = best_xgb.predict(X_train_scaled)\n",
    "eval_tr = pd.DataFrame([r2_score(y_train, y_pred_tr), np.sqrt(mean_squared_error(y_train, y_pred_tr)), mean_absolute_error(y_train, y_pred_tr)], index=['r2_score', 'RMSE', 'MAE']).T\n",
    "\n",
    "# Evaluate on test set\n",
    "y_pred = best_xgb.predict(X_test_scaled)\n",
    "eval_ts = pd.DataFrame([r2_score(y_test, y_pred), np.sqrt(mean_squared_error(y_test, y_pred)), mean_absolute_error(y_test, y_pred)], index=['r2_score', 'RMSE', 'MAE']).T\n",
    "\n",
    "eval = pd.concat([eval_tr,eval_ts])\n",
    "eval.index=['train', 'test']\n",
    "eval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba219ed2",
   "metadata": {},
   "source": [
    "- No effect with scaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd6a8e4",
   "metadata": {},
   "source": [
    "### Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1f020dc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 300, 'subsample': 0.8}\n"
     ]
    }
   ],
   "source": [
    "# Best parameters\n",
    "print(\"Best parameters:\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f68bc848",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features ordered by importance:\n",
      "          Feature  Ranking  Selected\n",
      "2     sqft_living        1      True\n",
      "5      waterfront        1      True\n",
      "6            view        1      True\n",
      "8           grade        1      True\n",
      "13  sqft_living15        1      True\n",
      "11       yr_built        1      True\n",
      "9      sqft_above        1      True\n",
      "17            lat        1      True\n",
      "18           long        1      True\n",
      "19   loc_clusters        1      True\n",
      "12      renovated        2     False\n",
      "7       condition        3     False\n",
      "14     sqft_lot15        4     False\n",
      "15      year_sold        5     False\n",
      "3        sqft_lot        6     False\n",
      "4          floors        7     False\n",
      "1       bathrooms        8     False\n",
      "10  sqft_basement        9     False\n",
      "20       sold_occ       10     False\n",
      "16     month_sold       11     False\n",
      "0        bedrooms       12     False\n",
      "\n",
      "Top 5 Selected Features:\n",
      "['sqft_living', 'waterfront', 'view', 'grade', 'sqft_living15', 'yr_built', 'sqft_above', 'lat', 'long', 'loc_clusters']\n"
     ]
    }
   ],
   "source": [
    "selector = RFE(best_xgb, n_features_to_select=10, step=1) ##xgb_reg, lin_baseline\n",
    "selector = selector.fit(X_train, y_train)\n",
    "\n",
    "# Get feature names and rankings\n",
    "feature_ranking = pd.DataFrame({\n",
    "    'Feature': X_train.columns,\n",
    "    'Ranking': selector.ranking_,\n",
    "    'Selected': selector.support_\n",
    "}).sort_values('Ranking')\n",
    "\n",
    "print(\"Features ordered by importance:\")\n",
    "print(feature_ranking)\n",
    "\n",
    "# Just the top 5 selected features\n",
    "print(\"\\nTop 5 Selected Features:\")\n",
    "print(feature_ranking[feature_ranking['Selected'] == True]['Feature'].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed7c2e5",
   "metadata": {},
   "source": [
    "### Test with Top features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "10988d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_features = feature_ranking[feature_ranking['Selected'] == True]['Feature'].tolist()\n",
    "rest_rf = feature_ranking[feature_ranking['Selected'] == False]['Feature'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c9392f75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Grid Search...\n",
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=0.8; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=0.8; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=0.8; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=0.8; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=0.8; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=1.0; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=1.0; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=1.0; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=1.0; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.8; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.8; total time=   0.8s[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.8; total time=   0.8s\n",
      "\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.8; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.8; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.8; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.8; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.8; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.8; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.8; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=1.0; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=0.8; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=0.8; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=0.8; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=0.8; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=1.0; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=1.0; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=1.0; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=1.0; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=0.8; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=0.8; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=0.8; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=0.8; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=1.0; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=1.0; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=1.0; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=1.0; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=0.8; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=1.0; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=0.8; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.4s[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.4s\n",
      "\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=1.0; total time=   2.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=0.8; total time=   2.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=0.8; total time=   2.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=0.8; total time=   2.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=0.8; total time=   2.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=0.8; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=0.8; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=0.8; total time=   3.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=0.8; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=0.8; total time=   0.5s[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=0.8; total time=   0.5s\n",
      "\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=1.0; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=1.0; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=1.0; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=1.0; total time=   2.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=1.0; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=1.0; total time=   2.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=1.0; total time=   2.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=1.0; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=1.0; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.8; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.8; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.8; total time=   0.6s[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1.0; total time=   0.6s\n",
      "\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.8; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.8; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.8; total time=  -2.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.8; total time=  -2.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.8; total time=  -2.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.8; total time=  -2.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.8; total time=  -2.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=1.0; total time=  -2.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=0.8; total time=  -2.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=0.8; total time=  -2.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=0.8; total time=  -2.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=0.8; total time=  -2.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=0.8; total time=  -2.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=1.0; total time=  -2.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=1.0; total time=  -2.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=1.0; total time=  -2.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=1.0; total time=  -2.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=1.0; total time=   3.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=1.0; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=1.0; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=0.8; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=0.8; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=0.8; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=0.8; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=1.0; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=0.8; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=1.0; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=1.0; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=0.8; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=0.8; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=0.8; total time=  -3.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=0.8; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=1.0; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=0.8; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=3, n_estimators=300, subsample=0.8; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=3, n_estimators=300, subsample=0.8; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=3, n_estimators=300, subsample=0.8; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=3, n_estimators=300, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=3, n_estimators=300, subsample=0.8; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=3, n_estimators=300, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=3, n_estimators=300, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=3, n_estimators=300, subsample=0.8; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=3, n_estimators=300, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=1.0; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=1.0; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=1.0; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=5, n_estimators=100, subsample=1.0; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=5, n_estimators=100, subsample=1.0; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=1.0; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=5, n_estimators=100, subsample=1.0; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=5, n_estimators=100, subsample=1.0; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=5, n_estimators=200, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=5, n_estimators=200, subsample=0.8; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=5, n_estimators=200, subsample=0.8; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=5, n_estimators=100, subsample=1.0; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=3, n_estimators=300, subsample=1.0; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=5, n_estimators=200, subsample=0.8; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=5, n_estimators=200, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=7, n_estimators=100, subsample=0.8; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=7, n_estimators=100, subsample=0.8; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=5, n_estimators=300, subsample=0.8; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=5, n_estimators=300, subsample=1.0; total time=   0.8s[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=5, n_estimators=300, subsample=0.8; total time=   1.0s\n",
      "\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=7, n_estimators=100, subsample=0.8; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=5, n_estimators=300, subsample=0.8; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=7, n_estimators=100, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=5, n_estimators=200, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=5, n_estimators=200, subsample=0.8; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=7, n_estimators=100, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=5, n_estimators=200, subsample=0.8; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=5, n_estimators=200, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=5, n_estimators=200, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=5, n_estimators=300, subsample=1.0; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=7, n_estimators=100, subsample=0.8; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=7, n_estimators=100, subsample=0.8; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=7, n_estimators=100, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=7, n_estimators=100, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=7, n_estimators=200, subsample=0.8; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=7, n_estimators=100, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=5, n_estimators=300, subsample=1.0; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=5, n_estimators=300, subsample=0.8; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=5, n_estimators=300, subsample=1.0; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=5, n_estimators=300, subsample=0.8; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=5, n_estimators=300, subsample=1.0; total time=   1.1s[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=7, n_estimators=200, subsample=1.0; total time=   1.1s\n",
      "\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=7, n_estimators=200, subsample=0.8; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=7, n_estimators=200, subsample=0.8; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=7, n_estimators=200, subsample=1.0; total time=   1.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=7, n_estimators=200, subsample=0.8; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=7, n_estimators=300, subsample=1.0; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=7, n_estimators=300, subsample=1.0; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=7, n_estimators=200, subsample=1.0; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=7, n_estimators=300, subsample=0.8; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=7, n_estimators=300, subsample=0.8; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=7, n_estimators=200, subsample=1.0; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=7, n_estimators=200, subsample=0.8; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=0.8; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=7, n_estimators=300, subsample=0.8; total time=   2.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=0.8; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=0.8; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=1.0; total time=   0.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=7, n_estimators=200, subsample=1.0; total time=   1.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=0.8; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=1.0; total time=   0.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=1.0; total time=   0.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=0.8; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=1.0; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=7, n_estimators=300, subsample=1.0; total time=   1.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.8; total time=   0.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.8; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=7, n_estimators=300, subsample=1.0; total time=   1.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=7, n_estimators=300, subsample=1.0; total time=   1.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.8; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=7, n_estimators=300, subsample=0.8; total time=   1.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.8; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.8; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.8; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=1.0; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.8; total time=   0.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=0.8; total time=   1.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=1.0; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=0.8; total time=   0.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=0.8; total time=   0.8s[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=7, n_estimators=300, subsample=0.8; total time=   2.1s\n",
      "\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.8; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.8; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=0.8; total time=   0.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=1.0; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=1.0; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=0.8; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=1.0; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.8; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=1.0; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=1.0; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=0.8; total time=   1.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=0.8; total time=   1.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=0.8; total time=   1.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=1.0; total time=   1.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=1.0; total time=   1.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=0.8; total time=   2.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=1.0; total time=   1.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=1.0; total time=   1.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=1.0; total time=   1.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=0.8; total time=   2.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=0.8; total time=   2.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=0.8; total time=   2.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=0.8; total time=   2.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=0.8; total time=   2.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=1.0; total time=   2.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=1.0; total time=   2.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=0.8; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=0.8; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=0.8; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=0.8; total time=   0.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=0.8; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=1.0; total time=   2.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=1.0; total time=   0.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=1.0; total time=   0.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=1.0; total time=   2.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=0.8; total time=   3.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=1.0; total time=   0.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=1.0; total time=   0.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=1.0; total time=   0.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.8; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.8; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=1.0; total time=   3.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.8; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.8; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.8; total time=   0.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.8; total time=   1.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.8; total time=   1.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.8; total time=   1.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.8; total time=   1.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.8; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=0.8; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=0.8; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=0.8; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=0.8; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=1.0; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=1.0; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=1.0; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=1.0; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=0.8; total time=   0.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=1.0; total time=   0.8s[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=1.0; total time=   1.0s\n",
      "\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=0.8; total time=   1.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=1.0; total time=   1.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=1.0; total time=   1.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=0.8; total time=   1.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=0.8; total time=   1.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=0.8; total time=   1.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=1.0; total time=   1.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=1.0; total time=   1.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=0.8; total time=   1.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=1.0; total time=   1.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=0.8; total time=   2.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=1.0; total time=   2.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=0.8; total time=   2.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=0.8; total time=   2.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=0.8; total time=   2.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=0.8; total time=   2.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=3, n_estimators=300, subsample=0.8; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=3, n_estimators=300, subsample=0.8; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=1.0; total time=   1.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=3, n_estimators=300, subsample=0.8; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=1.0; total time=   1.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=3, n_estimators=300, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=3, n_estimators=300, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=1.0; total time=   2.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=3, n_estimators=300, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=3, n_estimators=300, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=3, n_estimators=300, subsample=0.8; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=3, n_estimators=300, subsample=0.8; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=1.0; total time=   2.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=3, n_estimators=300, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=5, n_estimators=100, subsample=1.0; total time=   0.3s[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=5, n_estimators=100, subsample=1.0; total time=   0.4s\n",
      "\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=5, n_estimators=100, subsample=1.0; total time=   0.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=5, n_estimators=100, subsample=1.0; total time=   0.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=5, n_estimators=100, subsample=1.0; total time=   0.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=5, n_estimators=200, subsample=0.8; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=5, n_estimators=200, subsample=0.8; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=5, n_estimators=200, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=5, n_estimators=200, subsample=0.8; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=5, n_estimators=200, subsample=0.8; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=5, n_estimators=200, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=5, n_estimators=200, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=5, n_estimators=200, subsample=0.8; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=5, n_estimators=200, subsample=1.0; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=5, n_estimators=200, subsample=1.0; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=5, n_estimators=300, subsample=0.8; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=5, n_estimators=300, subsample=0.8; total time=   1.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=5, n_estimators=300, subsample=0.8; total time=   1.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=5, n_estimators=300, subsample=1.0; total time=   1.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=5, n_estimators=300, subsample=0.8; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=7, n_estimators=100, subsample=0.8; total time=   0.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=7, n_estimators=100, subsample=0.8; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=7, n_estimators=100, subsample=0.8; total time=   0.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=5, n_estimators=300, subsample=0.8; total time=   1.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=5, n_estimators=300, subsample=1.0; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=5, n_estimators=300, subsample=1.0; total time=   1.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=5, n_estimators=300, subsample=1.0; total time=   1.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=5, n_estimators=300, subsample=1.0; total time=   1.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=7, n_estimators=100, subsample=0.8; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=7, n_estimators=100, subsample=0.8; total time=   0.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=7, n_estimators=100, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=7, n_estimators=100, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=7, n_estimators=100, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=7, n_estimators=100, subsample=1.0; total time=   0.7s[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=7, n_estimators=100, subsample=1.0; total time=   0.7s\n",
      "\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=7, n_estimators=200, subsample=0.8; total time=   1.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=7, n_estimators=200, subsample=0.8; total time=   1.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=7, n_estimators=200, subsample=0.8; total time=   1.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=7, n_estimators=200, subsample=1.0; total time=   1.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=7, n_estimators=200, subsample=1.0; total time=   1.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=7, n_estimators=200, subsample=1.0; total time=   1.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=7, n_estimators=200, subsample=0.8; total time=   1.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=7, n_estimators=200, subsample=1.0; total time=   1.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=7, n_estimators=200, subsample=0.8; total time=   1.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=7, n_estimators=200, subsample=1.0; total time=   1.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=7, n_estimators=300, subsample=1.0; total time=   1.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=7, n_estimators=300, subsample=0.8; total time=   2.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=7, n_estimators=300, subsample=0.8; total time=   1.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=7, n_estimators=300, subsample=0.8; total time=   1.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=7, n_estimators=300, subsample=0.8; total time=   1.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=7, n_estimators=300, subsample=0.8; total time=   1.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=7, n_estimators=300, subsample=1.0; total time=   1.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=7, n_estimators=300, subsample=1.0; total time=   1.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=7, n_estimators=300, subsample=1.0; total time=   1.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=7, n_estimators=300, subsample=1.0; total time=   1.4s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "}\n",
       "\n",
       "#sk-container-id-4.light {\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: black;\n",
       "  --sklearn-color-background: white;\n",
       "  --sklearn-color-border-box: black;\n",
       "  --sklearn-color-icon: #696969;\n",
       "}\n",
       "\n",
       "#sk-container-id-4.dark {\n",
       "  --sklearn-color-text-on-default-background: white;\n",
       "  --sklearn-color-background: #111;\n",
       "  --sklearn-color-border-box: white;\n",
       "  --sklearn-color-icon: #878787;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-4 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-4 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: center;\n",
       "  justify-content: center;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"â¸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"â¾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-4 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-4 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-4 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-4 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-4 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-3) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  border: var(--sklearn-color-fitted-level-0) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-0);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  border: var(--sklearn-color-fitted-level-0) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-0);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-4 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table {\n",
       "    font-family: monospace;\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table summary::marker {\n",
       "    font-size: 0.7rem;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "    margin-top: 0;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       "/*\n",
       "    `table td`is set in notebook with right text-align.\n",
       "    We need to overwrite it.\n",
       "*/\n",
       ".estimator-table table td.param {\n",
       "    text-align: left;\n",
       "    position: relative;\n",
       "    padding: 0;\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left !important;\n",
       "}\n",
       "\n",
       ".user-set td.value {\n",
       "    color:rgb(255, 94, 0);\n",
       "    background-color: transparent;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left !important;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       "/*\n",
       "    Styles for parameter documentation links\n",
       "    We need styling for visited so jupyter doesn't overwrite it\n",
       "*/\n",
       "a.param-doc-link,\n",
       "a.param-doc-link:link,\n",
       "a.param-doc-link:visited {\n",
       "    text-decoration: underline dashed;\n",
       "    text-underline-offset: .3em;\n",
       "    color: inherit;\n",
       "    display: block;\n",
       "    padding: .5em;\n",
       "}\n",
       "\n",
       "/* \"hack\" to make the entire area of the cell containing the link clickable */\n",
       "a.param-doc-link::before {\n",
       "    position: absolute;\n",
       "    content: \"\";\n",
       "    inset: 0;\n",
       "}\n",
       "\n",
       ".param-doc-description {\n",
       "    display: none;\n",
       "    position: absolute;\n",
       "    z-index: 9999;\n",
       "    left: 0;\n",
       "    padding: .5ex;\n",
       "    margin-left: 1.5em;\n",
       "    color: var(--sklearn-color-text);\n",
       "    box-shadow: .3em .3em .4em #999;\n",
       "    width: max-content;\n",
       "    text-align: left;\n",
       "    max-height: 10em;\n",
       "    overflow-y: auto;\n",
       "\n",
       "    /* unfitted */\n",
       "    background: var(--sklearn-color-unfitted-level-0);\n",
       "    border: thin solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       "/* Fitted state for parameter tooltips */\n",
       ".fitted .param-doc-description {\n",
       "    /* fitted */\n",
       "    background: var(--sklearn-color-fitted-level-0);\n",
       "    border: thin solid var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".param-doc-link:hover .param-doc-description {\n",
       "    display: block;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                    callbacks=None, colsample_bylevel=None,\n",
       "                                    colsample_bynode=None,\n",
       "                                    colsample_bytree=None, device=None,\n",
       "                                    early_stopping_rounds=None,\n",
       "                                    enable_categorical=False, eval_metric=None,\n",
       "                                    feature_types=None, feature_weights=None,\n",
       "                                    gamma=None, grow_policy=None,\n",
       "                                    importance_type=None,\n",
       "                                    interaction_constraints=None...\n",
       "                                    max_depth=None, max_leaves=None,\n",
       "                                    min_child_weight=None, missing=nan,\n",
       "                                    monotone_constraints=None,\n",
       "                                    multi_strategy=None, n_estimators=None,\n",
       "                                    n_jobs=None, num_parallel_tree=None, ...),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;colsample_bytree&#x27;: [0.8, 1.0],\n",
       "                         &#x27;learning_rate&#x27;: [0.01, 0.1, 0.3],\n",
       "                         &#x27;max_depth&#x27;: [3, 5, 7],\n",
       "                         &#x27;n_estimators&#x27;: [100, 200, 300],\n",
       "                         &#x27;subsample&#x27;: [0.8, 1.0]},\n",
       "             scoring=&#x27;neg_mean_squared_error&#x27;, verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>GridSearchCV</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html\">?<span>Documentation for GridSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('estimator',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=estimator,-estimator%20object\">\n",
       "            estimator\n",
       "            <span class=\"param-doc-description\">estimator: estimator object<br><br>This is assumed to implement the scikit-learn estimator interface.<br>Either estimator needs to provide a ``score`` function,<br>or ``scoring`` must be passed.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">XGBRegressor(...ree=None, ...)</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('param_grid',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=param_grid,-dict%20or%20list%20of%20dictionaries\">\n",
       "            param_grid\n",
       "            <span class=\"param-doc-description\">param_grid: dict or list of dictionaries<br><br>Dictionary with parameters names (`str`) as keys and lists of<br>parameter settings to try as values, or a list of such<br>dictionaries, in which case the grids spanned by each dictionary<br>in the list are explored. This enables searching over any sequence<br>of parameter settings.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">{&#x27;colsample_bytree&#x27;: [0.8, 1.0], &#x27;learning_rate&#x27;: [0.01, 0.1, ...], &#x27;max_depth&#x27;: [3, 5, ...], &#x27;n_estimators&#x27;: [100, 200, ...], ...}</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('scoring',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=scoring,-str%2C%20callable%2C%20list%2C%20tuple%20or%20dict%2C%20default%3DNone\">\n",
       "            scoring\n",
       "            <span class=\"param-doc-description\">scoring: str, callable, list, tuple or dict, default=None<br><br>Strategy to evaluate the performance of the cross-validated model on<br>the test set.<br><br>If `scoring` represents a single score, one can use:<br><br>- a single string (see :ref:`scoring_string_names`);<br>- a callable (see :ref:`scoring_callable`) that returns a single value;<br>- `None`, the `estimator`'s<br>  :ref:`default evaluation criterion <scoring_api_overview>` is used.<br><br>If `scoring` represents multiple scores, one can use:<br><br>- a list or tuple of unique strings;<br>- a callable returning a dictionary where the keys are the metric<br>  names and the values are the metric scores;<br>- a dictionary with metric names as keys and callables as values.<br><br>See :ref:`multimetric_grid_search` for an example.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">&#x27;neg_mean_squared_error&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_jobs',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=n_jobs,-int%2C%20default%3DNone\">\n",
       "            n_jobs\n",
       "            <span class=\"param-doc-description\">n_jobs: int, default=None<br><br>Number of jobs to run in parallel.<br>``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.<br>``-1`` means using all processors. See :term:`Glossary <n_jobs>`<br>for more details.<br><br>.. versionchanged:: v0.20<br>   `n_jobs` default changed from 1 to None</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">-1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('refit',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=refit,-bool%2C%20str%2C%20or%20callable%2C%20default%3DTrue\">\n",
       "            refit\n",
       "            <span class=\"param-doc-description\">refit: bool, str, or callable, default=True<br><br>Refit an estimator using the best found parameters on the whole<br>dataset.<br><br>For multiple metric evaluation, this needs to be a `str` denoting the<br>scorer that would be used to find the best parameters for refitting<br>the estimator at the end.<br><br>Where there are considerations other than maximum score in<br>choosing a best estimator, ``refit`` can be set to a function which<br>returns the selected ``best_index_`` given ``cv_results_``. In that<br>case, the ``best_estimator_`` and ``best_params_`` will be set<br>according to the returned ``best_index_`` while the ``best_score_``<br>attribute will not be available.<br><br>The refitted estimator is made available at the ``best_estimator_``<br>attribute and permits using ``predict`` directly on this<br>``GridSearchCV`` instance.<br><br>Also for multiple metric evaluation, the attributes ``best_index_``,<br>``best_score_`` and ``best_params_`` will only be available if<br>``refit`` is set and all of them will be determined w.r.t this specific<br>scorer.<br><br>See ``scoring`` parameter to know more about multiple metric<br>evaluation.<br><br>See :ref:`sphx_glr_auto_examples_model_selection_plot_grid_search_digits.py`<br>to see how to design a custom selection strategy using a callable<br>via `refit`.<br><br>See :ref:`this example<br><sphx_glr_auto_examples_model_selection_plot_grid_search_refit_callable.py>`<br>for an example of how to use ``refit=callable`` to balance model<br>complexity and cross-validated score.<br><br>.. versionchanged:: 0.20<br>    Support for callable added.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('cv',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=cv,-int%2C%20cross-validation%20generator%20or%20an%20iterable%2C%20default%3DNone\">\n",
       "            cv\n",
       "            <span class=\"param-doc-description\">cv: int, cross-validation generator or an iterable, default=None<br><br>Determines the cross-validation splitting strategy.<br>Possible inputs for cv are:<br><br>- None, to use the default 5-fold cross validation,<br>- integer, to specify the number of folds in a `(Stratified)KFold`,<br>- :term:`CV splitter`,<br>- An iterable yielding (train, test) splits as arrays of indices.<br><br>For integer/None inputs, if the estimator is a classifier and ``y`` is<br>either binary or multiclass, :class:`StratifiedKFold` is used. In all<br>other cases, :class:`KFold` is used. These splitters are instantiated<br>with `shuffle=False` so the splits will be the same across calls.<br><br>Refer :ref:`User Guide <cross_validation>` for the various<br>cross-validation strategies that can be used here.<br><br>.. versionchanged:: 0.22<br>    ``cv`` default value if None changed from 3-fold to 5-fold.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">5</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbose',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=verbose,-int\">\n",
       "            verbose\n",
       "            <span class=\"param-doc-description\">verbose: int<br><br>Controls the verbosity: the higher, the more messages.<br><br>- >1 : the computation time for each fold and parameter candidate is<br>  displayed;<br>- >2 : the score is also displayed;<br>- >3 : the fold and candidate parameter indexes are also displayed<br>  together with the starting time of the computation.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">2</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('pre_dispatch',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=pre_dispatch,-int%2C%20or%20str%2C%20default%3D%272%2An_jobs%27\">\n",
       "            pre_dispatch\n",
       "            <span class=\"param-doc-description\">pre_dispatch: int, or str, default='2*n_jobs'<br><br>Controls the number of jobs that get dispatched during parallel<br>execution. Reducing this number can be useful to avoid an<br>explosion of memory consumption when more jobs get dispatched<br>than CPUs can process. This parameter can be:<br><br>- None, in which case all the jobs are immediately created and spawned. Use<br>  this for lightweight and fast-running jobs, to avoid delays due to on-demand<br>  spawning of the jobs<br>- An int, giving the exact number of total jobs that are spawned<br>- A str, giving an expression as a function of n_jobs, as in '2*n_jobs'</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">&#x27;2*n_jobs&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('error_score',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=error_score,-%27raise%27%20or%20numeric%2C%20default%3Dnp.nan\">\n",
       "            error_score\n",
       "            <span class=\"param-doc-description\">error_score: 'raise' or numeric, default=np.nan<br><br>Value to assign to the score if an error occurs in estimator fitting.<br>If set to 'raise', the error is raised. If a numeric value is given,<br>FitFailedWarning is raised. This parameter does not affect the refit<br>step, which will always raise the error.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">nan</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('return_train_score',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=return_train_score,-bool%2C%20default%3DFalse\">\n",
       "            return_train_score\n",
       "            <span class=\"param-doc-description\">return_train_score: bool, default=False<br><br>If ``False``, the ``cv_results_`` attribute will not include training<br>scores.<br>Computing training scores is used to get insights on how different<br>parameter settings impact the overfitting/underfitting trade-off.<br>However computing the scores on the training set can be computationally<br>expensive and is not strictly required to select the parameters that<br>yield the best generalization performance.<br><br>.. versionadded:: 0.19<br><br>.. versionchanged:: 0.21<br>    Default value was changed from ``True`` to ``False``</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>best_estimator_: XGBRegressor</div></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"best_estimator___\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=0.8, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             feature_weights=None, gamma=None, grow_policy=None,\n",
       "             importance_type=None, interaction_constraints=None,\n",
       "             learning_rate=0.1, max_bin=None, max_cat_threshold=None,\n",
       "             max_cat_to_onehot=None, max_delta_step=None, max_depth=7,\n",
       "             max_leaves=None, min_child_weight=None, missing=nan,\n",
       "             monotone_constraints=None, multi_strategy=None, n_estimators=300,\n",
       "             n_jobs=None, num_parallel_tree=None, ...)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>XGBRegressor</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor\">?<span>Documentation for XGBRegressor</span></a></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"best_estimator___\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('objective',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=objective,-str%20%7C%20xgboost.sklearn._SklObjWProto%20%7C%20typing.Callable%5B%5Btyping.Any%2C%20typing.Any%5D%2C%20typing.Tuple%5Bnumpy.ndarray%2C%20numpy.ndarray%5D%5D%20%7C%20None\">\n",
       "            objective\n",
       "            <span class=\"param-doc-description\">objective: str | xgboost.sklearn._SklObjWProto | typing.Callable[[typing.Any, typing.Any], typing.Tuple[numpy.ndarray, numpy.ndarray]] | None<br><br>Specify the learning task and the corresponding learning objective or a custom<br>objective function to be used.<br><br>For custom objective, see :doc:`/tutorials/custom_metric_obj` and<br>:ref:`custom-obj-metric` for more information, along with the end note for<br>function signatures.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">&#x27;reg:squarederror&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('base_score',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=base_score,-float%20%7C%20typing.List%5Bfloat%5D%20%7C%20None\">\n",
       "            base_score\n",
       "            <span class=\"param-doc-description\">base_score: float | typing.List[float] | None<br><br>The initial prediction score of all instances, global bias.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('booster',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">booster</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('callbacks',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=callbacks,-typing.List%5Bxgboost.callback.TrainingCallback%5D%20%7C%20None\">\n",
       "            callbacks\n",
       "            <span class=\"param-doc-description\">callbacks: typing.List[xgboost.callback.TrainingCallback] | None<br><br>List of callback functions that are applied at end of each iteration.<br>It is possible to use predefined callbacks by using<br>:ref:`Callback API <callback_api>`.<br><br>.. note::<br><br>   States in callback are not preserved during training, which means callback<br>   objects can not be reused for multiple training sessions without<br>   reinitialization or deepcopy.<br><br>.. code-block:: python<br><br>    for params in parameters_grid:<br>        # be sure to (re)initialize the callbacks before each run<br>        callbacks = [xgb.callback.LearningRateScheduler(custom_rates)]<br>        reg = xgboost.XGBRegressor(**params, callbacks=callbacks)<br>        reg.fit(X, y)</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('colsample_bylevel',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=colsample_bylevel,-float%20%7C%20None\">\n",
       "            colsample_bylevel\n",
       "            <span class=\"param-doc-description\">colsample_bylevel: float | None<br><br>Subsample ratio of columns for each level.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('colsample_bynode',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=colsample_bynode,-float%20%7C%20None\">\n",
       "            colsample_bynode\n",
       "            <span class=\"param-doc-description\">colsample_bynode: float | None<br><br>Subsample ratio of columns for each split.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('colsample_bytree',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=colsample_bytree,-float%20%7C%20None\">\n",
       "            colsample_bytree\n",
       "            <span class=\"param-doc-description\">colsample_bytree: float | None<br><br>Subsample ratio of columns when constructing each tree.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0.8</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('device',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=device,-str%20%7C%20None\">\n",
       "            device\n",
       "            <span class=\"param-doc-description\">device: str | None<br><br>.. versionadded:: 2.0.0<br><br>Device ordinal, available options are `cpu`, `cuda`, and `gpu`.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('early_stopping_rounds',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=early_stopping_rounds,-int%20%7C%20None\">\n",
       "            early_stopping_rounds\n",
       "            <span class=\"param-doc-description\">early_stopping_rounds: int | None<br><br>.. versionadded:: 1.6.0<br><br>- Activates early stopping. Validation metric needs to improve at least once in<br>  every **early_stopping_rounds** round(s) to continue training.  Requires at<br>  least one item in **eval_set** in :py:meth:`fit`.<br><br>- If early stopping occurs, the model will have two additional attributes:<br>  :py:attr:`best_score` and :py:attr:`best_iteration`. These are used by the<br>  :py:meth:`predict` and :py:meth:`apply` methods to determine the optimal<br>  number of trees during inference. If users want to access the full model<br>  (including trees built after early stopping), they can specify the<br>  `iteration_range` in these inference methods. In addition, other utilities<br>  like model plotting can also use the entire model.<br><br>- If you prefer to discard the trees after `best_iteration`, consider using the<br>  callback function :py:class:`xgboost.callback.EarlyStopping`.<br><br>- If there's more than one item in **eval_set**, the last entry will be used for<br>  early stopping.  If there's more than one metric in **eval_metric**, the last<br>  metric will be used for early stopping.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('enable_categorical',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=enable_categorical,-bool\">\n",
       "            enable_categorical\n",
       "            <span class=\"param-doc-description\">enable_categorical: bool<br><br>See the same parameter of :py:class:`DMatrix` for details.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('eval_metric',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=eval_metric,-str%20%7C%20typing.List%5Bstr%20%7C%20typing.Callable%5D%20%7C%20typing.Callable%20%7C%20None\">\n",
       "            eval_metric\n",
       "            <span class=\"param-doc-description\">eval_metric: str | typing.List[str | typing.Callable] | typing.Callable | None<br><br>.. versionadded:: 1.6.0<br><br>Metric used for monitoring the training result and early stopping.  It can be a<br>string or list of strings as names of predefined metric in XGBoost (See<br>:doc:`/parameter`), one of the metrics in :py:mod:`sklearn.metrics`, or any<br>other user defined metric that looks like `sklearn.metrics`.<br><br>If custom objective is also provided, then custom metric should implement the<br>corresponding reverse link function.<br><br>Unlike the `scoring` parameter commonly used in scikit-learn, when a callable<br>object is provided, it's assumed to be a cost function and by default XGBoost<br>will minimize the result during early stopping.<br><br>For advanced usage on Early stopping like directly choosing to maximize instead<br>of minimize, see :py:obj:`xgboost.callback.EarlyStopping`.<br><br>See :doc:`/tutorials/custom_metric_obj` and :ref:`custom-obj-metric` for more<br>information.<br><br>.. code-block:: python<br><br>    from sklearn.datasets import load_diabetes<br>    from sklearn.metrics import mean_absolute_error<br>    X, y = load_diabetes(return_X_y=True)<br>    reg = xgb.XGBRegressor(<br>        tree_method=\"hist\",<br>        eval_metric=mean_absolute_error,<br>    )<br>    reg.fit(X, y, eval_set=[(X, y)])</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('feature_types',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=feature_types,-typing.Sequence%5Bstr%5D%20%7C%20None\">\n",
       "            feature_types\n",
       "            <span class=\"param-doc-description\">feature_types: typing.Sequence[str] | None<br><br>.. versionadded:: 1.7.0<br><br>Used for specifying feature types without constructing a dataframe. See<br>the :py:class:`DMatrix` for details.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('feature_weights',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=feature_weights,-Optional%5BArrayLike%5D\">\n",
       "            feature_weights\n",
       "            <span class=\"param-doc-description\">feature_weights: Optional[ArrayLike]<br><br>Weight for each feature, defines the probability of each feature being selected<br>when colsample is being used.  All values must be greater than 0, otherwise a<br>`ValueError` is thrown.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('gamma',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=gamma,-float%20%7C%20None\">\n",
       "            gamma\n",
       "            <span class=\"param-doc-description\">gamma: float | None<br><br>(min_split_loss) Minimum loss reduction required to make a further partition on<br>a leaf node of the tree.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('grow_policy',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=grow_policy,-str%20%7C%20None\">\n",
       "            grow_policy\n",
       "            <span class=\"param-doc-description\">grow_policy: str | None<br><br>Tree growing policy.<br><br>- depthwise: Favors splitting at nodes closest to the node,<br>- lossguide: Favors splitting at nodes with highest loss change.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('importance_type',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">importance_type</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('interaction_constraints',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=interaction_constraints,-str%20%7C%20typing.List%5Btyping.Tuple%5Bstr%5D%5D%20%7C%20None\">\n",
       "            interaction_constraints\n",
       "            <span class=\"param-doc-description\">interaction_constraints: str | typing.List[typing.Tuple[str]] | None<br><br>Constraints for interaction representing permitted interactions.  The<br>constraints must be specified in the form of a nested list, e.g. ``[[0, 1], [2,<br>3, 4]]``, where each inner list is a group of indices of features that are<br>allowed to interact with each other.  See :doc:`tutorial<br></tutorials/feature_interaction_constraint>` for more information</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('learning_rate',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=learning_rate,-float%20%7C%20None\">\n",
       "            learning_rate\n",
       "            <span class=\"param-doc-description\">learning_rate: float | None<br><br>Boosting learning rate (xgb's \"eta\")</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0.1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_bin',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=max_bin,-int%20%7C%20None\">\n",
       "            max_bin\n",
       "            <span class=\"param-doc-description\">max_bin: int | None<br><br>If using histogram-based algorithm, maximum number of bins per feature</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_cat_threshold',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=max_cat_threshold,-int%20%7C%20None\">\n",
       "            max_cat_threshold\n",
       "            <span class=\"param-doc-description\">max_cat_threshold: int | None<br><br>.. versionadded:: 1.7.0<br><br>.. note:: This parameter is experimental<br><br>Maximum number of categories considered for each split. Used only by<br>partition-based splits for preventing over-fitting. Also, `enable_categorical`<br>needs to be set to have categorical feature support. See :doc:`Categorical Data<br></tutorials/categorical>` and :ref:`cat-param` for details.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_cat_to_onehot',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=max_cat_to_onehot,-Optional%5Bint%5D\">\n",
       "            max_cat_to_onehot\n",
       "            <span class=\"param-doc-description\">max_cat_to_onehot: Optional[int]<br><br>.. versionadded:: 1.6.0<br><br>.. note:: This parameter is experimental<br><br>A threshold for deciding whether XGBoost should use one-hot encoding based split<br>for categorical data.  When number of categories is lesser than the threshold<br>then one-hot encoding is chosen, otherwise the categories will be partitioned<br>into children nodes. Also, `enable_categorical` needs to be set to have<br>categorical feature support. See :doc:`Categorical Data<br></tutorials/categorical>` and :ref:`cat-param` for details.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_delta_step',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=max_delta_step,-float%20%7C%20None\">\n",
       "            max_delta_step\n",
       "            <span class=\"param-doc-description\">max_delta_step: float | None<br><br>Maximum delta step we allow each tree's weight estimation to be.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_depth',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=max_depth,-%20int%20%7C%20None\">\n",
       "            max_depth\n",
       "            <span class=\"param-doc-description\">max_depth:  int | None<br><br>Maximum tree depth for base learners.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">7</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_leaves',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=max_leaves,-int%20%7C%20None\">\n",
       "            max_leaves\n",
       "            <span class=\"param-doc-description\">max_leaves: int | None<br><br>Maximum number of leaves; 0 indicates no limit.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_child_weight',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=min_child_weight,-float%20%7C%20None\">\n",
       "            min_child_weight\n",
       "            <span class=\"param-doc-description\">min_child_weight: float | None<br><br>Minimum sum of instance weight(hessian) needed in a child.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('missing',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=missing,-float\">\n",
       "            missing\n",
       "            <span class=\"param-doc-description\">missing: float<br><br>Value in the data which needs to be present as a missing value. Default to<br>:py:data:`numpy.nan`.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">nan</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('monotone_constraints',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=monotone_constraints,-typing.Dict%5Bstr%2C%20int%5D%20%7C%20str%20%7C%20None\">\n",
       "            monotone_constraints\n",
       "            <span class=\"param-doc-description\">monotone_constraints: typing.Dict[str, int] | str | None<br><br>Constraint of variable monotonicity.  See :doc:`tutorial </tutorials/monotonic>`<br>for more information.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('multi_strategy',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=multi_strategy,-str%20%7C%20None\">\n",
       "            multi_strategy\n",
       "            <span class=\"param-doc-description\">multi_strategy: str | None<br><br>.. versionadded:: 2.0.0<br><br>.. note:: This parameter is working-in-progress.<br><br>The strategy used for training multi-target models, including multi-target<br>regression and multi-class classification. See :doc:`/tutorials/multioutput` for<br>more information.<br><br>- ``one_output_per_tree``: One model for each target.<br>- ``multi_output_tree``:  Use multi-target trees.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_estimators',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=n_estimators,-int%20%7C%20None\">\n",
       "            n_estimators\n",
       "            <span class=\"param-doc-description\">n_estimators: int | None<br><br>Number of gradient boosted trees.  Equivalent to number of boosting<br>rounds.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">300</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_jobs',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=n_jobs,-int%20%7C%20None\">\n",
       "            n_jobs\n",
       "            <span class=\"param-doc-description\">n_jobs: int | None<br><br>Number of parallel threads used to run xgboost.  When used with other<br>Scikit-Learn algorithms like grid search, you may choose which algorithm to<br>parallelize and balance the threads.  Creating thread contention will<br>significantly slow down both algorithms.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('num_parallel_tree',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">num_parallel_tree</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('random_state',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=random_state,-numpy.random.mtrand.RandomState%20%7C%20numpy.random._generator.Generator%20%7C%20int%20%7C%20None\">\n",
       "            random_state\n",
       "            <span class=\"param-doc-description\">random_state: numpy.random.mtrand.RandomState | numpy.random._generator.Generator | int | None<br><br>Random number seed.<br><br>.. note::<br><br>   Using gblinear booster with shotgun updater is nondeterministic as<br>   it uses Hogwild algorithm.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">5</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('reg_alpha',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=reg_alpha,-float%20%7C%20None\">\n",
       "            reg_alpha\n",
       "            <span class=\"param-doc-description\">reg_alpha: float | None<br><br>L1 regularization term on weights (xgb's alpha).</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('reg_lambda',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=reg_lambda,-float%20%7C%20None\">\n",
       "            reg_lambda\n",
       "            <span class=\"param-doc-description\">reg_lambda: float | None<br><br>L2 regularization term on weights (xgb's lambda).</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('sampling_method',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=sampling_method,-str%20%7C%20None\">\n",
       "            sampling_method\n",
       "            <span class=\"param-doc-description\">sampling_method: str | None<br><br>Sampling method. Used only by the GPU version of ``hist`` tree method.<br><br>- ``uniform``: Select random training instances uniformly.<br>- ``gradient_based``: Select random training instances with higher probability<br>    when the gradient and hessian are larger. (cf. CatBoost)</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('scale_pos_weight',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=scale_pos_weight,-float%20%7C%20None\">\n",
       "            scale_pos_weight\n",
       "            <span class=\"param-doc-description\">scale_pos_weight: float | None<br><br>Balancing of positive and negative weights.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('subsample',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=subsample,-float%20%7C%20None\">\n",
       "            subsample\n",
       "            <span class=\"param-doc-description\">subsample: float | None<br><br>Subsample ratio of the training instance.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">1.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('tree_method',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=tree_method,-str%20%7C%20None\">\n",
       "            tree_method\n",
       "            <span class=\"param-doc-description\">tree_method: str | None<br><br>Specify which tree method to use.  Default to auto.  If this parameter is set to<br>default, XGBoost will choose the most conservative option available.  It's<br>recommended to study this option from the parameters document :doc:`tree method<br></treemethod>`</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('validate_parameters',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=validate_parameters,-bool%20%7C%20None\">\n",
       "            validate_parameters\n",
       "            <span class=\"param-doc-description\">validate_parameters: bool | None<br><br>Give warnings for unknown parameter.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbosity',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=verbosity,-int%20%7C%20None\">\n",
       "            verbosity\n",
       "            <span class=\"param-doc-description\">verbosity: int | None<br><br>The degree of verbosity. Valid values are 0 (silent) - 3 (debug).</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div></div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.copy-paste-icon').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling\n",
       "        .textContent.trim().split(' ')[0];\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "\n",
       "\n",
       "/**\n",
       " * Adapted from Skrub\n",
       " * https://github.com/skrub-data/skrub/blob/403466d1d5d4dc76a7ef569b3f8228db59a31dc3/skrub/_reporting/_data/templates/report.js#L789\n",
       " * @returns \"light\" or \"dark\"\n",
       " */\n",
       "function detectTheme(element) {\n",
       "    const body = document.querySelector('body');\n",
       "\n",
       "    // Check VSCode theme\n",
       "    const themeKindAttr = body.getAttribute('data-vscode-theme-kind');\n",
       "    const themeNameAttr = body.getAttribute('data-vscode-theme-name');\n",
       "\n",
       "    if (themeKindAttr && themeNameAttr) {\n",
       "        const themeKind = themeKindAttr.toLowerCase();\n",
       "        const themeName = themeNameAttr.toLowerCase();\n",
       "\n",
       "        if (themeKind.includes(\"dark\") || themeName.includes(\"dark\")) {\n",
       "            return \"dark\";\n",
       "        }\n",
       "        if (themeKind.includes(\"light\") || themeName.includes(\"light\")) {\n",
       "            return \"light\";\n",
       "        }\n",
       "    }\n",
       "\n",
       "    // Check Jupyter theme\n",
       "    if (body.getAttribute('data-jp-theme-light') === 'false') {\n",
       "        return 'dark';\n",
       "    } else if (body.getAttribute('data-jp-theme-light') === 'true') {\n",
       "        return 'light';\n",
       "    }\n",
       "\n",
       "    // Guess based on a parent element's color\n",
       "    const color = window.getComputedStyle(element.parentNode, null).getPropertyValue('color');\n",
       "    const match = color.match(/^rgb\\s*\\(\\s*(\\d+)\\s*,\\s*(\\d+)\\s*,\\s*(\\d+)\\s*\\)\\s*$/i);\n",
       "    if (match) {\n",
       "        const [r, g, b] = [\n",
       "            parseFloat(match[1]),\n",
       "            parseFloat(match[2]),\n",
       "            parseFloat(match[3])\n",
       "        ];\n",
       "\n",
       "        // https://en.wikipedia.org/wiki/HSL_and_HSV#Lightness\n",
       "        const luma = 0.299 * r + 0.587 * g + 0.114 * b;\n",
       "\n",
       "        if (luma > 180) {\n",
       "            // If the text is very bright we have a dark theme\n",
       "            return 'dark';\n",
       "        }\n",
       "        if (luma < 75) {\n",
       "            // If the text is very dark we have a light theme\n",
       "            return 'light';\n",
       "        }\n",
       "        // Otherwise fall back to the next heuristic.\n",
       "    }\n",
       "\n",
       "    // Fallback to system preference\n",
       "    return window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'light';\n",
       "}\n",
       "\n",
       "\n",
       "function forceTheme(elementId) {\n",
       "    const estimatorElement = document.querySelector(`#${elementId}`);\n",
       "    if (estimatorElement === null) {\n",
       "        console.error(`Element with id ${elementId} not found.`);\n",
       "    } else {\n",
       "        const theme = detectTheme(estimatorElement);\n",
       "        estimatorElement.classList.add(theme);\n",
       "    }\n",
       "}\n",
       "\n",
       "forceTheme('sk-container-id-4');</script></body>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                    callbacks=None, colsample_bylevel=None,\n",
       "                                    colsample_bynode=None,\n",
       "                                    colsample_bytree=None, device=None,\n",
       "                                    early_stopping_rounds=None,\n",
       "                                    enable_categorical=False, eval_metric=None,\n",
       "                                    feature_types=None, feature_weights=None,\n",
       "                                    gamma=None, grow_policy=None,\n",
       "                                    importance_type=None,\n",
       "                                    interaction_constraints=None...\n",
       "                                    max_depth=None, max_leaves=None,\n",
       "                                    min_child_weight=None, missing=nan,\n",
       "                                    monotone_constraints=None,\n",
       "                                    multi_strategy=None, n_estimators=None,\n",
       "                                    n_jobs=None, num_parallel_tree=None, ...),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'colsample_bytree': [0.8, 1.0],\n",
       "                         'learning_rate': [0.01, 0.1, 0.3],\n",
       "                         'max_depth': [3, 5, 7],\n",
       "                         'n_estimators': [100, 200, 300],\n",
       "                         'subsample': [0.8, 1.0]},\n",
       "             scoring='neg_mean_squared_error', verbose=2)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## use gardient search\n",
    "X_train, X_test, y_train, y_test = train_test_split(king_hs_X_clean[top_features], king_hs_y, random_state=random_state, test_size=0.2)\n",
    "\n",
    "# Define the XGBoost model\n",
    "xgb_model = XGBRegressor(random_state=random_state, objective='reg:squarederror')\n",
    "\n",
    "# Define parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.01, 0.1, 0.3],\n",
    "    'subsample': [0.8, 1.0],\n",
    "    'colsample_bytree': [0.8, 1.0]\n",
    "}\n",
    "\n",
    "# Create GridSearchCV\n",
    "grid_search = GridSearchCV( ##RandomizedSearchCV , GridSearchCV\n",
    "    estimator=xgb_model,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,\n",
    "    scoring='neg_mean_squared_error',  # or 'r2', 'neg_mean_absolute_error'\n",
    "    verbose=2,\n",
    "    n_jobs=-1  # Use all processors\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "print(\"Starting Grid Search...\")\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba612d46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>r2_score</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td>0.974040</td>\n",
       "      <td>51158.568236</td>\n",
       "      <td>36277.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>0.905079</td>\n",
       "      <td>98105.711475</td>\n",
       "      <td>63687.796875</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       r2_score          RMSE           MAE\n",
       "train  0.974040  51158.568236  36277.750000\n",
       "test   0.905079  98105.711475  63687.796875"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the best model\n",
    "best_xgb = grid_search.best_estimator_\n",
    "\n",
    "### On train set\n",
    "y_pred_tr = best_xgb.predict(X_train)\n",
    "eval_tr = pd.DataFrame([r2_score(y_train, y_pred_tr), np.sqrt(mean_squared_error(y_train, y_pred_tr)), mean_absolute_error(y_train, y_pred_tr)], index=['r2_score', 'RMSE', 'MAE']).T\n",
    "\n",
    "# Evaluate on test set\n",
    "y_pred = best_xgb.predict(X_test)\n",
    "eval_ts = pd.DataFrame([r2_score(y_test, y_pred), np.sqrt(mean_squared_error(y_test, y_pred)), mean_absolute_error(y_test, y_pred)], index=['r2_score', 'RMSE', 'MAE']).T\n",
    "\n",
    "eval = pd.concat([eval_tr,eval_ts])\n",
    "eval.index=['train', 'test']\n",
    "eval\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30bf1b25",
   "metadata": {},
   "source": [
    "- Drop in the model when using only top 10 features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cae5d10",
   "metadata": {},
   "source": [
    "#### PLS to learn linear features for the rest 5 features >> compress into two features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9d2ee98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### PLS\n",
    "X_train, X_test, y_train, y_test = train_test_split(king_hs_X_clean[best_features], king_hs_y, random_state=random_state, test_size=0.2)\n",
    "\n",
    "# scaler = StandardScaler()\n",
    "# X_train_scaled = scaler.fit_transform(X_train)\n",
    "# X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "4758a90d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fitting PLS with 2 components...\n",
      "PLS is learning components that are correlated with price (Y)\n",
      "\n",
      "Created 2 new PLS features!\n",
      "These features are engineered to predict price well\n"
     ]
    }
   ],
   "source": [
    "# PLS FOR FEATURE ENGINEERING:\n",
    "n_components = 2\n",
    "pls = PLSRegression(n_components=n_components, scale=False)\n",
    "\n",
    "print(f\"\\nFitting PLS with {n_components} components...\")\n",
    "print(\"PLS is learning components that are correlated with price (Y)\")\n",
    "pls.fit(X_train[rest_rf], y_train)\n",
    "\n",
    "# Step 3: Transform X to get new features (PLS components)\n",
    "X_train_pls = pls.transform(X_train[rest_rf])\n",
    "X_test_pls = pls.transform(X_test[rest_rf])\n",
    "\n",
    "print(f\"\\nCreated {n_components} new PLS features!\")\n",
    "print(\"These features are engineered to predict price well\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0da1c6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_top_pls = pd.concat([X_train[top_features].reset_index(drop=True), pd.DataFrame(X_train_pls)], axis=1)\n",
    "# X_train_top_pls = pd.concat([X_test[top_features].reset_index(drop=True), pd.DataFrame(X_test_pls)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "45f11f9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "XGBoost on PLS components:\n",
      "  RMSE: 95,091.97\n",
      "MAE: 62,238.78\n",
      "  RÂ²: 0.9108\n"
     ]
    }
   ],
   "source": [
    "# USING PLS COMPONENTS AS FEATURES\n",
    "\n",
    "# with XGBoost\n",
    "xgb = XGBRegressor(n_estimators=300, random_state=42, verbosity=0, colsample_bytree= 0.8, learning_rate= 0.1, max_depth = 7, subsample=1.0)\n",
    "xgb.fit(pd.concat([X_train[top_features].reset_index(drop=True), pd.DataFrame(X_train_pls)], axis=1), y_train)\n",
    "y_pred_xgb = xgb.predict(pd.concat([X_test[top_features].reset_index(drop=True), pd.DataFrame(X_test_pls)], axis=1))\n",
    "\n",
    "print(\"\\nXGBoost on PLS components:\")\n",
    "print(f\"  RMSE: {np.sqrt(mean_squared_error(y_test, y_pred_xgb)):,.2f}\")\n",
    "print(f\"MAE: {mean_absolute_error(y_test, y_pred_xgb):,.2f}\")\n",
    "print(f\"  RÂ²: {r2_score(y_test, y_pred_xgb):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ee647c09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>r2_score</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td>0.979675</td>\n",
       "      <td>45267.001668</td>\n",
       "      <td>32196.177734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>0.910821</td>\n",
       "      <td>95091.972322</td>\n",
       "      <td>62238.777344</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       r2_score          RMSE           MAE\n",
       "train  0.979675  45267.001668  32196.177734\n",
       "test   0.910821  95091.972322  62238.777344"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_xgb_tr = xgb.predict(pd.concat([X_train[top_features].reset_index(drop=True), pd.DataFrame(X_train_pls)], axis=1))\n",
    "\n",
    "eval_tr = pd.DataFrame([r2_score(y_train, y_pred_xgb_tr), np.sqrt(mean_squared_error(y_train, y_pred_xgb_tr)), mean_absolute_error(y_train, y_pred_xgb_tr)], index=['r2_score', 'RMSE', 'MAE']).T\n",
    "\n",
    "y_pred_xgb = xgb.predict(pd.concat([X_test[top_features].reset_index(drop=True), pd.DataFrame(X_test_pls)], axis=1))\n",
    "eval_ts = pd.DataFrame([r2_score(y_test, y_pred_xgb), np.sqrt(mean_squared_error(y_test, y_pred_xgb)), mean_absolute_error(y_test, y_pred_xgb)], index=['r2_score', 'RMSE', 'MAE']).T\n",
    "\n",
    "eval = pd.concat([eval_tr,eval_ts])\n",
    "eval.index=['train', 'test']\n",
    "eval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4dc33f5",
   "metadata": {},
   "source": [
    "## Xgboost with new feature engeineering and scaled y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "14d9f327",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# 1. LOAD AND CLEAN\n",
    "full_path = \"data/df_fe.csv\"\n",
    "king_hs = pd.read_csv(full_path)\n",
    "\n",
    "\n",
    "# Fix the 33-bedroom outlier (likely a typo for 3)\n",
    "king_hs.loc[king_hs['bedrooms'] == 33, 'bedrooms'] = 3\n",
    "\n",
    "# 2. SEATTLE DISTANCE (The 'Location' Gamechanger)\n",
    "def haversine_distance(lat1, lon1, lat2, lon2):\n",
    "    r = 6371 # Earth radius in km\n",
    "    phi1, phi2 = np.radians(lat1), np.radians(lat2)\n",
    "    dphi = np.radians(lat2 - lat1)\n",
    "    dlambda = np.radians(lon2 - lon1)\n",
    "    a = np.sin(dphi / 2)**2 + np.cos(phi1) * np.cos(phi2) * np.sin(dlambda / 2)**2\n",
    "    return 2 * r * np.arctan2(np.sqrt(a), np.sqrt(1 - a))\n",
    "\n",
    "# Downtown Seattle coords\n",
    "seattle_lat, seattle_long = 47.6062, -122.3321\n",
    "king_hs['dist_seattle'] = haversine_distance(king_hs['lat'], king_hs['long'], seattle_lat, seattle_long)\n",
    "\n",
    "# 3. REGENERATE CLUSTERS\n",
    "scaler = StandardScaler()\n",
    "coords_scaled = scaler.fit_transform(king_hs[['long', 'lat']])\n",
    "kmeans = KMeans(n_clusters=50, random_state=42, n_init=10)\n",
    "king_hs['loc_clusters'] = kmeans.fit_predict(coords_scaled)\n",
    "\n",
    "# 4. FEATURE ENGINEERING (Ratios and Interactions)\n",
    "king_hs['log_price'] = np.log1p(king_hs['price'])\n",
    "king_hs['total_living_ratio'] = king_hs['sqft_living'] / (king_hs['sqft_lot'] + 1)\n",
    "king_hs['relative_size'] = king_hs['sqft_living'] / (king_hs['sqft_living15'] + 1)\n",
    "king_hs['luxury_index'] = king_hs['grade'] + king_hs['view'] + (king_hs['waterfront'] * 2)\n",
    "king_hs['quality_interaction'] = king_hs['grade'] * king_hs['condition']\n",
    "king_hs['size_grade_interaction'] = king_hs['sqft_living'] * king_hs['grade']\n",
    "\n",
    "# 5. DEFINE FEATURES\n",
    "best_features = [\n",
    "'bathrooms', \n",
    "'sqft_living', \n",
    "'sqft_lot', \n",
    "'sqft_above', \n",
    "'sqft_basement',\n",
    "'lat', 'long', 'sqft_living15', 'sqft_lot15', \"waterfront\", \"view\", \"condition\", \"grade\",\n",
    "\n",
    "'dist_seattle', 'total_living_ratio', 'relative_size',\n",
    " 'luxury_index', 'quality_interaction', 'size_grade_interaction',\n",
    "  \"year_sold\", 'house_age', \"zipcode\", 'loc_clusters'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "209a619a",
   "metadata": {},
   "outputs": [],
   "source": [
    "king_hs_X = king_hs.drop(['price','log_price'], axis=1)\n",
    "king_hs_y = king_hs[['log_price']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "94abc756",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Grid Search...\n",
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.4s[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.5s\n",
      "\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=0.8; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=0.8; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=0.8; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=0.8; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=0.8; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=1.0; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=1.0; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=1.0; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=1.0; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=1.0; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=1.0; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.8; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.8; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0; total time=  -1.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.8; total time=  -1.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.8; total time=  -1.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.8; total time=  -1.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0; total time=  -1.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0; total time=  -1.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0; total time=  -1.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.8; total time=  -1.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.8; total time=  -0.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.8; total time=  -0.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.8; total time=  -0.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.8; total time=  -0.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=1.0; total time=  -0.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=0.8; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=1.0; total time=  -0.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=0.8; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=0.8; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=1.0; total time=   2.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=0.8; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=1.0; total time=  -0.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=0.8; total time=   2.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=1.0; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=1.0; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=1.0; total time=   2.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=1.0; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=1.0; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=1.0; total time=   2.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=0.8; total time=   3.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=0.8; total time=   3.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=0.8; total time=   3.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=0.8; total time=   3.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=0.8; total time=   3.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=1.0; total time=   3.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=1.0; total time=   3.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=1.0; total time=   3.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=1.0; total time=   3.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=1.0; total time=   3.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=0.8; total time=   4.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=0.8; total time=   5.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=0.8; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=0.8; total time=   5.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=1.0; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=0.8; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=1.0; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=0.8; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=0.8; total time=   6.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=0.8; total time=   5.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=0.8; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=1.0; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=1.0; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=1.0; total time=   6.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=1.0; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=0.8; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=1.0; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=1.0; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=1.0; total time=   5.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=1.0; total time=   5.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.8; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.8; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1.0; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=1.0; total time=   5.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=1.0; total time=   5.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=1.0; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.8; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1.0; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=1.0; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.8; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.8; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=1.0; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.8; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=0.8; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=1.0; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=0.8; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.8; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.8; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1.0; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1.0; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1.0; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=1.0; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=1.0; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=0.8; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=0.8; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.8; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=1.0; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=0.8; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=1.0; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=1.0; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=1.0; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.8; total time=   2.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=0.8; total time=   2.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=1.0; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=0.8; total time=   3.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=1.0; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=0.8; total time=   2.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=0.8; total time=   2.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=0.8; total time=   2.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=1.0; total time=   2.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=1.0; total time=   2.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=1.0; total time=   2.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=1.0; total time=   2.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=1.0; total time=   2.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=0.8; total time=   4.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=0.8; total time=   4.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=3, n_estimators=300, subsample=0.8; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=0.8; total time=   4.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=1.0; total time=   3.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=3, n_estimators=300, subsample=0.8; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=0.8; total time=   3.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=3, n_estimators=300, subsample=0.8; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=1.0; total time=   4.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=1.0; total time=   3.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=0.8; total time=   4.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=3, n_estimators=300, subsample=0.8; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=3, n_estimators=300, subsample=1.0; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=3, n_estimators=300, subsample=1.0; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=3, n_estimators=300, subsample=0.8; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=3, n_estimators=300, subsample=1.0; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=3, n_estimators=300, subsample=1.0; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=1.0; total time=   4.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=5, n_estimators=100, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=3, n_estimators=300, subsample=1.0; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=5, n_estimators=100, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=5, n_estimators=100, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=5, n_estimators=100, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=1.0; total time=   4.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=5, n_estimators=100, subsample=1.0; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=5, n_estimators=200, subsample=0.8; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=5, n_estimators=200, subsample=0.8; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=5, n_estimators=200, subsample=1.0; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=5, n_estimators=200, subsample=1.0; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=5, n_estimators=200, subsample=0.8; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=5, n_estimators=200, subsample=0.8; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=5, n_estimators=200, subsample=1.0; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=5, n_estimators=200, subsample=0.8; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=5, n_estimators=200, subsample=1.0; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=5, n_estimators=200, subsample=1.0; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=5, n_estimators=300, subsample=0.8; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=5, n_estimators=300, subsample=0.8; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=5, n_estimators=300, subsample=0.8; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=5, n_estimators=300, subsample=0.8; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=5, n_estimators=300, subsample=0.8; total time=   2.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=5, n_estimators=300, subsample=1.0; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=5, n_estimators=300, subsample=1.0; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=7, n_estimators=100, subsample=0.8; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=7, n_estimators=100, subsample=0.8; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=7, n_estimators=100, subsample=0.8; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=7, n_estimators=100, subsample=1.0; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=5, n_estimators=300, subsample=1.0; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=5, n_estimators=300, subsample=1.0; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=5, n_estimators=300, subsample=1.0; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=7, n_estimators=100, subsample=0.8; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=7, n_estimators=100, subsample=0.8; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=7, n_estimators=100, subsample=1.0; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=7, n_estimators=100, subsample=1.0; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=7, n_estimators=100, subsample=1.0; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=7, n_estimators=100, subsample=1.0; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=7, n_estimators=200, subsample=0.8; total time=   2.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=7, n_estimators=200, subsample=0.8; total time=   2.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=7, n_estimators=200, subsample=1.0; total time=   2.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=7, n_estimators=200, subsample=0.8; total time=   2.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=7, n_estimators=200, subsample=1.0; total time=   2.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=7, n_estimators=200, subsample=1.0; total time=   2.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=7, n_estimators=200, subsample=0.8; total time=   3.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=7, n_estimators=200, subsample=1.0; total time=   3.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=7, n_estimators=200, subsample=0.8; total time=   3.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=7, n_estimators=200, subsample=1.0; total time=   3.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=7, n_estimators=300, subsample=0.8; total time=   4.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=7, n_estimators=300, subsample=0.8; total time=   4.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=7, n_estimators=300, subsample=0.8; total time=   4.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=7, n_estimators=300, subsample=0.8; total time=   4.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8; total time=   1.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=7, n_estimators=300, subsample=0.8; total time=   5.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=7, n_estimators=300, subsample=1.0; total time=   5.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=0.8; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=0.8; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=0.8; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=0.8; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=1.0; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=1.0; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=1.0; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=7, n_estimators=300, subsample=1.0; total time=   4.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=7, n_estimators=300, subsample=1.0; total time=   3.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=1.0; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=0.8; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=7, n_estimators=300, subsample=1.0; total time=   4.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=1.0; total time=   1.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.8; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=7, n_estimators=300, subsample=1.0; total time=   5.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.8; total time=   1.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.8; total time=   1.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.8; total time=   1.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.8; total time=   1.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.8; total time=   1.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0; total time=   1.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0; total time=   1.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0; total time=   1.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0; total time=   2.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0; total time=   1.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.8; total time=   2.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.8; total time=   2.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.8; total time=   2.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.8; total time=   2.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.8; total time=   2.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=1.0; total time=   2.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=0.8; total time=   1.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=0.8; total time=   1.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=1.0; total time=   2.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=1.0; total time=   2.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=1.0; total time=   2.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=0.8; total time=   1.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=0.8; total time=   1.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=1.0; total time=   2.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=0.8; total time=   2.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=1.0; total time=   2.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=1.0; total time=   2.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=1.0; total time=  -0.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=1.0; total time=  -0.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=1.0; total time=  -0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=0.8; total time=   1.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=0.8; total time=   1.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=0.8; total time=   1.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=0.8; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=1.0; total time=   1.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=1.0; total time=   1.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=1.0; total time=   1.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=1.0; total time=   1.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=0.8; total time=   1.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=1.0; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.4s[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.4s\n",
      "\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=0.8; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=0.8; total time=   2.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=0.8; total time=   5.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=0.8; total time=   1.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=1.0; total time=   5.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=0.8; total time=   2.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=0.8; total time=   1.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=0.8; total time=   1.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=0.8; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=0.8; total time=   3.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=1.0; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=0.8; total time=   5.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=1.0; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=1.0; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=1.0; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=1.0; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.8; total time=   1.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.8; total time=   1.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.8; total time=   1.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1.0; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.8; total time=   1.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.8; total time=   1.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1.0; total time=   1.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1.0; total time=   1.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=1.0; total time=   5.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1.0; total time=   1.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1.0; total time=   1.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=1.0; total time=   5.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=1.0; total time=   5.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=1.0; total time=   5.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.8; total time=   1.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.8; total time=   2.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.8; total time=   1.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=1.0; total time=   1.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.8; total time=   1.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=0.8; total time=   1.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=0.8; total time=   1.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=0.8; total time=   1.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=1.0; total time=   2.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.8; total time=   2.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=1.0; total time=   1.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=0.8; total time=   1.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=0.8; total time=   1.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=1.0; total time=   2.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=1.0; total time=   1.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=1.0; total time=   1.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=1.0; total time=   1.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=1.0; total time=   1.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=1.0; total time=   1.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=1.0; total time=   1.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=0.8; total time=   2.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=0.8; total time=   2.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=0.8; total time=   2.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=1.0; total time=   2.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=1.0; total time=   2.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=0.8; total time=   3.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=0.8; total time=   3.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=1.0; total time=   3.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=1.0; total time=   3.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=1.0; total time=   3.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=0.8; total time=   4.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=3, n_estimators=200, subsample=0.8; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=0.8; total time=   4.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=3, n_estimators=200, subsample=0.8; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=0.8; total time=   4.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=3, n_estimators=200, subsample=1.0; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=3, n_estimators=200, subsample=1.0; total time=   1.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=3, n_estimators=300, subsample=0.8; total time=   1.0s[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=1.0; total time=   4.2s\n",
      "\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=3, n_estimators=300, subsample=0.8; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=0.8; total time=   4.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=3, n_estimators=300, subsample=0.8; total time=   1.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=3, n_estimators=300, subsample=0.8; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=3, n_estimators=300, subsample=1.0; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=3, n_estimators=300, subsample=0.8; total time=   1.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=3, n_estimators=300, subsample=1.0; total time=   1.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=0.8; total time=   5.4s[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=3, n_estimators=300, subsample=1.0; total time=   1.4s\n",
      "\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=3, n_estimators=300, subsample=1.0; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=3, n_estimators=300, subsample=1.0; total time=   1.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=5, n_estimators=100, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=5, n_estimators=100, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=5, n_estimators=100, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=1.0; total time=   4.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=5, n_estimators=100, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=1.0; total time=   4.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=5, n_estimators=100, subsample=1.0; total time=   1.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=1.0; total time=   4.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=1.0; total time=   4.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=5, n_estimators=200, subsample=0.8; total time=   1.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=5, n_estimators=200, subsample=0.8; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=5, n_estimators=200, subsample=0.8; total time=   1.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=5, n_estimators=200, subsample=1.0; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=5, n_estimators=200, subsample=1.0; total time=   1.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=5, n_estimators=200, subsample=0.8; total time=   1.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=5, n_estimators=200, subsample=0.8; total time=   1.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=5, n_estimators=200, subsample=1.0; total time=   1.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=5, n_estimators=200, subsample=1.0; total time=   1.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=5, n_estimators=200, subsample=1.0; total time=   1.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=5, n_estimators=300, subsample=0.8; total time=   1.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=5, n_estimators=300, subsample=0.8; total time=   1.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=5, n_estimators=300, subsample=0.8; total time=   1.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=5, n_estimators=300, subsample=1.0; total time=   1.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=5, n_estimators=300, subsample=0.8; total time=   1.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=5, n_estimators=300, subsample=0.8; total time=   2.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=5, n_estimators=300, subsample=1.0; total time=   1.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=5, n_estimators=300, subsample=1.0; total time=   1.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=5, n_estimators=300, subsample=1.0; total time=   1.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=7, n_estimators=100, subsample=0.8; total time=   1.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=7, n_estimators=100, subsample=0.8; total time=   1.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=7, n_estimators=100, subsample=0.8; total time=   1.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=7, n_estimators=100, subsample=0.8; total time=   1.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=5, n_estimators=300, subsample=1.0; total time=   1.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=7, n_estimators=100, subsample=0.8; total time=   1.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=7, n_estimators=100, subsample=1.0; total time=   1.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=7, n_estimators=100, subsample=1.0; total time=   1.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=7, n_estimators=100, subsample=1.0; total time=   1.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=7, n_estimators=100, subsample=1.0; total time=   1.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=7, n_estimators=100, subsample=1.0; total time=   1.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=7, n_estimators=200, subsample=0.8; total time=   3.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=7, n_estimators=200, subsample=0.8; total time=   3.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=7, n_estimators=200, subsample=0.8; total time=   3.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=7, n_estimators=200, subsample=0.8; total time=   3.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=7, n_estimators=200, subsample=1.0; total time=   3.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=7, n_estimators=200, subsample=1.0; total time=   3.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=7, n_estimators=200, subsample=1.0; total time=   3.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=7, n_estimators=200, subsample=1.0; total time=   3.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=7, n_estimators=200, subsample=1.0; total time=   4.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=7, n_estimators=200, subsample=0.8; total time=   4.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=7, n_estimators=300, subsample=1.0; total time=   4.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=7, n_estimators=300, subsample=0.8; total time=   4.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=7, n_estimators=300, subsample=0.8; total time=   4.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=7, n_estimators=300, subsample=0.8; total time=   4.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=7, n_estimators=300, subsample=0.8; total time=   5.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=7, n_estimators=300, subsample=0.8; total time=   5.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=7, n_estimators=300, subsample=1.0; total time=   3.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=7, n_estimators=300, subsample=1.0; total time=   3.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=7, n_estimators=300, subsample=1.0; total time=   3.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=7, n_estimators=300, subsample=1.0; total time=   3.6s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "}\n",
       "\n",
       "#sk-container-id-5.light {\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: black;\n",
       "  --sklearn-color-background: white;\n",
       "  --sklearn-color-border-box: black;\n",
       "  --sklearn-color-icon: #696969;\n",
       "}\n",
       "\n",
       "#sk-container-id-5.dark {\n",
       "  --sklearn-color-text-on-default-background: white;\n",
       "  --sklearn-color-background: #111;\n",
       "  --sklearn-color-border-box: white;\n",
       "  --sklearn-color-icon: #878787;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-5 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-5 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-5 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: center;\n",
       "  justify-content: center;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"â¸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-5 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"â¾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-5 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-5 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-5 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-5 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-5 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-3) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  border: var(--sklearn-color-fitted-level-0) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-0);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  border: var(--sklearn-color-fitted-level-0) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-0);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-5 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-5 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table {\n",
       "    font-family: monospace;\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table summary::marker {\n",
       "    font-size: 0.7rem;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "    margin-top: 0;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       "/*\n",
       "    `table td`is set in notebook with right text-align.\n",
       "    We need to overwrite it.\n",
       "*/\n",
       ".estimator-table table td.param {\n",
       "    text-align: left;\n",
       "    position: relative;\n",
       "    padding: 0;\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left !important;\n",
       "}\n",
       "\n",
       ".user-set td.value {\n",
       "    color:rgb(255, 94, 0);\n",
       "    background-color: transparent;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left !important;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       "/*\n",
       "    Styles for parameter documentation links\n",
       "    We need styling for visited so jupyter doesn't overwrite it\n",
       "*/\n",
       "a.param-doc-link,\n",
       "a.param-doc-link:link,\n",
       "a.param-doc-link:visited {\n",
       "    text-decoration: underline dashed;\n",
       "    text-underline-offset: .3em;\n",
       "    color: inherit;\n",
       "    display: block;\n",
       "    padding: .5em;\n",
       "}\n",
       "\n",
       "/* \"hack\" to make the entire area of the cell containing the link clickable */\n",
       "a.param-doc-link::before {\n",
       "    position: absolute;\n",
       "    content: \"\";\n",
       "    inset: 0;\n",
       "}\n",
       "\n",
       ".param-doc-description {\n",
       "    display: none;\n",
       "    position: absolute;\n",
       "    z-index: 9999;\n",
       "    left: 0;\n",
       "    padding: .5ex;\n",
       "    margin-left: 1.5em;\n",
       "    color: var(--sklearn-color-text);\n",
       "    box-shadow: .3em .3em .4em #999;\n",
       "    width: max-content;\n",
       "    text-align: left;\n",
       "    max-height: 10em;\n",
       "    overflow-y: auto;\n",
       "\n",
       "    /* unfitted */\n",
       "    background: var(--sklearn-color-unfitted-level-0);\n",
       "    border: thin solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       "/* Fitted state for parameter tooltips */\n",
       ".fitted .param-doc-description {\n",
       "    /* fitted */\n",
       "    background: var(--sklearn-color-fitted-level-0);\n",
       "    border: thin solid var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".param-doc-link:hover .param-doc-description {\n",
       "    display: block;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                    callbacks=None, colsample_bylevel=None,\n",
       "                                    colsample_bynode=None,\n",
       "                                    colsample_bytree=None, device=None,\n",
       "                                    early_stopping_rounds=None,\n",
       "                                    enable_categorical=False, eval_metric=None,\n",
       "                                    feature_types=None, feature_weights=None,\n",
       "                                    gamma=None, grow_policy=None,\n",
       "                                    importance_type=None,\n",
       "                                    interaction_constraints=None...\n",
       "                                    max_depth=None, max_leaves=None,\n",
       "                                    min_child_weight=None, missing=nan,\n",
       "                                    monotone_constraints=None,\n",
       "                                    multi_strategy=None, n_estimators=None,\n",
       "                                    n_jobs=None, num_parallel_tree=None, ...),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;colsample_bytree&#x27;: [0.8, 1.0],\n",
       "                         &#x27;learning_rate&#x27;: [0.01, 0.1, 0.3],\n",
       "                         &#x27;max_depth&#x27;: [3, 5, 7],\n",
       "                         &#x27;n_estimators&#x27;: [100, 200, 300],\n",
       "                         &#x27;subsample&#x27;: [0.8, 1.0]},\n",
       "             scoring=&#x27;neg_mean_squared_error&#x27;, verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>GridSearchCV</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html\">?<span>Documentation for GridSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('estimator',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=estimator,-estimator%20object\">\n",
       "            estimator\n",
       "            <span class=\"param-doc-description\">estimator: estimator object<br><br>This is assumed to implement the scikit-learn estimator interface.<br>Either estimator needs to provide a ``score`` function,<br>or ``scoring`` must be passed.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">XGBRegressor(...ree=None, ...)</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('param_grid',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=param_grid,-dict%20or%20list%20of%20dictionaries\">\n",
       "            param_grid\n",
       "            <span class=\"param-doc-description\">param_grid: dict or list of dictionaries<br><br>Dictionary with parameters names (`str`) as keys and lists of<br>parameter settings to try as values, or a list of such<br>dictionaries, in which case the grids spanned by each dictionary<br>in the list are explored. This enables searching over any sequence<br>of parameter settings.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">{&#x27;colsample_bytree&#x27;: [0.8, 1.0], &#x27;learning_rate&#x27;: [0.01, 0.1, ...], &#x27;max_depth&#x27;: [3, 5, ...], &#x27;n_estimators&#x27;: [100, 200, ...], ...}</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('scoring',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=scoring,-str%2C%20callable%2C%20list%2C%20tuple%20or%20dict%2C%20default%3DNone\">\n",
       "            scoring\n",
       "            <span class=\"param-doc-description\">scoring: str, callable, list, tuple or dict, default=None<br><br>Strategy to evaluate the performance of the cross-validated model on<br>the test set.<br><br>If `scoring` represents a single score, one can use:<br><br>- a single string (see :ref:`scoring_string_names`);<br>- a callable (see :ref:`scoring_callable`) that returns a single value;<br>- `None`, the `estimator`'s<br>  :ref:`default evaluation criterion <scoring_api_overview>` is used.<br><br>If `scoring` represents multiple scores, one can use:<br><br>- a list or tuple of unique strings;<br>- a callable returning a dictionary where the keys are the metric<br>  names and the values are the metric scores;<br>- a dictionary with metric names as keys and callables as values.<br><br>See :ref:`multimetric_grid_search` for an example.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">&#x27;neg_mean_squared_error&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_jobs',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=n_jobs,-int%2C%20default%3DNone\">\n",
       "            n_jobs\n",
       "            <span class=\"param-doc-description\">n_jobs: int, default=None<br><br>Number of jobs to run in parallel.<br>``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.<br>``-1`` means using all processors. See :term:`Glossary <n_jobs>`<br>for more details.<br><br>.. versionchanged:: v0.20<br>   `n_jobs` default changed from 1 to None</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">-1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('refit',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=refit,-bool%2C%20str%2C%20or%20callable%2C%20default%3DTrue\">\n",
       "            refit\n",
       "            <span class=\"param-doc-description\">refit: bool, str, or callable, default=True<br><br>Refit an estimator using the best found parameters on the whole<br>dataset.<br><br>For multiple metric evaluation, this needs to be a `str` denoting the<br>scorer that would be used to find the best parameters for refitting<br>the estimator at the end.<br><br>Where there are considerations other than maximum score in<br>choosing a best estimator, ``refit`` can be set to a function which<br>returns the selected ``best_index_`` given ``cv_results_``. In that<br>case, the ``best_estimator_`` and ``best_params_`` will be set<br>according to the returned ``best_index_`` while the ``best_score_``<br>attribute will not be available.<br><br>The refitted estimator is made available at the ``best_estimator_``<br>attribute and permits using ``predict`` directly on this<br>``GridSearchCV`` instance.<br><br>Also for multiple metric evaluation, the attributes ``best_index_``,<br>``best_score_`` and ``best_params_`` will only be available if<br>``refit`` is set and all of them will be determined w.r.t this specific<br>scorer.<br><br>See ``scoring`` parameter to know more about multiple metric<br>evaluation.<br><br>See :ref:`sphx_glr_auto_examples_model_selection_plot_grid_search_digits.py`<br>to see how to design a custom selection strategy using a callable<br>via `refit`.<br><br>See :ref:`this example<br><sphx_glr_auto_examples_model_selection_plot_grid_search_refit_callable.py>`<br>for an example of how to use ``refit=callable`` to balance model<br>complexity and cross-validated score.<br><br>.. versionchanged:: 0.20<br>    Support for callable added.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('cv',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=cv,-int%2C%20cross-validation%20generator%20or%20an%20iterable%2C%20default%3DNone\">\n",
       "            cv\n",
       "            <span class=\"param-doc-description\">cv: int, cross-validation generator or an iterable, default=None<br><br>Determines the cross-validation splitting strategy.<br>Possible inputs for cv are:<br><br>- None, to use the default 5-fold cross validation,<br>- integer, to specify the number of folds in a `(Stratified)KFold`,<br>- :term:`CV splitter`,<br>- An iterable yielding (train, test) splits as arrays of indices.<br><br>For integer/None inputs, if the estimator is a classifier and ``y`` is<br>either binary or multiclass, :class:`StratifiedKFold` is used. In all<br>other cases, :class:`KFold` is used. These splitters are instantiated<br>with `shuffle=False` so the splits will be the same across calls.<br><br>Refer :ref:`User Guide <cross_validation>` for the various<br>cross-validation strategies that can be used here.<br><br>.. versionchanged:: 0.22<br>    ``cv`` default value if None changed from 3-fold to 5-fold.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">5</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbose',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=verbose,-int\">\n",
       "            verbose\n",
       "            <span class=\"param-doc-description\">verbose: int<br><br>Controls the verbosity: the higher, the more messages.<br><br>- >1 : the computation time for each fold and parameter candidate is<br>  displayed;<br>- >2 : the score is also displayed;<br>- >3 : the fold and candidate parameter indexes are also displayed<br>  together with the starting time of the computation.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">2</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('pre_dispatch',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=pre_dispatch,-int%2C%20or%20str%2C%20default%3D%272%2An_jobs%27\">\n",
       "            pre_dispatch\n",
       "            <span class=\"param-doc-description\">pre_dispatch: int, or str, default='2*n_jobs'<br><br>Controls the number of jobs that get dispatched during parallel<br>execution. Reducing this number can be useful to avoid an<br>explosion of memory consumption when more jobs get dispatched<br>than CPUs can process. This parameter can be:<br><br>- None, in which case all the jobs are immediately created and spawned. Use<br>  this for lightweight and fast-running jobs, to avoid delays due to on-demand<br>  spawning of the jobs<br>- An int, giving the exact number of total jobs that are spawned<br>- A str, giving an expression as a function of n_jobs, as in '2*n_jobs'</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">&#x27;2*n_jobs&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('error_score',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=error_score,-%27raise%27%20or%20numeric%2C%20default%3Dnp.nan\">\n",
       "            error_score\n",
       "            <span class=\"param-doc-description\">error_score: 'raise' or numeric, default=np.nan<br><br>Value to assign to the score if an error occurs in estimator fitting.<br>If set to 'raise', the error is raised. If a numeric value is given,<br>FitFailedWarning is raised. This parameter does not affect the refit<br>step, which will always raise the error.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">nan</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('return_train_score',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=return_train_score,-bool%2C%20default%3DFalse\">\n",
       "            return_train_score\n",
       "            <span class=\"param-doc-description\">return_train_score: bool, default=False<br><br>If ``False``, the ``cv_results_`` attribute will not include training<br>scores.<br>Computing training scores is used to get insights on how different<br>parameter settings impact the overfitting/underfitting trade-off.<br>However computing the scores on the training set can be computationally<br>expensive and is not strictly required to select the parameters that<br>yield the best generalization performance.<br><br>.. versionadded:: 0.19<br><br>.. versionchanged:: 0.21<br>    Default value was changed from ``True`` to ``False``</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>best_estimator_: XGBRegressor</div></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"best_estimator___\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=0.8, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             feature_weights=None, gamma=None, grow_policy=None,\n",
       "             importance_type=None, interaction_constraints=None,\n",
       "             learning_rate=0.1, max_bin=None, max_cat_threshold=None,\n",
       "             max_cat_to_onehot=None, max_delta_step=None, max_depth=5,\n",
       "             max_leaves=None, min_child_weight=None, missing=nan,\n",
       "             monotone_constraints=None, multi_strategy=None, n_estimators=300,\n",
       "             n_jobs=None, num_parallel_tree=None, ...)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>XGBRegressor</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor\">?<span>Documentation for XGBRegressor</span></a></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"best_estimator___\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('objective',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=objective,-str%20%7C%20xgboost.sklearn._SklObjWProto%20%7C%20typing.Callable%5B%5Btyping.Any%2C%20typing.Any%5D%2C%20typing.Tuple%5Bnumpy.ndarray%2C%20numpy.ndarray%5D%5D%20%7C%20None\">\n",
       "            objective\n",
       "            <span class=\"param-doc-description\">objective: str | xgboost.sklearn._SklObjWProto | typing.Callable[[typing.Any, typing.Any], typing.Tuple[numpy.ndarray, numpy.ndarray]] | None<br><br>Specify the learning task and the corresponding learning objective or a custom<br>objective function to be used.<br><br>For custom objective, see :doc:`/tutorials/custom_metric_obj` and<br>:ref:`custom-obj-metric` for more information, along with the end note for<br>function signatures.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">&#x27;reg:squarederror&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('base_score',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=base_score,-float%20%7C%20typing.List%5Bfloat%5D%20%7C%20None\">\n",
       "            base_score\n",
       "            <span class=\"param-doc-description\">base_score: float | typing.List[float] | None<br><br>The initial prediction score of all instances, global bias.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('booster',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">booster</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('callbacks',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=callbacks,-typing.List%5Bxgboost.callback.TrainingCallback%5D%20%7C%20None\">\n",
       "            callbacks\n",
       "            <span class=\"param-doc-description\">callbacks: typing.List[xgboost.callback.TrainingCallback] | None<br><br>List of callback functions that are applied at end of each iteration.<br>It is possible to use predefined callbacks by using<br>:ref:`Callback API <callback_api>`.<br><br>.. note::<br><br>   States in callback are not preserved during training, which means callback<br>   objects can not be reused for multiple training sessions without<br>   reinitialization or deepcopy.<br><br>.. code-block:: python<br><br>    for params in parameters_grid:<br>        # be sure to (re)initialize the callbacks before each run<br>        callbacks = [xgb.callback.LearningRateScheduler(custom_rates)]<br>        reg = xgboost.XGBRegressor(**params, callbacks=callbacks)<br>        reg.fit(X, y)</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('colsample_bylevel',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=colsample_bylevel,-float%20%7C%20None\">\n",
       "            colsample_bylevel\n",
       "            <span class=\"param-doc-description\">colsample_bylevel: float | None<br><br>Subsample ratio of columns for each level.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('colsample_bynode',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=colsample_bynode,-float%20%7C%20None\">\n",
       "            colsample_bynode\n",
       "            <span class=\"param-doc-description\">colsample_bynode: float | None<br><br>Subsample ratio of columns for each split.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('colsample_bytree',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=colsample_bytree,-float%20%7C%20None\">\n",
       "            colsample_bytree\n",
       "            <span class=\"param-doc-description\">colsample_bytree: float | None<br><br>Subsample ratio of columns when constructing each tree.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0.8</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('device',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=device,-str%20%7C%20None\">\n",
       "            device\n",
       "            <span class=\"param-doc-description\">device: str | None<br><br>.. versionadded:: 2.0.0<br><br>Device ordinal, available options are `cpu`, `cuda`, and `gpu`.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('early_stopping_rounds',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=early_stopping_rounds,-int%20%7C%20None\">\n",
       "            early_stopping_rounds\n",
       "            <span class=\"param-doc-description\">early_stopping_rounds: int | None<br><br>.. versionadded:: 1.6.0<br><br>- Activates early stopping. Validation metric needs to improve at least once in<br>  every **early_stopping_rounds** round(s) to continue training.  Requires at<br>  least one item in **eval_set** in :py:meth:`fit`.<br><br>- If early stopping occurs, the model will have two additional attributes:<br>  :py:attr:`best_score` and :py:attr:`best_iteration`. These are used by the<br>  :py:meth:`predict` and :py:meth:`apply` methods to determine the optimal<br>  number of trees during inference. If users want to access the full model<br>  (including trees built after early stopping), they can specify the<br>  `iteration_range` in these inference methods. In addition, other utilities<br>  like model plotting can also use the entire model.<br><br>- If you prefer to discard the trees after `best_iteration`, consider using the<br>  callback function :py:class:`xgboost.callback.EarlyStopping`.<br><br>- If there's more than one item in **eval_set**, the last entry will be used for<br>  early stopping.  If there's more than one metric in **eval_metric**, the last<br>  metric will be used for early stopping.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('enable_categorical',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=enable_categorical,-bool\">\n",
       "            enable_categorical\n",
       "            <span class=\"param-doc-description\">enable_categorical: bool<br><br>See the same parameter of :py:class:`DMatrix` for details.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('eval_metric',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=eval_metric,-str%20%7C%20typing.List%5Bstr%20%7C%20typing.Callable%5D%20%7C%20typing.Callable%20%7C%20None\">\n",
       "            eval_metric\n",
       "            <span class=\"param-doc-description\">eval_metric: str | typing.List[str | typing.Callable] | typing.Callable | None<br><br>.. versionadded:: 1.6.0<br><br>Metric used for monitoring the training result and early stopping.  It can be a<br>string or list of strings as names of predefined metric in XGBoost (See<br>:doc:`/parameter`), one of the metrics in :py:mod:`sklearn.metrics`, or any<br>other user defined metric that looks like `sklearn.metrics`.<br><br>If custom objective is also provided, then custom metric should implement the<br>corresponding reverse link function.<br><br>Unlike the `scoring` parameter commonly used in scikit-learn, when a callable<br>object is provided, it's assumed to be a cost function and by default XGBoost<br>will minimize the result during early stopping.<br><br>For advanced usage on Early stopping like directly choosing to maximize instead<br>of minimize, see :py:obj:`xgboost.callback.EarlyStopping`.<br><br>See :doc:`/tutorials/custom_metric_obj` and :ref:`custom-obj-metric` for more<br>information.<br><br>.. code-block:: python<br><br>    from sklearn.datasets import load_diabetes<br>    from sklearn.metrics import mean_absolute_error<br>    X, y = load_diabetes(return_X_y=True)<br>    reg = xgb.XGBRegressor(<br>        tree_method=\"hist\",<br>        eval_metric=mean_absolute_error,<br>    )<br>    reg.fit(X, y, eval_set=[(X, y)])</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('feature_types',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=feature_types,-typing.Sequence%5Bstr%5D%20%7C%20None\">\n",
       "            feature_types\n",
       "            <span class=\"param-doc-description\">feature_types: typing.Sequence[str] | None<br><br>.. versionadded:: 1.7.0<br><br>Used for specifying feature types without constructing a dataframe. See<br>the :py:class:`DMatrix` for details.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('feature_weights',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=feature_weights,-Optional%5BArrayLike%5D\">\n",
       "            feature_weights\n",
       "            <span class=\"param-doc-description\">feature_weights: Optional[ArrayLike]<br><br>Weight for each feature, defines the probability of each feature being selected<br>when colsample is being used.  All values must be greater than 0, otherwise a<br>`ValueError` is thrown.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('gamma',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=gamma,-float%20%7C%20None\">\n",
       "            gamma\n",
       "            <span class=\"param-doc-description\">gamma: float | None<br><br>(min_split_loss) Minimum loss reduction required to make a further partition on<br>a leaf node of the tree.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('grow_policy',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=grow_policy,-str%20%7C%20None\">\n",
       "            grow_policy\n",
       "            <span class=\"param-doc-description\">grow_policy: str | None<br><br>Tree growing policy.<br><br>- depthwise: Favors splitting at nodes closest to the node,<br>- lossguide: Favors splitting at nodes with highest loss change.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('importance_type',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">importance_type</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('interaction_constraints',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=interaction_constraints,-str%20%7C%20typing.List%5Btyping.Tuple%5Bstr%5D%5D%20%7C%20None\">\n",
       "            interaction_constraints\n",
       "            <span class=\"param-doc-description\">interaction_constraints: str | typing.List[typing.Tuple[str]] | None<br><br>Constraints for interaction representing permitted interactions.  The<br>constraints must be specified in the form of a nested list, e.g. ``[[0, 1], [2,<br>3, 4]]``, where each inner list is a group of indices of features that are<br>allowed to interact with each other.  See :doc:`tutorial<br></tutorials/feature_interaction_constraint>` for more information</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('learning_rate',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=learning_rate,-float%20%7C%20None\">\n",
       "            learning_rate\n",
       "            <span class=\"param-doc-description\">learning_rate: float | None<br><br>Boosting learning rate (xgb's \"eta\")</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0.1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_bin',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=max_bin,-int%20%7C%20None\">\n",
       "            max_bin\n",
       "            <span class=\"param-doc-description\">max_bin: int | None<br><br>If using histogram-based algorithm, maximum number of bins per feature</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_cat_threshold',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=max_cat_threshold,-int%20%7C%20None\">\n",
       "            max_cat_threshold\n",
       "            <span class=\"param-doc-description\">max_cat_threshold: int | None<br><br>.. versionadded:: 1.7.0<br><br>.. note:: This parameter is experimental<br><br>Maximum number of categories considered for each split. Used only by<br>partition-based splits for preventing over-fitting. Also, `enable_categorical`<br>needs to be set to have categorical feature support. See :doc:`Categorical Data<br></tutorials/categorical>` and :ref:`cat-param` for details.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_cat_to_onehot',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=max_cat_to_onehot,-Optional%5Bint%5D\">\n",
       "            max_cat_to_onehot\n",
       "            <span class=\"param-doc-description\">max_cat_to_onehot: Optional[int]<br><br>.. versionadded:: 1.6.0<br><br>.. note:: This parameter is experimental<br><br>A threshold for deciding whether XGBoost should use one-hot encoding based split<br>for categorical data.  When number of categories is lesser than the threshold<br>then one-hot encoding is chosen, otherwise the categories will be partitioned<br>into children nodes. Also, `enable_categorical` needs to be set to have<br>categorical feature support. See :doc:`Categorical Data<br></tutorials/categorical>` and :ref:`cat-param` for details.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_delta_step',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=max_delta_step,-float%20%7C%20None\">\n",
       "            max_delta_step\n",
       "            <span class=\"param-doc-description\">max_delta_step: float | None<br><br>Maximum delta step we allow each tree's weight estimation to be.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_depth',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=max_depth,-%20int%20%7C%20None\">\n",
       "            max_depth\n",
       "            <span class=\"param-doc-description\">max_depth:  int | None<br><br>Maximum tree depth for base learners.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">5</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_leaves',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=max_leaves,-int%20%7C%20None\">\n",
       "            max_leaves\n",
       "            <span class=\"param-doc-description\">max_leaves: int | None<br><br>Maximum number of leaves; 0 indicates no limit.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_child_weight',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=min_child_weight,-float%20%7C%20None\">\n",
       "            min_child_weight\n",
       "            <span class=\"param-doc-description\">min_child_weight: float | None<br><br>Minimum sum of instance weight(hessian) needed in a child.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('missing',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=missing,-float\">\n",
       "            missing\n",
       "            <span class=\"param-doc-description\">missing: float<br><br>Value in the data which needs to be present as a missing value. Default to<br>:py:data:`numpy.nan`.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">nan</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('monotone_constraints',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=monotone_constraints,-typing.Dict%5Bstr%2C%20int%5D%20%7C%20str%20%7C%20None\">\n",
       "            monotone_constraints\n",
       "            <span class=\"param-doc-description\">monotone_constraints: typing.Dict[str, int] | str | None<br><br>Constraint of variable monotonicity.  See :doc:`tutorial </tutorials/monotonic>`<br>for more information.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('multi_strategy',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=multi_strategy,-str%20%7C%20None\">\n",
       "            multi_strategy\n",
       "            <span class=\"param-doc-description\">multi_strategy: str | None<br><br>.. versionadded:: 2.0.0<br><br>.. note:: This parameter is working-in-progress.<br><br>The strategy used for training multi-target models, including multi-target<br>regression and multi-class classification. See :doc:`/tutorials/multioutput` for<br>more information.<br><br>- ``one_output_per_tree``: One model for each target.<br>- ``multi_output_tree``:  Use multi-target trees.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_estimators',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=n_estimators,-int%20%7C%20None\">\n",
       "            n_estimators\n",
       "            <span class=\"param-doc-description\">n_estimators: int | None<br><br>Number of gradient boosted trees.  Equivalent to number of boosting<br>rounds.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">300</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_jobs',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=n_jobs,-int%20%7C%20None\">\n",
       "            n_jobs\n",
       "            <span class=\"param-doc-description\">n_jobs: int | None<br><br>Number of parallel threads used to run xgboost.  When used with other<br>Scikit-Learn algorithms like grid search, you may choose which algorithm to<br>parallelize and balance the threads.  Creating thread contention will<br>significantly slow down both algorithms.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('num_parallel_tree',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">num_parallel_tree</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('random_state',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=random_state,-numpy.random.mtrand.RandomState%20%7C%20numpy.random._generator.Generator%20%7C%20int%20%7C%20None\">\n",
       "            random_state\n",
       "            <span class=\"param-doc-description\">random_state: numpy.random.mtrand.RandomState | numpy.random._generator.Generator | int | None<br><br>Random number seed.<br><br>.. note::<br><br>   Using gblinear booster with shotgun updater is nondeterministic as<br>   it uses Hogwild algorithm.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">5</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('reg_alpha',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=reg_alpha,-float%20%7C%20None\">\n",
       "            reg_alpha\n",
       "            <span class=\"param-doc-description\">reg_alpha: float | None<br><br>L1 regularization term on weights (xgb's alpha).</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('reg_lambda',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=reg_lambda,-float%20%7C%20None\">\n",
       "            reg_lambda\n",
       "            <span class=\"param-doc-description\">reg_lambda: float | None<br><br>L2 regularization term on weights (xgb's lambda).</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('sampling_method',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=sampling_method,-str%20%7C%20None\">\n",
       "            sampling_method\n",
       "            <span class=\"param-doc-description\">sampling_method: str | None<br><br>Sampling method. Used only by the GPU version of ``hist`` tree method.<br><br>- ``uniform``: Select random training instances uniformly.<br>- ``gradient_based``: Select random training instances with higher probability<br>    when the gradient and hessian are larger. (cf. CatBoost)</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('scale_pos_weight',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=scale_pos_weight,-float%20%7C%20None\">\n",
       "            scale_pos_weight\n",
       "            <span class=\"param-doc-description\">scale_pos_weight: float | None<br><br>Balancing of positive and negative weights.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('subsample',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=subsample,-float%20%7C%20None\">\n",
       "            subsample\n",
       "            <span class=\"param-doc-description\">subsample: float | None<br><br>Subsample ratio of the training instance.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">1.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('tree_method',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=tree_method,-str%20%7C%20None\">\n",
       "            tree_method\n",
       "            <span class=\"param-doc-description\">tree_method: str | None<br><br>Specify which tree method to use.  Default to auto.  If this parameter is set to<br>default, XGBoost will choose the most conservative option available.  It's<br>recommended to study this option from the parameters document :doc:`tree method<br></treemethod>`</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('validate_parameters',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=validate_parameters,-bool%20%7C%20None\">\n",
       "            validate_parameters\n",
       "            <span class=\"param-doc-description\">validate_parameters: bool | None<br><br>Give warnings for unknown parameter.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbosity',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=verbosity,-int%20%7C%20None\">\n",
       "            verbosity\n",
       "            <span class=\"param-doc-description\">verbosity: int | None<br><br>The degree of verbosity. Valid values are 0 (silent) - 3 (debug).</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div></div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.copy-paste-icon').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling\n",
       "        .textContent.trim().split(' ')[0];\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "\n",
       "\n",
       "/**\n",
       " * Adapted from Skrub\n",
       " * https://github.com/skrub-data/skrub/blob/403466d1d5d4dc76a7ef569b3f8228db59a31dc3/skrub/_reporting/_data/templates/report.js#L789\n",
       " * @returns \"light\" or \"dark\"\n",
       " */\n",
       "function detectTheme(element) {\n",
       "    const body = document.querySelector('body');\n",
       "\n",
       "    // Check VSCode theme\n",
       "    const themeKindAttr = body.getAttribute('data-vscode-theme-kind');\n",
       "    const themeNameAttr = body.getAttribute('data-vscode-theme-name');\n",
       "\n",
       "    if (themeKindAttr && themeNameAttr) {\n",
       "        const themeKind = themeKindAttr.toLowerCase();\n",
       "        const themeName = themeNameAttr.toLowerCase();\n",
       "\n",
       "        if (themeKind.includes(\"dark\") || themeName.includes(\"dark\")) {\n",
       "            return \"dark\";\n",
       "        }\n",
       "        if (themeKind.includes(\"light\") || themeName.includes(\"light\")) {\n",
       "            return \"light\";\n",
       "        }\n",
       "    }\n",
       "\n",
       "    // Check Jupyter theme\n",
       "    if (body.getAttribute('data-jp-theme-light') === 'false') {\n",
       "        return 'dark';\n",
       "    } else if (body.getAttribute('data-jp-theme-light') === 'true') {\n",
       "        return 'light';\n",
       "    }\n",
       "\n",
       "    // Guess based on a parent element's color\n",
       "    const color = window.getComputedStyle(element.parentNode, null).getPropertyValue('color');\n",
       "    const match = color.match(/^rgb\\s*\\(\\s*(\\d+)\\s*,\\s*(\\d+)\\s*,\\s*(\\d+)\\s*\\)\\s*$/i);\n",
       "    if (match) {\n",
       "        const [r, g, b] = [\n",
       "            parseFloat(match[1]),\n",
       "            parseFloat(match[2]),\n",
       "            parseFloat(match[3])\n",
       "        ];\n",
       "\n",
       "        // https://en.wikipedia.org/wiki/HSL_and_HSV#Lightness\n",
       "        const luma = 0.299 * r + 0.587 * g + 0.114 * b;\n",
       "\n",
       "        if (luma > 180) {\n",
       "            // If the text is very bright we have a dark theme\n",
       "            return 'dark';\n",
       "        }\n",
       "        if (luma < 75) {\n",
       "            // If the text is very dark we have a light theme\n",
       "            return 'light';\n",
       "        }\n",
       "        // Otherwise fall back to the next heuristic.\n",
       "    }\n",
       "\n",
       "    // Fallback to system preference\n",
       "    return window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'light';\n",
       "}\n",
       "\n",
       "\n",
       "function forceTheme(elementId) {\n",
       "    const estimatorElement = document.querySelector(`#${elementId}`);\n",
       "    if (estimatorElement === null) {\n",
       "        console.error(`Element with id ${elementId} not found.`);\n",
       "    } else {\n",
       "        const theme = detectTheme(estimatorElement);\n",
       "        estimatorElement.classList.add(theme);\n",
       "    }\n",
       "}\n",
       "\n",
       "forceTheme('sk-container-id-5');</script></body>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                    callbacks=None, colsample_bylevel=None,\n",
       "                                    colsample_bynode=None,\n",
       "                                    colsample_bytree=None, device=None,\n",
       "                                    early_stopping_rounds=None,\n",
       "                                    enable_categorical=False, eval_metric=None,\n",
       "                                    feature_types=None, feature_weights=None,\n",
       "                                    gamma=None, grow_policy=None,\n",
       "                                    importance_type=None,\n",
       "                                    interaction_constraints=None...\n",
       "                                    max_depth=None, max_leaves=None,\n",
       "                                    min_child_weight=None, missing=nan,\n",
       "                                    monotone_constraints=None,\n",
       "                                    multi_strategy=None, n_estimators=None,\n",
       "                                    n_jobs=None, num_parallel_tree=None, ...),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'colsample_bytree': [0.8, 1.0],\n",
       "                         'learning_rate': [0.01, 0.1, 0.3],\n",
       "                         'max_depth': [3, 5, 7],\n",
       "                         'n_estimators': [100, 200, 300],\n",
       "                         'subsample': [0.8, 1.0]},\n",
       "             scoring='neg_mean_squared_error', verbose=2)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## use grid search\n",
    "X_train, X_test, y_train, y_test = train_test_split(king_hs_X[best_features], king_hs_y, random_state=random_state, test_size=0.2)\n",
    "\n",
    "# Define the XGBoost model\n",
    "xgb_model = XGBRegressor(random_state=random_state, objective='reg:squarederror')\n",
    "\n",
    "# Define parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.01, 0.1, 0.3],\n",
    "    'subsample': [0.8, 1.0],\n",
    "    'colsample_bytree': [0.8, 1.0]\n",
    "}\n",
    "\n",
    "# Create GridSearchCV\n",
    "grid_search = GridSearchCV( ##RandomizedSearchCV , GridSearchCV\n",
    "    estimator=xgb_model,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,\n",
    "    scoring='neg_mean_squared_error',  # or 'r2', 'neg_mean_absolute_error'\n",
    "    verbose=2,\n",
    "    n_jobs=-1  # Use all processors\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "print(\"Starting Grid Search...\")\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "91e30b5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "BEST PARAMETERS:\n",
      "======================================================================\n",
      "{'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 300, 'subsample': 1.0}\n",
      "\n",
      "======================================================================\n",
      "BEST SCORE (CV):\n",
      "======================================================================\n",
      "Best CV Score: 0.0260\n"
     ]
    }
   ],
   "source": [
    "# Best parameters and score\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"BEST PARAMETERS:\")\n",
    "print(\"=\"*70)\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"BEST SCORE (CV):\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Best CV Score: {-grid_search.best_score_:.4f}\")  # Negative because of neg_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "8daaa972",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>r2_score</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td>0.951974</td>\n",
       "      <td>69583.251318</td>\n",
       "      <td>45304.148438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>0.916086</td>\n",
       "      <td>92242.177251</td>\n",
       "      <td>58919.042969</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       r2_score          RMSE           MAE\n",
       "train  0.951974  69583.251318  45304.148438\n",
       "test   0.916086  92242.177251  58919.042969"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the best model\n",
    "#np.expm1\n",
    "best_xgb = grid_search.best_estimator_\n",
    "\n",
    "### On train set\n",
    "y_pred_tr = np.expm1(best_xgb.predict(X_train))\n",
    "y_train_recaled =  np.expm1(y_train)\n",
    "eval_tr = pd.DataFrame([r2_score(y_train_recaled, y_pred_tr), np.sqrt(mean_squared_error(y_train_recaled, y_pred_tr)), mean_absolute_error(y_train_recaled, y_pred_tr)], index=['r2_score', 'RMSE', 'MAE']).T\n",
    "\n",
    "# Evaluate on test set\n",
    "y_pred = np.expm1(best_xgb.predict(X_test))\n",
    "y_test_recaled =  np.expm1(y_test)\n",
    "eval_ts = pd.DataFrame([r2_score(y_test_recaled, y_pred), np.sqrt(mean_squared_error(y_test_recaled, y_pred)), mean_absolute_error(y_test_recaled, y_pred)], index=['r2_score', 'RMSE', 'MAE']).T\n",
    "\n",
    "eval = pd.concat([eval_tr,eval_ts])\n",
    "eval.index=['train', 'test']\n",
    "eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "3772ebdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Importance:\n",
      "                   Feature  Importance\n",
      "16            luxury_index    0.271476\n",
      "18  size_grade_interaction    0.221254\n",
      "12                   grade    0.201556\n",
      "5                      lat    0.109582\n",
      "1              sqft_living    0.042737\n",
      "13            dist_seattle    0.024395\n",
      "9               waterfront    0.022893\n",
      "17     quality_interaction    0.019488\n",
      "7            sqft_living15    0.013857\n",
      "6                     long    0.008729\n",
      "21                 zipcode    0.007990\n",
      "19               year_sold    0.007749\n",
      "3               sqft_above    0.007538\n",
      "22            loc_clusters    0.005872\n",
      "20               house_age    0.005584\n",
      "2                 sqft_lot    0.005029\n",
      "8               sqft_lot15    0.004868\n",
      "10                    view    0.004805\n",
      "14      total_living_ratio    0.004294\n",
      "11               condition    0.003989\n",
      "0                bathrooms    0.002583\n",
      "15           relative_size    0.001911\n",
      "4            sqft_basement    0.001821\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get feature importances\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': X_train.columns,\n",
    "    'Importance': best_xgb.feature_importances_\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "# Display\n",
    "print(\"Feature Importance:\")\n",
    "print(feature_importance)\n",
    "\n",
    "# Visualize\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.barh(feature_importance['Feature'], feature_importance['Importance'])\n",
    "plt.xlabel('Importance', fontsize=12)\n",
    "plt.ylabel('Feature', fontsize=12)\n",
    "plt.title('XGBoost Feature Importance', fontsize=14, fontweight='bold')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ironhack",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
